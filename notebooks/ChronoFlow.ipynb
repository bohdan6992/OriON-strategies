{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e568166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_date = \"2026-01-01\"  # papermill replacement\n",
    "import os\n",
    "output_dir = os.environ.get(\"ORION_SIGNALS_DIR\", \"../signals\")\n",
    "config_path = os.environ.get(\"DATUM_API_CONFIG_PATH\", \"../ops/datum_api_config.json\")\n",
    "dry_run = False\n",
    "\n",
    "# ensure output exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b328423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic modules\n",
    "import pandas as pd\n",
    "from datum_api_client import DatumApi\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# pip install xlrd\n",
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dad44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import time, datetime, date, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _add_minutes_to_time(t: time, minutes: int) -> time:\n",
    "    \"\"\"Допоміжна: додає minutes до time (без врахування переходу через добу).\"\"\"\n",
    "    base = datetime.combine(date(2000, 1, 1), t)\n",
    "    res = base + timedelta(minutes=minutes)\n",
    "    return res.time()\n",
    "\n",
    "\n",
    "def analyze_intraday_windows(\n",
    "    input_parquet: str,\n",
    "    output_dir: str,\n",
    "    *,\n",
    "    # назви колонок у вхідному файлі\n",
    "    time_col: str = \"dt\",\n",
    "    ticker_col: str = \"ticker\",\n",
    "    stack_col: str = \"Stack%\",   # стак%\n",
    "    bench_col: str = \"Bench%\",   # бенч%\n",
    "    devsig_col: str = \"dev_sig\", # dev сигма\n",
    "    # часові вікна: (назва, nominal_from, nominal_to)\n",
    "    windows=None,\n",
    "    # параметри для бінінгу\n",
    "    n_bins: int = 6,\n",
    "    grow_threshold: float = 0.55,  # коли grow_rate >= цього → \"росте\"\n",
    "    fall_threshold: float = 0.45,  # коли grow_rate <= цього → \"падає\"\n",
    "    min_total_in_bin: int = 5,     # мін. кількість спостережень у біні\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Аналіз рухів по фіксованих вікнах часу.\n",
    "\n",
    "    summary.csv (ГОЛОВНА ЗМІНА):\n",
    "      - ОДИН рядок на тікер.\n",
    "      - Колонки, які потрібні фронту:\n",
    "          ticker, bench, corr, beta, sig,\n",
    "          events_total,\n",
    "          early_blue_up_rate, early_blue_down_rate,\n",
    "          early_ark_up_rate, early_ark_down_rate,\n",
    "          middle_ark_up_rate, middle_ark_down_rate,\n",
    "          late_ark_up_rate, late_ark_down_rate,\n",
    "          open_up_rate, open_down_rate,\n",
    "          early_post_up_rate, early_post_down_rate,\n",
    "          late_post_up_rate, late_post_down_rate,\n",
    "        + інші технічні колонки (total_delta, mean_delta_total тощо), які можна юзати в extras.\n",
    "\n",
    "    onefile.jsonl / best_params.json — без змін.\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 0. Дефолтні вікна\n",
    "    # --------------------------------------------------------\n",
    "    if windows is None:\n",
    "        windows = [\n",
    "            (\"EARLY_BLUE\",  time(0, 0),  time(0, 30)),\n",
    "            (\"EARLY_ARK\",   time(3, 50), time(4, 30)),\n",
    "            (\"MIDDLE_ARK\",  time(5, 50), time(6, 30)),\n",
    "            (\"LATE_ARK\",    time(7, 50), time(8, 30)),\n",
    "            (\"OPEN\",        time(9, 20), time(9, 40)),\n",
    "            (\"EARLY_POST\",  time(15, 50), time(16, 30)),\n",
    "            (\"LATE_POST\",   time(19, 30), time(19, 59)),\n",
    "        ]\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    summary_path = os.path.join(output_dir, \"summary.csv\")\n",
    "    onefile_path = os.path.join(output_dir, \"onefile.jsonl\")\n",
    "    best_params_path = os.path.join(output_dir, \"best_params.json\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 1. Читаємо дані\n",
    "    # --------------------------------------------------------\n",
    "    cols = [time_col, ticker_col, stack_col, bench_col, devsig_col]\n",
    "    df = pd.read_parquet(input_parquet, columns=cols)\n",
    "\n",
    "    required_cols = cols\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"У вхідному файлі немає колонок: {missing}\")\n",
    "\n",
    "    mask_basic = df[time_col].notna() & df[ticker_col].notna()\n",
    "    df = df.loc[mask_basic]\n",
    "\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df[\"session_date\"] = df[time_col].dt.date\n",
    "    df[\"time_only\"] = df[time_col].dt.time\n",
    "\n",
    "    for c in (stack_col, bench_col, devsig_col):\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    mask_num = df[stack_col].notna() & df[bench_col].notna() & df[devsig_col].notna()\n",
    "    df = df.loc[mask_num].reset_index(drop=True)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 2. Конструюємо events по кожному вікну\n",
    "    # --------------------------------------------------------\n",
    "    events_frames = []\n",
    "\n",
    "    for win_name, t_from, t_to in windows:\n",
    "        start_to = _add_minutes_to_time(t_from, 10)\n",
    "        end_to = _add_minutes_to_time(t_to, 10)\n",
    "\n",
    "        mask_window = (df[\"time_only\"] >= t_from) & (df[\"time_only\"] <= end_to)\n",
    "        wdf = df.loc[mask_window].copy()\n",
    "        if wdf.empty:\n",
    "            continue\n",
    "\n",
    "        # START\n",
    "        start_mask = (wdf[\"time_only\"] >= t_from) & (wdf[\"time_only\"] <= start_to)\n",
    "        w_start = wdf.loc[start_mask]\n",
    "        if w_start.empty:\n",
    "            continue\n",
    "        w_start = w_start.sort_values(time_col)\n",
    "        start_idx = w_start.groupby([ticker_col, \"session_date\"])[time_col].idxmin()\n",
    "        start_rows = w_start.loc[start_idx]\n",
    "\n",
    "        # END\n",
    "        end_mask = (wdf[\"time_only\"] >= t_to) & (wdf[\"time_only\"] <= end_to)\n",
    "        w_end = wdf.loc[end_mask]\n",
    "        if w_end.empty:\n",
    "            continue\n",
    "        w_end = w_end.sort_values(time_col)\n",
    "        end_idx = w_end.groupby([ticker_col, \"session_date\"])[time_col].idxmin()\n",
    "        end_rows = w_end.loc[end_idx]\n",
    "\n",
    "        # merge start/end\n",
    "        start_rows = start_rows.reset_index(drop=True)\n",
    "        end_rows = end_rows.reset_index(drop=True)\n",
    "\n",
    "        merged = pd.merge(\n",
    "            start_rows,\n",
    "            end_rows,\n",
    "            on=[ticker_col, \"session_date\"],\n",
    "            suffixes=(\"_start\", \"_end\"),\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        if merged.empty:\n",
    "            continue\n",
    "\n",
    "        start_dt_col = f\"{time_col}_start\"\n",
    "        end_dt_col = f\"{time_col}_end\"\n",
    "        merged = merged[merged[end_dt_col] > merged[start_dt_col]]\n",
    "        if merged.empty:\n",
    "            continue\n",
    "\n",
    "        events_win = pd.DataFrame({\n",
    "            ticker_col: merged[ticker_col],\n",
    "            \"session_date\": merged[\"session_date\"],\n",
    "            \"window\": win_name,\n",
    "            \"start_dt\": merged[start_dt_col],\n",
    "            \"end_dt\": merged[end_dt_col],\n",
    "            \"stack_start\": merged[f\"{stack_col}_start\"].astype(float),\n",
    "            \"stack_end\": merged[f\"{stack_col}_end\"].astype(float),\n",
    "            \"bench_start\": merged[f\"{bench_col}_start\"].astype(float),\n",
    "            \"bench_end\": merged[f\"{bench_col}_end\"].astype(float),\n",
    "            \"dev_start\": merged[f\"{devsig_col}_start\"].astype(float),\n",
    "            \"dev_end\": merged[f\"{devsig_col}_end\"].astype(float),\n",
    "        })\n",
    "\n",
    "        events_win[\"delta_stack\"] = events_win[\"stack_end\"] - events_win[\"stack_start\"]\n",
    "        events_win[\"delta_bench\"] = events_win[\"bench_end\"] - events_win[\"bench_start\"]\n",
    "        events_win[\"delta_dev\"] = events_win[\"dev_end\"] - events_win[\"dev_start\"]\n",
    "        events_win[\"grew\"] = events_win[\"delta_stack\"] > 0\n",
    "\n",
    "        events_frames.append(events_win)\n",
    "\n",
    "    if not events_frames:\n",
    "        raise ValueError(\n",
    "            \"Немає жодної події в жодному вікні (навіть з +10 хв толерансом). \"\n",
    "            \"Перевір вхідний файл / таймзону / вікна.\"\n",
    "        )\n",
    "\n",
    "    events = pd.concat(events_frames, ignore_index=True)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3. summary_df по (ticker, window) — проміжний крок\n",
    "    # --------------------------------------------------------\n",
    "    g_tw = events.groupby([ticker_col, \"window\"])\n",
    "\n",
    "    agg_base = (\n",
    "        g_tw\n",
    "        .agg(\n",
    "            n=(\"delta_stack\", \"count\"),\n",
    "            total_delta=(\"delta_stack\", \"sum\"),\n",
    "            mean_delta=(\"delta_stack\", \"mean\"),\n",
    "            median_delta=(\"delta_stack\", \"median\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    up_mask = events[\"delta_stack\"] > 0\n",
    "    down_mask = events[\"delta_stack\"] < 0\n",
    "\n",
    "    up_stats = (\n",
    "        events.loc[up_mask]\n",
    "        .groupby([ticker_col, \"window\"])\n",
    "        .agg(\n",
    "            n_up=(\"delta_stack\", \"count\"),\n",
    "            mean_up=(\"delta_stack\", \"mean\"),\n",
    "            median_up=(\"delta_stack\", \"median\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    down_stats = (\n",
    "        events.loc[down_mask]\n",
    "        .groupby([ticker_col, \"window\"])\n",
    "        .agg(\n",
    "            n_down=(\"delta_stack\", \"count\"),\n",
    "            mean_down=(\"delta_stack\", \"mean\"),\n",
    "            median_down=(\"delta_stack\", \"median\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    summary_df = (\n",
    "        agg_base\n",
    "        .merge(up_stats, on=[ticker_col, \"window\"], how=\"left\")\n",
    "        .merge(down_stats, on=[ticker_col, \"window\"], how=\"left\")\n",
    "    )\n",
    "\n",
    "    summary_df[\"n_up\"] = summary_df[\"n_up\"].fillna(0).astype(int)\n",
    "    summary_df[\"n_down\"] = summary_df[\"n_down\"].fillna(0).astype(int)\n",
    "\n",
    "    summary_df[\"mean_up\"] = summary_df[\"mean_up\"].where(summary_df[\"n_up\"] > 0, np.nan)\n",
    "    summary_df[\"median_up\"] = summary_df[\"median_up\"].where(summary_df[\"n_up\"] > 0, np.nan)\n",
    "    summary_df[\"mean_down\"] = summary_df[\"mean_down\"].where(summary_df[\"n_down\"] > 0, np.nan)\n",
    "    summary_df[\"median_down\"] = summary_df[\"median_down\"].where(summary_df[\"n_down\"] > 0, np.nan)\n",
    "\n",
    "    summary_df[\"n_flat\"] = summary_df[\"n\"] - summary_df[\"n_up\"] - summary_df[\"n_down\"]\n",
    "    summary_df[\"up_ratio\"] = summary_df[\"n_up\"] / summary_df[\"n\"]\n",
    "    summary_df[\"down_ratio\"] = summary_df[\"n_down\"] / summary_df[\"n\"]\n",
    "\n",
    "    summary_df = summary_df[\n",
    "        [\n",
    "            ticker_col,\n",
    "            \"window\",\n",
    "            \"n\",\n",
    "            \"n_up\",\n",
    "            \"n_down\",\n",
    "            \"n_flat\",\n",
    "            \"up_ratio\",\n",
    "            \"down_ratio\",\n",
    "            \"total_delta\",\n",
    "            \"mean_delta\",\n",
    "            \"median_delta\",\n",
    "            \"mean_up\",\n",
    "            \"median_up\",\n",
    "            \"mean_down\",\n",
    "            \"median_down\",\n",
    "        ]\n",
    "    ].sort_values([ticker_col, \"window\"])\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3b. Перетворюємо summary_df → ОДИН РЯДОК НА ТІКЕР (ПІД ФРОНТ)\n",
    "    # --------------------------------------------------------\n",
    "    # Глобальні метрики по тікеру (агрегація по всіх вікнах)\n",
    "    g_t = events.groupby(ticker_col)\n",
    "\n",
    "    global_df = (\n",
    "        g_t\n",
    "        .agg(\n",
    "            events_total=(\"delta_stack\", \"count\"),\n",
    "            total_delta=(\"delta_stack\", \"sum\"),\n",
    "            mean_delta_total=(\"delta_stack\", \"mean\"),\n",
    "            median_delta_total=(\"delta_stack\", \"median\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # up/down/flat по всіх вікнах\n",
    "    up_global = (\n",
    "        events.loc[events[\"delta_stack\"] > 0]\n",
    "        .groupby(ticker_col)\n",
    "        .agg(n_up_total=(\"delta_stack\", \"count\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    down_global = (\n",
    "        events.loc[events[\"delta_stack\"] < 0]\n",
    "        .groupby(ticker_col)\n",
    "        .agg(n_down_total=(\"delta_stack\", \"count\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    global_df = (\n",
    "        global_df\n",
    "        .merge(up_global, on=ticker_col, how=\"left\")\n",
    "        .merge(down_global, on=ticker_col, how=\"left\")\n",
    "    )\n",
    "\n",
    "    global_df[\"n_up_total\"] = global_df[\"n_up_total\"].fillna(0).astype(int)\n",
    "    global_df[\"n_down_total\"] = global_df[\"n_down_total\"].fillna(0).astype(int)\n",
    "    global_df[\"n_flat_total\"] = (\n",
    "        global_df[\"events_total\"] - global_df[\"n_up_total\"] - global_df[\"n_down_total\"]\n",
    "    ).astype(int)\n",
    "\n",
    "    global_df[\"up_ratio_total\"] = global_df[\"n_up_total\"] / global_df[\"events_total\"]\n",
    "    global_df[\"down_ratio_total\"] = global_df[\"n_down_total\"] / global_df[\"events_total\"]\n",
    "\n",
    "    # wide-таблиця по вікнах: (metric, window) → колонки\n",
    "    wide = summary_df.pivot(\n",
    "        index=ticker_col,\n",
    "        columns=\"window\",\n",
    "        values=[\n",
    "            \"n\",\n",
    "            \"n_up\",\n",
    "            \"n_down\",\n",
    "            \"n_flat\",\n",
    "            \"up_ratio\",\n",
    "            \"down_ratio\",\n",
    "            \"total_delta\",\n",
    "            \"mean_delta\",\n",
    "            \"median_delta\",\n",
    "            \"mean_up\",\n",
    "            \"median_up\",\n",
    "            \"mean_down\",\n",
    "            \"median_down\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # (metric, window) → f\"{window}_{metric}\", напр. EARLY_ARK_up_ratio\n",
    "    wide.columns = [\n",
    "        f\"{win}_{metric}\"\n",
    "        for (metric, win) in wide.columns.to_flat_index()\n",
    "    ]\n",
    "    wide = wide.reset_index()\n",
    "\n",
    "    # мерджимо глобальні колонки + wide по вікнах\n",
    "    summary_final = (\n",
    "        global_df\n",
    "        .merge(wide, on=ticker_col, how=\"left\")\n",
    "        .sort_values(ticker_col)\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3c. Додаємо meta-колонки bench/corr/beta/sig (порожні, якщо немає)\n",
    "    # --------------------------------------------------------\n",
    "    for c in [\"bench\", \"corr\", \"beta\", \"sig\"]:\n",
    "        if c not in summary_final.columns:\n",
    "            summary_final[c] = \"\"\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3d. Аліаси під фронт: *_up_rate / *_down_rate\n",
    "    #     Беремо з <WINDOW>_up_ratio / <WINDOW>_down_ratio\n",
    "    # --------------------------------------------------------\n",
    "    def alias_rate(window_name: str, alias_prefix: str):\n",
    "        up_src = f\"{window_name}_up_ratio\"\n",
    "        dn_src = f\"{window_name}_down_ratio\"\n",
    "\n",
    "        up_alias = f\"{alias_prefix}_up_rate\"\n",
    "        dn_alias = f\"{alias_prefix}_down_rate\"\n",
    "\n",
    "        if up_src in summary_final.columns:\n",
    "            summary_final[up_alias] = summary_final[up_src]\n",
    "        else:\n",
    "            summary_final[up_alias] = np.nan\n",
    "\n",
    "        if dn_src in summary_final.columns:\n",
    "            summary_final[dn_alias] = summary_final[dn_src]\n",
    "        else:\n",
    "            summary_final[dn_alias] = np.nan\n",
    "\n",
    "    alias_rate(\"EARLY_BLUE\",  \"early_blue\")\n",
    "    alias_rate(\"EARLY_ARK\",   \"early_ark\")\n",
    "    alias_rate(\"MIDDLE_ARK\",  \"middle_ark\")\n",
    "    alias_rate(\"LATE_ARK\",    \"late_ark\")\n",
    "    alias_rate(\"OPEN\",        \"open\")\n",
    "    alias_rate(\"EARLY_POST\",  \"early_post\")\n",
    "    alias_rate(\"LATE_POST\",   \"late_post\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3e. Порядок колонок: спочатку те, що юзає фронт\n",
    "    # --------------------------------------------------------\n",
    "    preferred_order = [\n",
    "        ticker_col,\n",
    "        \"bench\",\n",
    "        \"corr\",\n",
    "        \"beta\",\n",
    "        \"sig\",\n",
    "        \"events_total\",\n",
    "        \"total_delta\",\n",
    "        \"mean_delta_total\",\n",
    "        \"median_delta_total\",\n",
    "        \"n_up_total\",\n",
    "        \"n_down_total\",\n",
    "        \"n_flat_total\",\n",
    "        \"up_ratio_total\",\n",
    "        \"down_ratio_total\",\n",
    "\n",
    "        \"early_blue_up_rate\",\n",
    "        \"early_blue_down_rate\",\n",
    "        \"early_ark_up_rate\",\n",
    "        \"early_ark_down_rate\",\n",
    "        \"middle_ark_up_rate\",\n",
    "        \"middle_ark_down_rate\",\n",
    "        \"late_ark_up_rate\",\n",
    "        \"late_ark_down_rate\",\n",
    "        \"open_up_rate\",\n",
    "        \"open_down_rate\",\n",
    "        \"early_post_up_rate\",\n",
    "        \"early_post_down_rate\",\n",
    "        \"late_post_up_rate\",\n",
    "        \"late_post_down_rate\",\n",
    "    ]\n",
    "\n",
    "    other_cols = [c for c in summary_final.columns if c not in preferred_order]\n",
    "    summary_final = summary_final[preferred_order + other_cols]\n",
    "\n",
    "    # фінальний запис CSV\n",
    "    summary_final.to_csv(summary_path, index=False)\n",
    "\n",
    "    # мапа (ticker, window) → рядок summary_df (для onefile.jsonl)\n",
    "    summary_map = {\n",
    "        (row[ticker_col], row[\"window\"]): row\n",
    "        for _, row in summary_df.iterrows()\n",
    "    }\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 4. Хелпери для бінінгу та examples (ONEFILE / BEST_PARAMS)\n",
    "    # --------------------------------------------------------\n",
    "    def build_bins_for_feature(df_group: pd.DataFrame, feature_col: str):\n",
    "        series = df_group[feature_col].dropna()\n",
    "        if len(series) < min_total_in_bin:\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            labels = pd.qcut(series, q=min(n_bins, series.nunique()), duplicates=\"drop\")\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "        tmp = df_group.copy()\n",
    "        tmp[\"bin\"] = labels\n",
    "\n",
    "        res = []\n",
    "        for b, gb in tmp.groupby(\"bin\"):\n",
    "            n = len(gb)\n",
    "            if n < min_total_in_bin:\n",
    "                continue\n",
    "\n",
    "            delta = gb[\"delta_stack\"]\n",
    "            pos = delta[delta > 0]\n",
    "            neg = delta[delta < 0]\n",
    "            grow_rate = float((delta > 0).mean()) if n > 0 else 0.0\n",
    "\n",
    "            left = float(b.left)\n",
    "            right = float(b.right)\n",
    "\n",
    "            res.append(\n",
    "                {\n",
    "                    \"from\": left,\n",
    "                    \"to\": right,\n",
    "                    \"n\": int(n),\n",
    "                    \"grow_rate\": grow_rate,\n",
    "                    \"mean_delta\": float(delta.mean()),\n",
    "                    \"median_delta\": float(delta.median()),\n",
    "                    \"mean_up\": float(pos.mean()) if len(pos) else None,\n",
    "                    \"median_up\": float(pos.median()) if len(pos) else None,\n",
    "                    \"mean_down\": float(neg.mean()) if len(neg) else None,\n",
    "                    \"median_down\": float(neg.median()) if len(neg) else None,\n",
    "                }\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    def build_bins_2d(df_group: pd.DataFrame, x_col: str, y_col: str):\n",
    "        df_xy = df_group[[x_col, y_col, \"delta_stack\"]].dropna()\n",
    "        if len(df_xy) < min_total_in_bin:\n",
    "            return []\n",
    "\n",
    "        x = df_xy[x_col]\n",
    "        y = df_xy[y_col]\n",
    "\n",
    "        try:\n",
    "            x_bins = pd.qcut(x, q=min(n_bins, x.nunique()), duplicates=\"drop\")\n",
    "            y_bins = pd.qcut(y, q=min(n_bins, y.nunique()), duplicates=\"drop\")\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "        tmp = df_xy.copy()\n",
    "        tmp[\"x_bin\"] = x_bins\n",
    "        tmp[\"y_bin\"] = y_bins\n",
    "\n",
    "        res = []\n",
    "        for (bx, by), gb in tmp.groupby([\"x_bin\", \"y_bin\"]):\n",
    "            n = len(gb)\n",
    "            if n < min_total_in_bin:\n",
    "                continue\n",
    "\n",
    "            delta = gb[\"delta_stack\"]\n",
    "            pos = delta[delta > 0]\n",
    "            neg = delta[delta < 0]\n",
    "            grow_rate = float((delta > 0).mean()) if n > 0 else 0.0\n",
    "\n",
    "            res.append(\n",
    "                {\n",
    "                    \"dev_from\": float(bx.left),\n",
    "                    \"dev_to\": float(bx.right),\n",
    "                    \"bench_from\": float(by.left),\n",
    "                    \"bench_to\": float(by.right),\n",
    "                    \"n\": int(n),\n",
    "                    \"grow_rate\": grow_rate,\n",
    "                    \"mean_delta\": float(delta.mean()),\n",
    "                    \"median_delta\": float(delta.median()),\n",
    "                    \"mean_up\": float(pos.mean()) if len(pos) else None,\n",
    "                    \"median_up\": float(pos.median()) if len(pos) else None,\n",
    "                    \"mean_down\": float(neg.mean()) if len(neg) else None,\n",
    "                    \"median_down\": float(neg.median()) if len(neg) else None,\n",
    "                }\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    def build_examples(df_tw: pd.DataFrame, kind: str, limit: int = 3):\n",
    "        if kind == \"up\":\n",
    "            mask = df_tw[\"delta_stack\"] > 0\n",
    "        elif kind == \"down\":\n",
    "            mask = df_tw[\"delta_stack\"] < 0\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        df_k = df_tw.loc[mask]\n",
    "        if df_k.empty:\n",
    "            return []\n",
    "\n",
    "        df_k = df_k.sort_values([\"session_date\", \"end_dt\"])\n",
    "        df_last = df_k.tail(limit)\n",
    "\n",
    "        examples = []\n",
    "        for _, row in df_last.iterrows():\n",
    "            examples.append(\n",
    "                {\n",
    "                    \"date\": str(row[\"session_date\"]),\n",
    "                    \"start_dt\": row[\"start_dt\"].isoformat(),\n",
    "                    \"end_dt\": row[\"end_dt\"].isoformat(),\n",
    "                    \"stack_start\": float(row[\"stack_start\"]),\n",
    "                    \"stack_end\": float(row[\"stack_end\"]),\n",
    "                    \"bench_start\": float(row[\"bench_start\"]),\n",
    "                    \"bench_end\": float(row[\"bench_end\"]),\n",
    "                    \"dev_start\": float(row[\"dev_start\"]),\n",
    "                    \"dev_end\": float(row[\"dev_end\"]),\n",
    "                    \"delta_stack\": float(row[\"delta_stack\"]),\n",
    "                    \"delta_bench\": float(row[\"delta_bench\"]),\n",
    "                    \"delta_dev\": float(row[\"delta_dev\"]),\n",
    "                }\n",
    "            )\n",
    "        return examples\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 5. onefile.jsonl + best_params.json (без змін)\n",
    "    # --------------------------------------------------------\n",
    "    best_params: dict[str, dict] = {}\n",
    "    onefile_out = open(onefile_path, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    for ticker, df_ticker in events.groupby(ticker_col):\n",
    "\n",
    "        ticker_record = {\n",
    "            \"ticker\": ticker,\n",
    "            \"windows\": {}\n",
    "        }\n",
    "\n",
    "        best_params[ticker] = {}\n",
    "\n",
    "        for win_name, df_tw in df_ticker.groupby(\"window\"):\n",
    "            stats_row = summary_map.get((ticker, win_name))\n",
    "            if stats_row is None:\n",
    "                continue\n",
    "\n",
    "            # 1D-біни\n",
    "            stack_bins = build_bins_for_feature(df_tw, \"stack_start\")\n",
    "            bench_bins = build_bins_for_feature(df_tw, \"bench_start\")\n",
    "            dev_bins = build_bins_for_feature(df_tw, \"dev_start\")\n",
    "\n",
    "            bins_1d = {\n",
    "                \"stack_start\": stack_bins,\n",
    "                \"bench_start\": bench_bins,\n",
    "                \"dev_start\": dev_bins,\n",
    "            }\n",
    "\n",
    "            # 2D-біни dev_start vs bench_start\n",
    "            bins2d_dev_bench = build_bins_2d(df_tw, \"dev_start\", \"bench_start\")\n",
    "\n",
    "            # приклади\n",
    "            examples_up = build_examples(df_tw, \"up\", limit=3)\n",
    "            examples_down = build_examples(df_tw, \"down\", limit=3)\n",
    "\n",
    "            ticker_record[\"windows\"][win_name] = {\n",
    "                \"stats\": {\n",
    "                    \"n\": int(stats_row[\"n\"]),\n",
    "                    \"n_up\": int(stats_row[\"n_up\"]),\n",
    "                    \"n_down\": int(stats_row[\"n_down\"]),\n",
    "                    \"n_flat\": int(stats_row[\"n_flat\"]),\n",
    "                    \"up_ratio\": float(stats_row[\"up_ratio\"]),\n",
    "                    \"down_ratio\": float(stats_row[\"down_ratio\"]),\n",
    "                    \"total_delta\": float(stats_row[\"total_delta\"]),\n",
    "                    \"mean_delta\": float(stats_row[\"mean_delta\"]),\n",
    "                    \"median_delta\": float(stats_row[\"median_delta\"]),\n",
    "                    \"mean_up\": None if pd.isna(stats_row[\"mean_up\"]) else float(stats_row[\"mean_up\"]),\n",
    "                    \"median_up\": None if pd.isna(stats_row[\"median_up\"]) else float(stats_row[\"median_up\"]),\n",
    "                    \"mean_down\": None if pd.isna(stats_row[\"mean_down\"]) else float(stats_row[\"mean_down\"]),\n",
    "                    \"median_down\": None if pd.isna(stats_row[\"median_down\"]) else float(stats_row[\"median_down\"]),\n",
    "                },\n",
    "                \"bins_1d\": bins_1d,\n",
    "                \"bins_2d\": {\n",
    "                    \"dev_vs_bench\": bins2d_dev_bench\n",
    "                },\n",
    "                \"examples\": {\n",
    "                    \"up\": examples_up,\n",
    "                    \"down\": examples_down,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # best_params з 1D-бінів\n",
    "            win_best = {}\n",
    "\n",
    "            def merge_bins(bins_list):\n",
    "                if not bins_list:\n",
    "                    return []\n",
    "\n",
    "                bins_sorted = sorted(bins_list, key=lambda x: x[\"from\"])\n",
    "                merged = []\n",
    "                cur = {\n",
    "                    \"from\": bins_sorted[0][\"from\"],\n",
    "                    \"to\": bins_sorted[0][\"to\"],\n",
    "                    \"total\": bins_sorted[0][\"n\"],\n",
    "                    \"sum_rate\": bins_sorted[0][\"grow_rate\"] * bins_sorted[0][\"n\"],\n",
    "                }\n",
    "\n",
    "                for b in bins_sorted[1:]:\n",
    "                    if b[\"from\"] <= cur[\"to\"]:\n",
    "                        cur[\"to\"] = max(cur[\"to\"], b[\"to\"])\n",
    "                        cur[\"total\"] += b[\"n\"]\n",
    "                        cur[\"sum_rate\"] += b[\"grow_rate\"] * b[\"n\"]\n",
    "                    else:\n",
    "                        rate = cur[\"sum_rate\"] / cur[\"total\"] if cur[\"total\"] > 0 else 0.0\n",
    "                        merged.append(\n",
    "                            {\n",
    "                                \"from\": float(cur[\"from\"]),\n",
    "                                \"to\": float(cur[\"to\"]),\n",
    "                                \"rate\": float(rate),\n",
    "                                \"total\": int(cur[\"total\"]),\n",
    "                            }\n",
    "                        )\n",
    "                        cur = {\n",
    "                            \"from\": b[\"from\"],\n",
    "                            \"to\": b[\"to\"],\n",
    "                            \"total\": b[\"n\"],\n",
    "                            \"sum_rate\": b[\"grow_rate\"] * b[\"n\"],\n",
    "                        }\n",
    "\n",
    "                rate = cur[\"sum_rate\"] / cur[\"total\"] if cur[\"total\"] > 0 else 0.0\n",
    "                merged.append(\n",
    "                    {\n",
    "                        \"from\": float(cur[\"from\"]),\n",
    "                        \"to\": float(cur[\"to\"]),\n",
    "                        \"rate\": float(rate),\n",
    "                        \"total\": int(cur[\"total\"]),\n",
    "                    }\n",
    "                )\n",
    "                return merged\n",
    "\n",
    "            for feat_name, feat_bins in bins_1d.items():\n",
    "                if not feat_bins:\n",
    "                    continue\n",
    "\n",
    "                up_bins = [\n",
    "                    b for b in feat_bins\n",
    "                    if (b[\"grow_rate\"] >= grow_threshold and b[\"n\"] >= min_total_in_bin)\n",
    "                ]\n",
    "                down_bins = [\n",
    "                    b for b in feat_bins\n",
    "                    if (b[\"grow_rate\"] <= fall_threshold and b[\"n\"] >= min_total_in_bin)\n",
    "                ]\n",
    "\n",
    "                win_best[feat_name] = {\n",
    "                    \"up\": merge_bins(up_bins),\n",
    "                    \"down\": merge_bins(down_bins),\n",
    "                }\n",
    "\n",
    "            best_params[ticker][win_name] = win_best\n",
    "\n",
    "        onefile_out.write(json.dumps(ticker_record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    onefile_out.close()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 6. best_params.json\n",
    "    # --------------------------------------------------------\n",
    "    with open(best_params_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(best_params, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"Готово:\")\n",
    "    print(f\"  summary     -> {summary_path}\")\n",
    "    print(f\"  onefile     -> {onefile_path}\")\n",
    "    print(f\"  best_params -> {best_params_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d69fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово:\n",
      "  summary     -> ARBITRAGE/windows_analysis\\summary.csv\n",
      "  onefile     -> ARBITRAGE/windows_analysis\\onefile.jsonl\n",
      "  best_params -> ARBITRAGE/windows_analysis\\best_params.json\n"
     ]
    }
   ],
   "source": [
    "# analyze_intraday_windows(\n",
    "#     input_parquet=\"ARBITRAGE/final_filtered.parquet\",\n",
    "#     output_dir=\"ARBITRAGE/windows_analysis\",\n",
    "#     n_bins=6,\n",
    "#     grow_threshold=0.55,\n",
    "#     fall_threshold=0.45,\n",
    "#     min_total_in_bin=5,\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
