{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ae8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_date = \"2026-01-01\"  # papermill replacement\n",
    "import os\n",
    "output_dir = os.environ.get(\"ORION_SIGNALS_DIR\", \"../signals\")\n",
    "config_path = os.environ.get(\"DATUM_API_CONFIG_PATH\", \"../ops/datum_api_config.json\")\n",
    "dry_run = False\n",
    "\n",
    "# ensure output exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0381d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic modules\n",
    "import pandas as pd\n",
    "from datum_api_client import DatumApi\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# pip install xlrd\n",
    "# pip install openpyxl\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af3ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "def devsig_stream_stats_v12_exporter(\n",
    "    input_path: str,\n",
    "    *,\n",
    "    # === outputs ===\n",
    "    output_onefile_jsonl: str = \"ARBITRAGE/onefile.jsonl\",\n",
    "    output_summary_csv: str = \"ARBITRAGE/summary.csv\",\n",
    "    output_best_params_jsonl: str = \"ARBITRAGE/best_params.jsonl\",\n",
    "    # === include heavy parts ===\n",
    "    include_events_pre: bool = False,\n",
    "    include_events_intra: bool = False,\n",
    "    include_events_post: bool = False,\n",
    "    max_events_per_ticker: int = 500,\n",
    "    # === thresholds ===\n",
    "    dev_thr: float = 0.30,      # trigger (abs(dev_sig) >= dev_thr)\n",
    "    norm_thr: float = 0.10,     # HARD normalization threshold (abs(dev_sig) <= norm_thr)\n",
    "    soft_ratio: float = 3.0,    # SOFT: abs(dev_sig) <= peak_abs / soft_ratio\n",
    "    # === best params selection rules (kept; we ADD simpler ANY windows) ===\n",
    "    best_rules: \"dict|None\" = None,\n",
    "    # === reading ===\n",
    "    assume_sorted: bool = True,\n",
    "    parquet_use_pyarrow: bool = True,\n",
    "    parquet_iter_batches: bool = True,   # ✅ optional speedup (Step 4)\n",
    "    parquet_batch_size: int = 1_000_000, # ✅ batch size for iter_batches\n",
    "    csv_chunksize: int = 500_000,\n",
    "    log_every_n_chunks: int = 5,\n",
    "    # === bins ===\n",
    "    sigma_bin_min: float = 0.2,\n",
    "    sigma_bin_max: float = 2.7,\n",
    "    sigma_bin_step: float = 0.1,\n",
    "    bench_bin_min: float = -3.0,\n",
    "    bench_bin_max: float = 3.0,\n",
    "    bench_bin_step: float = 0.1,\n",
    "    # === time bands ===\n",
    "    start_band_minutes: int = 30,\n",
    "    norm_band_minutes: int = 30,\n",
    "    # === numeric fields stored in data ===\n",
    "    BENCH_NUM_FIELD: str = \"Bench%\",\n",
    "    STOCK_NUM_FIELD: str = \"Stack%\",\n",
    "    # === global filter for ALL outputs ===\n",
    "    min_events_per_ticker: int = 10,\n",
    "    # === open series ===\n",
    "    open_series_downsample_seconds: int = 60,  # 60s => 1 point / minute\n",
    "):\n",
    "    \"\"\"\n",
    "    v12 exporter UPDATED with BLUE + POST and strict \"parallel class checks\" semantics:\n",
    "\n",
    "    ✅ Classes:\n",
    "      - PRE classes: BLUE, ARK, PRINT, OPEN (all evaluated in parallel for the same PRE event)\n",
    "      - GLOBAL = priority selector over {BLUE, ARK, PRINT, OPEN} (POST NOT included)\n",
    "      - INTRA class (10:00–12:00)\n",
    "      - POST class (16:01–19:59) (separate event stream, not in GLOBAL)\n",
    "\n",
    "    ✅ GLOBAL priority:\n",
    "      BLUE_HARD > ARK_HARD > PRINT_HARD > BLUE_SOFT > ARK_SOFT > PRINT_SOFT > OPEN_HARD > OPEN_SOFT > NONE\n",
    "\n",
    "    ✅ BEST_PARAMS:\n",
    "      - best_windows_any stitched for ALL classes:\n",
    "        blue/ark/print/open/global/intra/post, each per sign (pos/neg)\n",
    "      - uses ANY = hard+soft normalization ratio, thresholds total>=4, rate>=0.6\n",
    "\n",
    "    ✅ IMPORTANT SEMANTICS:\n",
    "      - BLUE/ARK/PRINT/OPEN do NOT mute each other. They all get their own hard/soft/none outcome.\n",
    "      - PRE event is finalized after OPEN window (same as before).\n",
    "      - BLUE has its OWN peak (frozen until 03:59) and soft is evaluated vs BLUE peak.\n",
    "      - ARK/PRINT/OPEN use PRE peak frozen until 09:29.\n",
    "\n",
    "    ✅ PERFORMANCE PATCHES (no semantic changes):\n",
    "      - gzip outputs: .jsonl -> .jsonl.gz (if path endswith .gz)\n",
    "      - vectorized dt/dev parsing + ignored window filtering before loop\n",
    "      - avoid parse_dt()/hhmm()/is_ignored_time() per row\n",
    "      - reduce gc.collect() frequency\n",
    "      - optional pyarrow iter_batches() for parquet\n",
    "    \"\"\"\n",
    "    import os, gc, json, time, math, gzip\n",
    "    from collections import deque, defaultdict, Counter\n",
    "    from datetime import datetime, timedelta\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # ---------------- defaults for best rules (kept) ----------------\n",
    "    if best_rules is None:\n",
    "        best_rules = {\n",
    "            \"sigma_any\":  {\"min_rate\": 0.60, \"min_total\": 20, \"top_n\": 3},\n",
    "            \"sigma_hard\": {\"min_rate\": 0.55, \"min_total\": 20, \"top_n\": 3},\n",
    "            \"sigma_soft\": {\"min_rate\": 0.60, \"min_total\": 15, \"top_n\": 3},\n",
    "\n",
    "            \"bench_any\":  {\"min_rate\": 0.58, \"min_total\": 25, \"top_n\": 3},\n",
    "            \"bench_hard\": {\"min_rate\": 0.52, \"min_total\": 25, \"top_n\": 3},\n",
    "            \"bench_soft\": {\"min_rate\": 0.60, \"min_total\": 20, \"top_n\": 3},\n",
    "\n",
    "            \"soft_peak_rate\": {\"min_rate\": 0.55, \"min_total\": 15, \"top_n\": 3},\n",
    "            \"soft_low_rate\":  {\"min_rate\": 0.55, \"min_total\": 15, \"top_n\": 3},\n",
    "\n",
    "            \"start_band_any\": {\"min_rate\": 0.60, \"min_total\": 20, \"top_n\": 3},\n",
    "        }\n",
    "\n",
    "    # ---------------- gzip-aware open ----------------\n",
    "    def _open_text(path: str, mode: str = \"wt\"):\n",
    "        # mode expected: \"wt\" or \"at\"\n",
    "        if str(path).lower().endswith(\".gz\"):\n",
    "            return gzip.open(\n",
    "                path,\n",
    "                mode,\n",
    "                encoding=\"utf-8\",\n",
    "                newline=\"\\n\",\n",
    "                compresslevel=6,  # баланс швидкість/розмір\n",
    "            )\n",
    "        return open(path, mode.replace(\"t\", \"\"), encoding=\"utf-8\", newline=\"\\n\")\n",
    "\n",
    "    Path(output_onefile_jsonl).parent.mkdir(parents=True, exist_ok=True)\n",
    "    Path(output_summary_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    Path(output_best_params_jsonl).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    onefile_f = _open_text(output_onefile_jsonl, \"wt\")\n",
    "\n",
    "    summary_cols = [\n",
    "        \"ticker\", \"bench\", \"events_total\",\n",
    "        \"events_pre_total\", \"events_intra_total\", \"events_post_total\",\n",
    "\n",
    "        \"blue_any_rate\", \"blue_hard_rate\", \"blue_soft_rate\",\n",
    "        \"ark_any_rate\", \"ark_hard_rate\", \"ark_soft_rate\",\n",
    "        \"print_any_rate\", \"print_hard_rate\", \"print_soft_rate\",\n",
    "        \"open_any_rate\", \"open_hard_rate\", \"open_soft_rate\",\n",
    "        \"global_any_rate\", \"global_hard_rate\", \"global_soft_rate\",\n",
    "        \"intra_any_rate\", \"intra_hard_rate\", \"intra_soft_rate\",\n",
    "        \"post_any_rate\", \"post_hard_rate\", \"post_soft_rate\",\n",
    "\n",
    "        \"corr\", \"beta\", \"sigma\",\n",
    "    ]\n",
    "    pd.DataFrame(columns=summary_cols).to_csv(output_summary_csv, index=False, mode=\"w\")\n",
    "\n",
    "    best_params_f = _open_text(output_best_params_jsonl, \"wt\")\n",
    "    best_params_f.write(json.dumps({\n",
    "        \"meta\": {\"version\": \"v12+blue+post\", \"generated_at\": datetime.utcnow().isoformat() + \"Z\"}\n",
    "    }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    # ---------------- helpers ----------------\n",
    "    def _json_safe(x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        if isinstance(x, (np.floating, float)):\n",
    "            if np.isnan(x) or np.isinf(x):\n",
    "                return None\n",
    "            return float(x)\n",
    "        if isinstance(x, (np.integer, int)):\n",
    "            return int(x)\n",
    "        if isinstance(x, (np.bool_, bool)):\n",
    "            return bool(x)\n",
    "        if isinstance(x, (pd.Timestamp,)):\n",
    "            return x.isoformat()\n",
    "        if isinstance(x, (datetime,)):\n",
    "            return x.isoformat()\n",
    "        return x\n",
    "\n",
    "    def is_finite_num(x) -> bool:\n",
    "        try:\n",
    "            return np.isfinite(float(x))\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def as_float_or_nan(x) -> float:\n",
    "        try:\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    def hhmm(dt_obj):\n",
    "        return (dt_obj.hour, dt_obj.minute) if isinstance(dt_obj, datetime) else None\n",
    "\n",
    "    def in_range(t, a, b):\n",
    "        return (t is not None) and (a <= t <= b)\n",
    "\n",
    "    def _dt_iso(x):\n",
    "        return x.isoformat() if isinstance(x, datetime) else None\n",
    "\n",
    "    def floor_to_band(dt_obj: datetime, minutes: int) -> str:\n",
    "        if not isinstance(dt_obj, datetime):\n",
    "            return None\n",
    "        m = (dt_obj.minute // minutes) * minutes\n",
    "        start = dt_obj.replace(minute=m, second=0, microsecond=0)\n",
    "        end = start + timedelta(minutes=minutes)\n",
    "        return f\"{start.hour:02d}:{start.minute:02d}-{end.hour:02d}:{end.minute:02d}\"\n",
    "\n",
    "    # ---------------- time windows ----------------\n",
    "    BLUE_FROM = (0, 1)\n",
    "    BLUE_TO   = (3, 59)\n",
    "\n",
    "    ARK_FROM = (0, 5)\n",
    "    ARK_TO   = (9, 29)\n",
    "\n",
    "    PRINT_FROM = (9, 30)\n",
    "    PRINT_TO   = (9, 35)\n",
    "\n",
    "    OPEN_FROM  = (9, 31)\n",
    "    OPEN_TO    = (9, 40)\n",
    "\n",
    "    INTRA_FROM = (10, 0)\n",
    "    INTRA_TO   = (12, 0)\n",
    "\n",
    "    POST_FROM  = (16, 1)\n",
    "    POST_TO    = (19, 59)\n",
    "\n",
    "    # ✅ ignored windows (vectorized filtering uses these exact bounds, inclusive)\n",
    "    IGNORE_WINDOWS = [((3, 58), (4, 5)), ((7, 58), (8, 5))]\n",
    "\n",
    "    def is_ignored_time(t):\n",
    "        return any(in_range(t, a, b) for a, b in IGNORE_WINDOWS)\n",
    "\n",
    "    # ---------------- binning ----------------\n",
    "    def _clamp(v, lo, hi):\n",
    "        return max(lo, min(hi, v))\n",
    "\n",
    "    def sigma_bin(abs_sigma):\n",
    "        if not is_finite_num(abs_sigma):\n",
    "            return None\n",
    "        v = float(abs_sigma)\n",
    "        v = _clamp(v, sigma_bin_min, sigma_bin_max)\n",
    "        b = round(np.floor(v / sigma_bin_step) * sigma_bin_step, 1)\n",
    "        return f\"{b:.1f}\"\n",
    "\n",
    "    def bench_bin(val):\n",
    "        if not is_finite_num(val):\n",
    "            return None\n",
    "        v = float(val)\n",
    "        v = _clamp(v, bench_bin_min, bench_bin_max)\n",
    "        b = round(np.floor(v / bench_bin_step) * bench_bin_step, 1)\n",
    "        return f\"{b:.1f}\"\n",
    "\n",
    "    def _score(rate: float, total: int) -> float:\n",
    "        return float(rate) * math.log1p(int(total))\n",
    "\n",
    "    # ---- “simple ANY windows” selection (rate>=0.6 & total>=4) ----\n",
    "    def stitch_numeric_bin_intervals_from_any(\n",
    "        bin_counts: dict, *, step: float, min_total: int = 4, min_rate: float = 0.6\n",
    "    ):\n",
    "        eligible = []\n",
    "        for b_str, st in (bin_counts or {}).items():\n",
    "            try:\n",
    "                b = float(b_str)\n",
    "            except Exception:\n",
    "                continue\n",
    "            total = int(st.get(\"total\", 0))\n",
    "            if total < min_total:\n",
    "                continue\n",
    "            any_ = int(st.get(\"hard\", 0)) + int(st.get(\"soft\", 0))\n",
    "            rate = any_ / total if total else 0.0\n",
    "            if rate >= min_rate:\n",
    "                eligible.append(b)\n",
    "\n",
    "        eligible.sort()\n",
    "        if not eligible:\n",
    "            return []\n",
    "\n",
    "        intervals = []\n",
    "        lo = hi = eligible[0]\n",
    "        for b in eligible[1:]:\n",
    "            if abs(b - (hi + step)) <= 1e-9:\n",
    "                hi = b\n",
    "            else:\n",
    "                intervals.append((lo, hi))\n",
    "                lo = hi = b\n",
    "        intervals.append((lo, hi))\n",
    "\n",
    "        out = []\n",
    "        for lo, hi in intervals:\n",
    "            tot = hard = soft = none = 0\n",
    "            k = lo\n",
    "            while k <= hi + 1e-9:\n",
    "                ks = f\"{k:.1f}\"\n",
    "                st = (bin_counts or {}).get(ks)\n",
    "                if st:\n",
    "                    tot += int(st.get(\"total\", 0))\n",
    "                    hard += int(st.get(\"hard\", 0))\n",
    "                    soft += int(st.get(\"soft\", 0))\n",
    "                    none += int(st.get(\"none\", 0))\n",
    "                k = round(k + step, 10)\n",
    "            if tot <= 0:\n",
    "                continue\n",
    "            rate = (hard + soft) / tot\n",
    "            if tot >= min_total and rate >= min_rate:\n",
    "                out.append({\n",
    "                    \"lo\": round(lo, 2),\n",
    "                    \"hi\": round(hi, 2),\n",
    "                    \"total\": int(tot),\n",
    "                    \"hard\": int(hard),\n",
    "                    \"soft\": int(soft),\n",
    "                    \"none\": int(none),\n",
    "                    \"rate\": float(rate),\n",
    "                    \"score\": _score(rate, tot),\n",
    "                })\n",
    "\n",
    "        out.sort(key=lambda x: (x[\"score\"], x[\"total\"]), reverse=True)\n",
    "        return out\n",
    "\n",
    "    def stitch_timeband_intervals_from_any(\n",
    "        band_counts: dict, *, min_total: int = 4, min_rate: float = 0.6\n",
    "    ):\n",
    "        def band_key_to_minutes(k: str):\n",
    "            try:\n",
    "                a, _b = k.split(\"-\")\n",
    "                h1, m1 = map(int, a.split(\":\"))\n",
    "                return h1 * 60 + m1\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "        items = []\n",
    "        for k, st in (band_counts or {}).items():\n",
    "            tot = int(st.get(\"total\", 0))\n",
    "            if tot < min_total:\n",
    "                continue\n",
    "            any_ = int(st.get(\"hard\", 0)) + int(st.get(\"soft\", 0))\n",
    "            rate = any_ / tot if tot else 0.0\n",
    "            if rate >= min_rate:\n",
    "                km = band_key_to_minutes(k)\n",
    "                if km is not None:\n",
    "                    items.append((km, k))\n",
    "        items.sort()\n",
    "        if not items:\n",
    "            return []\n",
    "\n",
    "        stitched_groups = []\n",
    "        cur = [items[0][1]]\n",
    "        for _, k in items[1:]:\n",
    "            prev = cur[-1]\n",
    "            try:\n",
    "                prev_end = prev.split(\"-\")[1]\n",
    "                k_start = k.split(\"-\")[0]\n",
    "                if prev_end == k_start:\n",
    "                    cur.append(k)\n",
    "                else:\n",
    "                    stitched_groups.append(cur)\n",
    "                    cur = [k]\n",
    "            except Exception:\n",
    "                stitched_groups.append(cur)\n",
    "                cur = [k]\n",
    "        stitched_groups.append(cur)\n",
    "\n",
    "        stitched = []\n",
    "        for bands in stitched_groups:\n",
    "            tot = hard = soft = none = 0\n",
    "            for b in bands:\n",
    "                st = (band_counts or {}).get(b, {})\n",
    "                tot += int(st.get(\"total\", 0))\n",
    "                hard += int(st.get(\"hard\", 0))\n",
    "                soft += int(st.get(\"soft\", 0))\n",
    "                none += int(st.get(\"none\", 0))\n",
    "            if tot <= 0:\n",
    "                continue\n",
    "            rate = (hard + soft) / tot\n",
    "            if tot >= min_total and rate >= min_rate:\n",
    "                stitched.append({\n",
    "                    \"from\": bands[0],\n",
    "                    \"to\": bands[-1],\n",
    "                    \"bands\": bands,\n",
    "                    \"total\": int(tot),\n",
    "                    \"hard\": int(hard),\n",
    "                    \"soft\": int(soft),\n",
    "                    \"none\": int(none),\n",
    "                    \"rate\": float(rate),\n",
    "                    \"score\": _score(rate, tot),\n",
    "                })\n",
    "        stitched.sort(key=lambda x: (x[\"score\"], x[\"total\"]), reverse=True)\n",
    "        return stitched\n",
    "\n",
    "    # ---------------- global label priority (GLOBAL only) ----------------\n",
    "    GLOBAL_PRIORITY = [\n",
    "        \"BLUE_HARD\",\n",
    "        \"ARK_HARD\",\n",
    "        \"PRINT_HARD\",\n",
    "        \"BLUE_SOFT\",\n",
    "        \"ARK_SOFT\",\n",
    "        \"PRINT_SOFT\",\n",
    "        \"OPEN_HARD\",\n",
    "        \"OPEN_SOFT\",\n",
    "        \"NONE\",\n",
    "    ]\n",
    "\n",
    "    def compute_global_label(blue_status, ark_status, print_status, open_status):\n",
    "        if blue_status == \"hard\":\n",
    "            return \"BLUE_HARD\"\n",
    "        if ark_status == \"hard\":\n",
    "            return \"ARK_HARD\"\n",
    "        if print_status == \"hard\":\n",
    "            return \"PRINT_HARD\"\n",
    "        if blue_status == \"soft\":\n",
    "            return \"BLUE_SOFT\"\n",
    "        if ark_status == \"soft\":\n",
    "            return \"ARK_SOFT\"\n",
    "        if print_status == \"soft\":\n",
    "            return \"PRINT_SOFT\"\n",
    "        if open_status == \"hard\":\n",
    "            return \"OPEN_HARD\"\n",
    "        if open_status == \"soft\":\n",
    "            return \"OPEN_SOFT\"\n",
    "        return \"NONE\"\n",
    "\n",
    "    # ---------------- per-ticker state ----------------\n",
    "    cur_ticker = None\n",
    "    cur_day = None\n",
    "\n",
    "    bench_name_seen = None\n",
    "    static_triplet_set = False\n",
    "    corr_static = beta_static = sigma_static = None\n",
    "\n",
    "    # optional heavy buffers\n",
    "    pre_events_buf = deque(maxlen=max_events_per_ticker)\n",
    "    intra_events_buf = deque(maxlen=max_events_per_ticker)\n",
    "    post_events_buf = deque(maxlen=max_events_per_ticker)\n",
    "\n",
    "    # counts per class\n",
    "    counts_pre = {\n",
    "        \"blue\": Counter(),\n",
    "        \"ark\": Counter(),\n",
    "        \"print\": Counter(),\n",
    "        \"open\": Counter(),\n",
    "        \"global\": Counter(),\n",
    "    }\n",
    "    global_labels_counter = Counter()\n",
    "    counts_intra = {\"intra\": Counter()}\n",
    "    counts_post = {\"post\": Counter()}\n",
    "\n",
    "    # sigma bins: class -> sign -> bin -> Counter(total/hard/soft/none)\n",
    "    def make_sigma_bins_map(classes):\n",
    "        m = {}\n",
    "        for c in classes:\n",
    "            m[c] = {\"pos\": defaultdict(lambda: Counter()), \"neg\": defaultdict(lambda: Counter())}\n",
    "        return m\n",
    "\n",
    "    sigma_bins_pre = make_sigma_bins_map([\"blue\", \"ark\", \"print\", \"open\", \"global\"])\n",
    "    sigma_bins_intra = make_sigma_bins_map([\"intra\"])\n",
    "    sigma_bins_post = make_sigma_bins_map([\"post\"])\n",
    "\n",
    "    # bench bins\n",
    "    def make_bench_bins_map(classes):\n",
    "        out = {}\n",
    "        for c in classes:\n",
    "            out[c] = {\n",
    "                \"start\": {\"pos\": defaultdict(lambda: Counter()), \"neg\": defaultdict(lambda: Counter())},\n",
    "                \"peak\":  {\"pos\": defaultdict(lambda: Counter()), \"neg\": defaultdict(lambda: Counter())},\n",
    "                \"norm\":  {\"pos\": defaultdict(lambda: Counter()), \"neg\": defaultdict(lambda: Counter())},\n",
    "            }\n",
    "        return out\n",
    "\n",
    "    bench_bins_pre = make_bench_bins_map([\"blue\", \"ark\", \"print\", \"open\", \"global\"])\n",
    "    bench_bins_intra = make_bench_bins_map([\"intra\"])\n",
    "    bench_bins_post = make_bench_bins_map([\"post\"])\n",
    "\n",
    "    # time bands (OLD ones kept) — PRE/INTRA/POST each\n",
    "    start_bands_pre_total = Counter()\n",
    "    start_bands_pre_any   = Counter()\n",
    "    start_bands_pre_hard  = Counter()\n",
    "    start_bands_pre_soft  = Counter()\n",
    "    norm_bands_pre_any   = Counter()\n",
    "    norm_bands_pre_hard  = Counter()\n",
    "    norm_bands_pre_soft  = Counter()\n",
    "\n",
    "    start_bands_intra_total = Counter()\n",
    "    start_bands_intra_any   = Counter()\n",
    "    start_bands_intra_hard  = Counter()\n",
    "    start_bands_intra_soft  = Counter()\n",
    "    norm_bands_intra_any   = Counter()\n",
    "    norm_bands_intra_hard  = Counter()\n",
    "    norm_bands_intra_soft  = Counter()\n",
    "\n",
    "    start_bands_post_total = Counter()\n",
    "    start_bands_post_any   = Counter()\n",
    "    start_bands_post_hard  = Counter()\n",
    "    start_bands_post_soft  = Counter()\n",
    "    norm_bands_post_any   = Counter()\n",
    "    norm_bands_post_hard  = Counter()\n",
    "    norm_bands_post_soft  = Counter()\n",
    "\n",
    "    # NEW: time bands per class+sign with total/hard/soft/none\n",
    "    def make_timeband_map(classes):\n",
    "        out = {}\n",
    "        for c in classes:\n",
    "            out[c] = {\n",
    "                \"start\": {\"pos\": defaultdict(lambda: Counter()), \"neg\": defaultdict(lambda: Counter())},\n",
    "                \"norm\":  {\"pos\": defaultdict(lambda: Counter()), \"neg\": defaultdict(lambda: Counter())},\n",
    "            }\n",
    "        return out\n",
    "\n",
    "    timebands_pre_by_class_sign = make_timeband_map([\"blue\", \"ark\", \"print\", \"open\", \"global\"])\n",
    "    timebands_intra_by_class_sign = make_timeband_map([\"intra\"])\n",
    "    timebands_post_by_class_sign = make_timeband_map([\"post\"])\n",
    "\n",
    "    # ✅ last3 examples per class AND per sign\n",
    "    def make_last3_map(classes):\n",
    "        return {c: {\"pos\": deque(maxlen=3), \"neg\": deque(maxlen=3)} for c in classes}\n",
    "\n",
    "    last3_examples = make_last3_map([\"blue\", \"ark\", \"print\", \"open\", \"global\", \"intra\", \"post\"])\n",
    "\n",
    "    # RECENT by DAYS (kept)\n",
    "    recent_days = deque(maxlen=10)  # day strings YYYY-MM-DD\n",
    "    recent_by_day = {}  # day -> {\"print\":..., \"peak\":...}\n",
    "\n",
    "    last5_print_days_pos = deque(maxlen=5)\n",
    "    last5_print_days_neg = deque(maxlen=5)\n",
    "\n",
    "    last5_peak_days_pos = deque(maxlen=5)\n",
    "    last5_peak_days_neg = deque(maxlen=5)\n",
    "\n",
    "    # HARD delays (kept + blue/post)\n",
    "    hard_delay_sum = Counter()\n",
    "    hard_delay_cnt = Counter()\n",
    "\n",
    "    # mean peak_abs for globally normalized events (kept) — now picks BLUE peak if global is BLUE\n",
    "    global_norm_peak_sum = {\"pos\": 0.0, \"neg\": 0.0}\n",
    "    global_norm_peak_cnt = {\"pos\": 0, \"neg\": 0}\n",
    "\n",
    "    # OPEN dev_sig series for last10 days (downsample by seconds)\n",
    "    open_series_by_day = {}\n",
    "\n",
    "    # ---------------- reset ticker ----------------\n",
    "    def reset_ticker_state():\n",
    "        nonlocal bench_name_seen, static_triplet_set, corr_static, beta_static, sigma_static\n",
    "        nonlocal pre_events_buf, intra_events_buf, post_events_buf\n",
    "        nonlocal counts_pre, global_labels_counter, counts_intra, counts_post\n",
    "        nonlocal sigma_bins_pre, sigma_bins_intra, sigma_bins_post\n",
    "        nonlocal bench_bins_pre, bench_bins_intra, bench_bins_post\n",
    "        nonlocal start_bands_pre_total, start_bands_pre_any, start_bands_pre_hard, start_bands_pre_soft\n",
    "        nonlocal norm_bands_pre_any, norm_bands_pre_hard, norm_bands_pre_soft\n",
    "        nonlocal start_bands_intra_total, start_bands_intra_any, start_bands_intra_hard, start_bands_intra_soft\n",
    "        nonlocal norm_bands_intra_any, norm_bands_intra_hard, norm_bands_intra_soft\n",
    "        nonlocal start_bands_post_total, start_bands_post_any, start_bands_post_hard, start_bands_post_soft\n",
    "        nonlocal norm_bands_post_any, norm_bands_post_hard, norm_bands_post_soft\n",
    "        nonlocal timebands_pre_by_class_sign, timebands_intra_by_class_sign, timebands_post_by_class_sign\n",
    "        nonlocal last3_examples\n",
    "        nonlocal recent_days, recent_by_day, last5_print_days_pos, last5_print_days_neg\n",
    "        nonlocal last5_peak_days_pos, last5_peak_days_neg\n",
    "        nonlocal hard_delay_sum, hard_delay_cnt\n",
    "        nonlocal global_norm_peak_sum, global_norm_peak_cnt\n",
    "        nonlocal open_series_by_day\n",
    "\n",
    "        bench_name_seen = None\n",
    "        static_triplet_set = False\n",
    "        corr_static = beta_static = sigma_static = None\n",
    "\n",
    "        pre_events_buf = deque(maxlen=max_events_per_ticker)\n",
    "        intra_events_buf = deque(maxlen=max_events_per_ticker)\n",
    "        post_events_buf = deque(maxlen=max_events_per_ticker)\n",
    "\n",
    "        counts_pre = {\"blue\": Counter(), \"ark\": Counter(), \"print\": Counter(), \"open\": Counter(), \"global\": Counter()}\n",
    "        global_labels_counter = Counter()\n",
    "        counts_intra = {\"intra\": Counter()}\n",
    "        counts_post = {\"post\": Counter()}\n",
    "\n",
    "        sigma_bins_pre = make_sigma_bins_map([\"blue\", \"ark\", \"print\", \"open\", \"global\"])\n",
    "        sigma_bins_intra = make_sigma_bins_map([\"intra\"])\n",
    "        sigma_bins_post = make_sigma_bins_map([\"post\"])\n",
    "\n",
    "        bench_bins_pre = make_bench_bins_map([\"blue\", \"ark\", \"print\", \"open\", \"global\"])\n",
    "        bench_bins_intra = make_bench_bins_map([\"intra\"])\n",
    "        bench_bins_post = make_bench_bins_map([\"post\"])\n",
    "\n",
    "        start_bands_pre_total = Counter()\n",
    "        start_bands_pre_any   = Counter()\n",
    "        start_bands_pre_hard  = Counter()\n",
    "        start_bands_pre_soft  = Counter()\n",
    "        norm_bands_pre_any   = Counter()\n",
    "        norm_bands_pre_hard  = Counter()\n",
    "        norm_bands_pre_soft  = Counter()\n",
    "\n",
    "        start_bands_intra_total = Counter()\n",
    "        start_bands_intra_any   = Counter()\n",
    "        start_bands_intra_hard  = Counter()\n",
    "        start_bands_intra_soft  = Counter()\n",
    "        norm_bands_intra_any   = Counter()\n",
    "        norm_bands_intra_hard  = Counter()\n",
    "        norm_bands_intra_soft  = Counter()\n",
    "\n",
    "        start_bands_post_total = Counter()\n",
    "        start_bands_post_any   = Counter()\n",
    "        start_bands_post_hard  = Counter()\n",
    "        start_bands_post_soft  = Counter()\n",
    "        norm_bands_post_any   = Counter()\n",
    "        norm_bands_post_hard  = Counter()\n",
    "        norm_bands_post_soft  = Counter()\n",
    "\n",
    "        timebands_pre_by_class_sign = make_timeband_map([\"blue\", \"ark\", \"print\", \"open\", \"global\"])\n",
    "        timebands_intra_by_class_sign = make_timeband_map([\"intra\"])\n",
    "        timebands_post_by_class_sign = make_timeband_map([\"post\"])\n",
    "\n",
    "        last3_examples = make_last3_map([\"blue\", \"ark\", \"print\", \"open\", \"global\", \"intra\", \"post\"])\n",
    "\n",
    "        recent_days = deque(maxlen=10)\n",
    "        recent_by_day = {}\n",
    "        last5_print_days_pos = deque(maxlen=5)\n",
    "        last5_print_days_neg = deque(maxlen=5)\n",
    "        last5_peak_days_pos = deque(maxlen=5)\n",
    "        last5_peak_days_neg = deque(maxlen=5)\n",
    "\n",
    "        hard_delay_sum = Counter()\n",
    "        hard_delay_cnt = Counter()\n",
    "\n",
    "        global_norm_peak_sum = {\"pos\": 0.0, \"neg\": 0.0}\n",
    "        global_norm_peak_cnt = {\"pos\": 0, \"neg\": 0}\n",
    "\n",
    "        open_series_by_day = {}\n",
    "\n",
    "    # ---------------- common utils ----------------\n",
    "\n",
    "    def parse_dt(x):\n",
    "        \"\"\"Уніфіковано привести вхід до datetime або None.\n",
    "        Підтримує: datetime, pd.Timestamp, ISO-рядки; повертає Python datetime (може бути tz-aware) або None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if x is None:\n",
    "                return None\n",
    "            if isinstance(x, datetime):\n",
    "                return x\n",
    "            # pandas поверне pd.Timestamp; встановлюємо utc=True щоб уникнути неоднозначностей\n",
    "            ts = pd.to_datetime(x, errors=\"coerce\", utc=True)\n",
    "            if pd.isna(ts):\n",
    "                return None\n",
    "            return ts.to_pydatetime()\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    \n",
    "    def push_last3_example(class_key, sign_key, kind, start_dt, end_dt, start_dev, end_dev, peak_dev,\n",
    "                           start_stock, end_stock, start_bench, end_bench, start_time=None, end_time=None):\n",
    "        d = start_dt.date().isoformat() if isinstance(start_dt, datetime) else None\n",
    "        last3_examples[class_key][sign_key].appendleft({\n",
    "            \"date\": d,\n",
    "            \"dt\": _dt_iso(start_dt),\n",
    "            \"kind\": kind,  # \"hard\"/\"soft\"\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"start_dev\": _json_safe(start_dev),\n",
    "            \"peak_dev\": _json_safe(peak_dev),\n",
    "            \"end_dev\": _json_safe(end_dev),\n",
    "            \"stock_start\": _json_safe(start_stock),\n",
    "            \"stock_end\": _json_safe(end_stock),\n",
    "            \"bench_start\": _json_safe(start_bench),\n",
    "            \"bench_end\": _json_safe(end_bench),\n",
    "        })\n",
    "\n",
    "    def update_sigma_bins(map_ref, class_key, sign_key, abs_peak_sigma, outcome_kind):\n",
    "        b = sigma_bin(abs_peak_sigma)\n",
    "        if b is None:\n",
    "            return\n",
    "        st = map_ref[class_key][sign_key][b]\n",
    "        st[\"total\"] += 1\n",
    "        if outcome_kind not in (\"hard\", \"soft\", \"none\"):\n",
    "            outcome_kind = \"none\"\n",
    "        st[outcome_kind] += 1\n",
    "\n",
    "    def update_bench_bins(map_ref, class_key, which, sign_key, bench_value, outcome_kind):\n",
    "        b = bench_bin(bench_value)\n",
    "        if b is None:\n",
    "            return\n",
    "        st = map_ref[class_key][which][sign_key][b]\n",
    "        st[\"total\"] += 1\n",
    "        if outcome_kind not in (\"hard\", \"soft\", \"none\"):\n",
    "            outcome_kind = \"none\"\n",
    "        st[outcome_kind] += 1\n",
    "\n",
    "    def update_timeband_by_class_sign(map_ref, class_key, which, sign_key, band_key, outcome_kind):\n",
    "        if not band_key:\n",
    "            return\n",
    "        st = map_ref[class_key][which][sign_key][band_key]\n",
    "        st[\"total\"] += 1\n",
    "        if outcome_kind not in (\"hard\", \"soft\", \"none\"):\n",
    "            outcome_kind = \"none\"\n",
    "        st[outcome_kind] += 1\n",
    "        _ = st[\"hard\"]; _ = st[\"soft\"]; _ = st[\"none\"]\n",
    "\n",
    "    def class_rates(counter: Counter):\n",
    "        total = int(sum(counter.values()))\n",
    "        hard = int(counter.get(\"hard\", 0))\n",
    "        soft = int(counter.get(\"soft\", 0))\n",
    "        none = int(counter.get(\"none\", 0))\n",
    "        any_ = hard + soft\n",
    "        return {\n",
    "            \"total\": total,\n",
    "            \"hard\": hard,\n",
    "            \"soft\": soft,\n",
    "            \"none\": none,\n",
    "            \"rate_any\": (any_ / total) if total else None,\n",
    "            \"rate_hard\": (hard / total) if total else None,\n",
    "            \"rate_soft\": (soft / total) if total else None,\n",
    "            \"hard_share_in_norm\": (hard / (hard + soft)) if (hard + soft) else None,\n",
    "        }\n",
    "\n",
    "    def add_hard_delay(key: str, start_dt: datetime, hard_dt: datetime):\n",
    "        if isinstance(start_dt, datetime) and isinstance(hard_dt, datetime) and hard_dt >= start_dt:\n",
    "            hard_delay_sum[key] += (hard_dt - start_dt).total_seconds()\n",
    "            hard_delay_cnt[key] += 1\n",
    "\n",
    "    def avg_hard_delay(key: str):\n",
    "        c = int(hard_delay_cnt.get(key, 0))\n",
    "        if c <= 0:\n",
    "            return None\n",
    "        return float(hard_delay_sum.get(key, 0.0)) / c\n",
    "\n",
    "    # ---------------- PRE event state ----------------\n",
    "    pre_active = False\n",
    "    pre_id = 0\n",
    "\n",
    "    pre_start_dt = None\n",
    "    pre_start_dev = np.nan\n",
    "    pre_start_sign = 0\n",
    "    pre_start_stock = np.nan\n",
    "    pre_start_bench = np.nan\n",
    "\n",
    "    # PRE peak frozen until 09:29 (for ARK/PRINT/OPEN/GLOBAL)\n",
    "    pre_peak_abs = 0.0\n",
    "    pre_peak_signed = 0.0\n",
    "    pre_peak_dt = None\n",
    "    pre_peak_stock = np.nan\n",
    "    pre_peak_bench = np.nan\n",
    "\n",
    "    pre_post_peak_low_abs = np.inf\n",
    "\n",
    "    # BLUE peak frozen until 03:59 (for BLUE soft)\n",
    "    blue_peak_abs = 0.0\n",
    "    blue_peak_signed = 0.0\n",
    "    blue_peak_dt = None\n",
    "    blue_peak_stock = np.nan\n",
    "    blue_peak_bench = np.nan\n",
    "\n",
    "    blue_hard_dt = None\n",
    "    blue_hard_val = np.nan\n",
    "    blue_hard_stock = np.nan\n",
    "    blue_hard_bench = np.nan\n",
    "\n",
    "    blue_soft_found = False\n",
    "    blue_soft_dt = None\n",
    "    blue_soft_val = np.nan\n",
    "    blue_soft_stock = np.nan\n",
    "    blue_soft_bench = np.nan\n",
    "\n",
    "    ark_hard_dt = None\n",
    "    ark_hard_val = np.nan\n",
    "    ark_hard_stock = np.nan\n",
    "    ark_hard_bench = np.nan\n",
    "\n",
    "    ark_soft_found = False\n",
    "    ark_soft_dt = None\n",
    "    ark_soft_val = np.nan\n",
    "    ark_soft_stock = np.nan\n",
    "    ark_soft_bench = np.nan\n",
    "\n",
    "    print_first_dt = None\n",
    "    print_first_val = np.nan\n",
    "    print_first_stock = np.nan\n",
    "    print_first_bench = np.nan\n",
    "\n",
    "    open_hard_dt = None\n",
    "    open_hard_val = np.nan\n",
    "    open_hard_stock = np.nan\n",
    "    open_hard_bench = np.nan\n",
    "\n",
    "    open_soft_found = False\n",
    "    open_soft_dt = None\n",
    "    open_soft_val = np.nan\n",
    "    open_soft_stock = np.nan\n",
    "    open_soft_bench = np.nan\n",
    "\n",
    "    def reset_pre_event():\n",
    "        nonlocal pre_active, pre_start_dt, pre_start_dev, pre_start_sign, pre_start_stock, pre_start_bench\n",
    "        nonlocal pre_peak_abs, pre_peak_signed, pre_peak_dt, pre_peak_stock, pre_peak_bench\n",
    "        nonlocal pre_post_peak_low_abs\n",
    "        nonlocal blue_peak_abs, blue_peak_signed, blue_peak_dt, blue_peak_stock, blue_peak_bench\n",
    "        nonlocal blue_hard_dt, blue_hard_val, blue_hard_stock, blue_hard_bench\n",
    "        nonlocal blue_soft_found, blue_soft_dt, blue_soft_val, blue_soft_stock, blue_soft_bench\n",
    "        nonlocal ark_hard_dt, ark_hard_val, ark_hard_stock, ark_hard_bench\n",
    "        nonlocal ark_soft_found, ark_soft_dt, ark_soft_val, ark_soft_stock, ark_soft_bench\n",
    "        nonlocal print_first_dt, print_first_val, print_first_stock, print_first_bench\n",
    "        nonlocal open_hard_dt, open_hard_val, open_hard_stock, open_hard_bench\n",
    "        nonlocal open_soft_found, open_soft_dt, open_soft_val, open_soft_stock, open_soft_bench\n",
    "\n",
    "        pre_active = False\n",
    "        pre_start_dt = None\n",
    "        pre_start_dev = np.nan\n",
    "        pre_start_sign = 0\n",
    "        pre_start_stock = np.nan\n",
    "        pre_start_bench = np.nan\n",
    "\n",
    "        pre_peak_abs = 0.0\n",
    "        pre_peak_signed = 0.0\n",
    "        pre_peak_dt = None\n",
    "        pre_peak_stock = np.nan\n",
    "        pre_peak_bench = np.nan\n",
    "\n",
    "        pre_post_peak_low_abs = np.inf\n",
    "\n",
    "        blue_peak_abs = 0.0\n",
    "        blue_peak_signed = 0.0\n",
    "        blue_peak_dt = None\n",
    "        blue_peak_stock = np.nan\n",
    "        blue_peak_bench = np.nan\n",
    "\n",
    "        blue_hard_dt = None\n",
    "        blue_hard_val = np.nan\n",
    "        blue_hard_stock = np.nan\n",
    "        blue_hard_bench = np.nan\n",
    "\n",
    "        blue_soft_found = False\n",
    "        blue_soft_dt = None\n",
    "        blue_soft_val = np.nan\n",
    "        blue_soft_stock = np.nan\n",
    "        blue_soft_bench = np.nan\n",
    "\n",
    "        ark_hard_dt = None\n",
    "        ark_hard_val = np.nan\n",
    "        ark_hard_stock = np.nan\n",
    "        ark_hard_bench = np.nan\n",
    "\n",
    "        ark_soft_found = False\n",
    "        ark_soft_dt = None\n",
    "        ark_soft_val = np.nan\n",
    "        ark_soft_stock = np.nan\n",
    "        ark_soft_bench = np.nan\n",
    "\n",
    "        print_first_dt = None\n",
    "        print_first_val = np.nan\n",
    "        print_first_stock = np.nan\n",
    "        print_first_bench = np.nan\n",
    "\n",
    "        open_hard_dt = None\n",
    "        open_hard_val = np.nan\n",
    "        open_hard_stock = np.nan\n",
    "        open_hard_bench = np.nan\n",
    "\n",
    "        open_soft_found = False\n",
    "        open_soft_dt = None\n",
    "        open_soft_val = np.nan\n",
    "        open_soft_stock = np.nan\n",
    "        open_soft_bench = np.nan\n",
    "\n",
    "    def start_pre_event(dt_now, dev_now, stock_pct, bench_pct):\n",
    "        nonlocal pre_active, pre_start_dt, pre_start_dev, pre_start_sign, pre_start_stock, pre_start_bench\n",
    "        nonlocal pre_peak_abs, pre_peak_signed, pre_peak_dt, pre_peak_stock, pre_peak_bench\n",
    "        nonlocal blue_peak_abs, blue_peak_signed, blue_peak_dt, blue_peak_stock, blue_peak_bench\n",
    "\n",
    "        pre_active = True\n",
    "        pre_start_dt = dt_now\n",
    "        pre_start_dev = float(dev_now)\n",
    "        pre_start_sign = 1 if float(dev_now) >= 0 else -1\n",
    "        pre_start_stock = stock_pct\n",
    "        pre_start_bench = bench_pct\n",
    "\n",
    "        # PRE peak init (shared)\n",
    "        pre_peak_abs = abs(float(dev_now))\n",
    "        pre_peak_signed = float(dev_now)\n",
    "        pre_peak_dt = dt_now\n",
    "        pre_peak_stock = stock_pct\n",
    "        pre_peak_bench = bench_pct\n",
    "\n",
    "        # BLUE peak init (so BLUE soft works even if event starts in BLUE)\n",
    "        blue_peak_abs = abs(float(dev_now))\n",
    "        blue_peak_signed = float(dev_now)\n",
    "        blue_peak_dt = dt_now\n",
    "        blue_peak_stock = stock_pct\n",
    "        blue_peak_bench = bench_pct\n",
    "\n",
    "    def pre_sign_key():\n",
    "        return \"pos\" if pre_start_sign > 0 else \"neg\"\n",
    "\n",
    "    def classify_print_with_frozen_peak(first_val):\n",
    "        if not is_finite_num(first_val):\n",
    "            return \"none\"\n",
    "        a = abs(float(first_val))\n",
    "        if a <= norm_thr:\n",
    "            return \"hard\"\n",
    "        if pre_peak_abs > 0 and a <= (float(pre_peak_abs) / float(soft_ratio)):\n",
    "            return \"soft\"\n",
    "        return \"none\"\n",
    "\n",
    "    def classify_blue():\n",
    "        if blue_hard_dt is not None and is_finite_num(blue_hard_val):\n",
    "            return \"hard\"\n",
    "        if blue_soft_found and blue_soft_dt is not None and is_finite_num(blue_soft_val):\n",
    "            return \"soft\"\n",
    "        return \"none\"\n",
    "\n",
    "    def classify_ark():\n",
    "        if ark_hard_dt is not None and is_finite_num(ark_hard_val):\n",
    "            return \"hard\"\n",
    "        if ark_soft_found and ark_soft_dt is not None and is_finite_num(ark_soft_val):\n",
    "            return \"soft\"\n",
    "        return \"none\"\n",
    "\n",
    "    def classify_open():\n",
    "        if open_hard_dt is not None and is_finite_num(open_hard_val):\n",
    "            return \"hard\"\n",
    "        if open_soft_found and open_soft_dt is not None and is_finite_num(open_soft_val):\n",
    "            return \"soft\"\n",
    "        return \"none\"\n",
    "\n",
    "    def capture_open_series(dt_now: datetime, dev_now: float):\n",
    "        if not isinstance(dt_now, datetime):\n",
    "            return\n",
    "        t = (dt_now.hour, dt_now.minute)\n",
    "        if not in_range(t, OPEN_FROM, OPEN_TO):\n",
    "            return\n",
    "\n",
    "        day_str = dt_now.date().isoformat()\n",
    "        store = open_series_by_day.get(day_str)\n",
    "        if store is None:\n",
    "            store = {}\n",
    "            open_series_by_day[day_str] = store\n",
    "\n",
    "        sec = max(1, int(open_series_downsample_seconds))\n",
    "        bucket_epoch = int(dt_now.timestamp() // sec) * sec\n",
    "        # use pandas to create tz-aware Timestamp consistently\n",
    "        bucket_dt = pd.Timestamp(bucket_epoch, unit=\"s\", tz=dt_now.tzinfo).to_pydatetime()\n",
    "        store[bucket_dt.isoformat()] = float(dev_now)\n",
    "\n",
    "    def pre_process_tick(dt_now, dev_now, stock_pct, bench_pct):\n",
    "        nonlocal pre_peak_abs, pre_peak_signed, pre_peak_dt, pre_peak_stock, pre_peak_bench\n",
    "        nonlocal pre_post_peak_low_abs\n",
    "\n",
    "        nonlocal blue_peak_abs, blue_peak_signed, blue_peak_dt, blue_peak_stock, blue_peak_bench\n",
    "        nonlocal blue_hard_dt, blue_hard_val, blue_hard_stock, blue_hard_bench\n",
    "        nonlocal blue_soft_found, blue_soft_dt, blue_soft_val, blue_soft_stock, blue_soft_bench\n",
    "\n",
    "        nonlocal ark_hard_dt, ark_hard_val, ark_hard_stock, ark_hard_bench\n",
    "        nonlocal ark_soft_found, ark_soft_dt, ark_soft_val, ark_soft_stock, ark_soft_bench\n",
    "\n",
    "        nonlocal print_first_dt, print_first_val, print_first_stock, print_first_bench\n",
    "\n",
    "        nonlocal open_hard_dt, open_hard_val, open_hard_stock, open_hard_bench\n",
    "        nonlocal open_soft_found, open_soft_dt, open_soft_val, open_soft_stock, open_soft_bench\n",
    "\n",
    "        t = (dt_now.hour, dt_now.minute)\n",
    "        cur_abs = abs(float(dev_now))\n",
    "\n",
    "        # capture open series (kept)\n",
    "        capture_open_series(dt_now, float(dev_now))\n",
    "\n",
    "        # ---------- BLUE processing inside 00:01–03:59 (parallel) ----------\n",
    "        if in_range(t, BLUE_FROM, BLUE_TO):\n",
    "            # BLUE peak frozen until 03:59\n",
    "            if cur_abs > float(blue_peak_abs):\n",
    "                blue_peak_abs = float(cur_abs)\n",
    "                blue_peak_signed = float(dev_now)\n",
    "                blue_peak_dt = dt_now\n",
    "                blue_peak_stock = stock_pct\n",
    "                blue_peak_bench = bench_pct\n",
    "                if blue_hard_dt is None:\n",
    "                    blue_soft_found = False\n",
    "                    blue_soft_dt = None\n",
    "                    blue_soft_val = np.nan\n",
    "                    blue_soft_stock = np.nan\n",
    "                    blue_soft_bench = np.nan\n",
    "\n",
    "            # BLUE HARD\n",
    "            if blue_hard_dt is None and cur_abs <= norm_thr:\n",
    "                blue_hard_dt = dt_now\n",
    "                blue_hard_val = float(dev_now)\n",
    "                blue_hard_stock = stock_pct\n",
    "                blue_hard_bench = bench_pct\n",
    "\n",
    "            # BLUE SOFT only if hard not yet, after BLUE peak\n",
    "            if (blue_hard_dt is None) and isinstance(blue_peak_dt, datetime) and (dt_now >= blue_peak_dt) and blue_peak_abs > 0:\n",
    "                if cur_abs <= (float(blue_peak_abs) / float(soft_ratio)):\n",
    "                    if (not blue_soft_found) or (dt_now < blue_soft_dt):\n",
    "                        blue_soft_found = True\n",
    "                        blue_soft_dt = dt_now\n",
    "                        blue_soft_val = float(dev_now)\n",
    "                        blue_soft_stock = stock_pct\n",
    "                        blue_soft_bench = bench_pct\n",
    "\n",
    "        # ---------- PRE peak (for ARK/PRINT/OPEN/GLOBAL) frozen until 09:29 ----------\n",
    "        if t <= ARK_TO:\n",
    "            if cur_abs > float(pre_peak_abs):\n",
    "                pre_peak_abs = float(cur_abs)\n",
    "                pre_peak_signed = float(dev_now)\n",
    "                pre_peak_dt = dt_now\n",
    "                pre_peak_stock = stock_pct\n",
    "                pre_peak_bench = bench_pct\n",
    "                if ark_hard_dt is None:\n",
    "                    ark_soft_found = False\n",
    "                    ark_soft_dt = None\n",
    "                    ark_soft_val = np.nan\n",
    "                    ark_soft_stock = np.nan\n",
    "                    ark_soft_bench = np.nan\n",
    "\n",
    "        # post-peak low abs after peak (kept)\n",
    "        if isinstance(pre_peak_dt, datetime) and dt_now >= pre_peak_dt:\n",
    "            if cur_abs < pre_post_peak_low_abs:\n",
    "                pre_post_peak_low_abs = cur_abs\n",
    "\n",
    "        # ARK HARD in [start..09:29]\n",
    "        if (ark_hard_dt is None) and (t <= ARK_TO):\n",
    "            if cur_abs <= norm_thr:\n",
    "                ark_hard_dt = dt_now\n",
    "                ark_hard_val = float(dev_now)\n",
    "                ark_hard_stock = stock_pct\n",
    "                ark_hard_bench = bench_pct\n",
    "\n",
    "        # ARK SOFT only if hard failed, in [peak_dt..09:29]\n",
    "        if (ark_hard_dt is None) and (t <= ARK_TO) and isinstance(pre_peak_dt, datetime):\n",
    "            if dt_now >= pre_peak_dt and pre_peak_abs > 0:\n",
    "                if cur_abs <= (float(pre_peak_abs) / float(soft_ratio)):\n",
    "                    if (not ark_soft_found) or (dt_now < ark_soft_dt):\n",
    "                        ark_soft_found = True\n",
    "                        ark_soft_dt = dt_now\n",
    "                        ark_soft_val = float(dev_now)\n",
    "                        ark_soft_stock = stock_pct\n",
    "                        ark_soft_bench = bench_pct\n",
    "\n",
    "        # PRINT first tick only in [09:30..09:35]\n",
    "        if (print_first_dt is None) and in_range(t, PRINT_FROM, PRINT_TO):\n",
    "            print_first_dt = dt_now\n",
    "            print_first_val = float(dev_now)\n",
    "            print_first_stock = stock_pct\n",
    "            print_first_bench = bench_pct\n",
    "\n",
    "        # OPEN scan in [09:31..09:40]\n",
    "        if in_range(t, OPEN_FROM, OPEN_TO):\n",
    "            if open_hard_dt is None and cur_abs <= norm_thr:\n",
    "                open_hard_dt = dt_now\n",
    "                open_hard_val = float(dev_now)\n",
    "                open_hard_stock = stock_pct\n",
    "                open_hard_bench = bench_pct\n",
    "\n",
    "            if open_hard_dt is None and pre_peak_abs > 0:\n",
    "                gate_dt = pre_peak_dt if isinstance(pre_peak_dt, datetime) else dt_now\n",
    "                open_gate = dt_now.replace(hour=OPEN_FROM[0], minute=OPEN_FROM[1], second=0, microsecond=0)\n",
    "                if gate_dt < open_gate:\n",
    "                    gate_dt = open_gate\n",
    "                if dt_now >= gate_dt:\n",
    "                    if cur_abs <= (float(pre_peak_abs) / float(soft_ratio)):\n",
    "                        if (not open_soft_found) or (dt_now < open_soft_dt):\n",
    "                            open_soft_found = True\n",
    "                            open_soft_dt = dt_now\n",
    "                            open_soft_val = float(dev_now)\n",
    "                            open_soft_stock = stock_pct\n",
    "                            open_soft_bench = bench_pct\n",
    "\n",
    "    def _ensure_recent_day(day_str: str):\n",
    "        if day_str not in recent_by_day:\n",
    "            recent_by_day[day_str] = {\"print\": None, \"peak\": None}\n",
    "        if (len(recent_days) == 0) or (recent_days[0] != day_str):\n",
    "            if day_str in recent_days:\n",
    "                recent_days.remove(day_str)\n",
    "            recent_days.appendleft(day_str)\n",
    "\n",
    "    def _update_recent_daily_print(day_str: str, print_dt: datetime, print_dev: float, peak_abs: float, peak_signed: float, first_sign: int):\n",
    "        snap = recent_by_day.get(day_str)\n",
    "        if snap is None:\n",
    "            recent_by_day[day_str] = {\"print\": None, \"peak\": None}\n",
    "            snap = recent_by_day[day_str]\n",
    "        if snap[\"print\"] is None:\n",
    "            snap[\"print\"] = {\n",
    "                \"dt\": _dt_iso(print_dt),\n",
    "                \"dev\": _json_safe(print_dev),\n",
    "                \"pre_peak_abs\": _json_safe(peak_abs),\n",
    "                \"pre_peak_signed\": _json_safe(peak_signed),\n",
    "                \"first_sign\": int(first_sign),\n",
    "            }\n",
    "\n",
    "    def _update_recent_daily_peak(day_str: str, peak_dt: datetime, peak_abs: float, peak_signed: float, first_sign: int):\n",
    "        snap = recent_by_day.get(day_str)\n",
    "        if snap is None:\n",
    "            recent_by_day[day_str] = {\"print\": None, \"peak\": None}\n",
    "            snap = recent_by_day[day_str]\n",
    "        cur = snap[\"peak\"]\n",
    "        if cur is None or (is_finite_num(peak_abs) and float(peak_abs) > float(cur.get(\"sigma_abs\", 0.0) or 0.0)):\n",
    "            snap[\"peak\"] = {\n",
    "                \"dt\": _dt_iso(peak_dt),\n",
    "                \"sigma_abs\": _json_safe(peak_abs),\n",
    "                \"sigma_signed\": _json_safe(peak_signed),\n",
    "                \"first_sign\": int(first_sign),\n",
    "            }\n",
    "\n",
    "    def finalize_pre_event(reason=\"window_end\"):\n",
    "        nonlocal pre_active, pre_id\n",
    "        nonlocal global_norm_peak_sum, global_norm_peak_cnt\n",
    "\n",
    "        if not pre_active:\n",
    "            return\n",
    "\n",
    "        blue_status  = classify_blue()\n",
    "        ark_status   = classify_ark()\n",
    "        print_status = classify_print_with_frozen_peak(print_first_val)\n",
    "        open_status  = classify_open()\n",
    "\n",
    "        global_label = compute_global_label(blue_status, ark_status, print_status, open_status)\n",
    "        if global_label.endswith(\"_HARD\"):\n",
    "            global_kind = \"hard\"\n",
    "        elif global_label.endswith(\"_SOFT\"):\n",
    "            global_kind = \"soft\"\n",
    "        else:\n",
    "            global_kind = \"none\"\n",
    "\n",
    "        sk = pre_sign_key()\n",
    "\n",
    "        # OLD start band counters (kept) — any/hard/soft across all pre classes (OR semantics)\n",
    "        sb_total = floor_to_band(pre_start_dt, start_band_minutes)\n",
    "        if sb_total:\n",
    "            start_bands_pre_total[sb_total] += 1\n",
    "            if (blue_status != \"none\") or (ark_status != \"none\") or (print_status != \"none\") or (open_status != \"none\"):\n",
    "                start_bands_pre_any[sb_total] += 1\n",
    "            if (blue_status == \"hard\") or (ark_status == \"hard\") or (print_status == \"hard\") or (open_status == \"hard\"):\n",
    "                start_bands_pre_hard[sb_total] += 1\n",
    "            if (blue_status == \"soft\") or (ark_status == \"soft\") or (print_status == \"soft\") or (open_status == \"soft\"):\n",
    "                start_bands_pre_soft[sb_total] += 1\n",
    "\n",
    "        # NEW per-class-sign start band counters\n",
    "        if sb_total:\n",
    "            update_timeband_by_class_sign(timebands_pre_by_class_sign, \"blue\", \"start\", sk, sb_total, blue_status)\n",
    "            update_timeband_by_class_sign(timebands_pre_by_class_sign, \"ark\", \"start\", sk, sb_total, ark_status)\n",
    "            update_timeband_by_class_sign(timebands_pre_by_class_sign, \"print\", \"start\", sk, sb_total, print_status)\n",
    "            update_timeband_by_class_sign(timebands_pre_by_class_sign, \"open\", \"start\", sk, sb_total, open_status)\n",
    "            update_timeband_by_class_sign(timebands_pre_by_class_sign, \"global\", \"start\", sk, sb_total, global_kind)\n",
    "\n",
    "        # counts (classes independent)\n",
    "        counts_pre[\"blue\"][blue_status] += 1\n",
    "        counts_pre[\"ark\"][ark_status] += 1\n",
    "        counts_pre[\"print\"][print_status] += 1\n",
    "        counts_pre[\"open\"][open_status] += 1\n",
    "        counts_pre[\"global\"][global_kind] += 1\n",
    "        global_labels_counter[global_label] += 1\n",
    "\n",
    "        # HARD delays (kept + blue)\n",
    "        if blue_status == \"hard\":\n",
    "            add_hard_delay(\"blue\", pre_start_dt, blue_hard_dt)\n",
    "        if ark_status == \"hard\":\n",
    "            add_hard_delay(\"ark\", pre_start_dt, ark_hard_dt)\n",
    "        if print_status == \"hard\":\n",
    "            add_hard_delay(\"print\", pre_start_dt, print_first_dt)\n",
    "        if open_status == \"hard\":\n",
    "            add_hard_delay(\"open\", pre_start_dt, open_hard_dt)\n",
    "        if global_kind == \"hard\":\n",
    "            # delay is delay to the winning hard in GLOBAL\n",
    "            if global_label.startswith(\"BLUE_\"):\n",
    "                add_hard_delay(\"global\", pre_start_dt, blue_hard_dt)\n",
    "            elif global_label.startswith(\"ARK_\"):\n",
    "                add_hard_delay(\"global\", pre_start_dt, ark_hard_dt)\n",
    "            elif global_label.startswith(\"PRINT_\"):\n",
    "                add_hard_delay(\"global\", pre_start_dt, print_first_dt)\n",
    "            elif global_label.startswith(\"OPEN_\"):\n",
    "                add_hard_delay(\"global\", pre_start_dt, open_hard_dt)\n",
    "\n",
    "        # sigma bins:\n",
    "        # - BLUE uses BLUE peak (frozen to 03:59)\n",
    "        # - others use PRE peak (frozen to 09:29)\n",
    "        update_sigma_bins(sigma_bins_pre, \"blue\", sk, blue_peak_abs, blue_status)\n",
    "        update_sigma_bins(sigma_bins_pre, \"ark\", sk, pre_peak_abs, ark_status)\n",
    "        update_sigma_bins(sigma_bins_pre, \"print\", sk, pre_peak_abs, print_status)\n",
    "        update_sigma_bins(sigma_bins_pre, \"open\", sk, pre_peak_abs, open_status)\n",
    "        update_sigma_bins(sigma_bins_pre, \"global\", sk, pre_peak_abs, global_kind)  # global is modeled on PRE peak scale\n",
    "\n",
    "        # bench bins start+peak\n",
    "        update_bench_bins(bench_bins_pre, \"blue\", \"start\", sk, pre_start_bench, blue_status)\n",
    "        update_bench_bins(bench_bins_pre, \"blue\", \"peak\",  sk, blue_peak_bench, blue_status)\n",
    "\n",
    "        for cls, status in ((\"ark\", ark_status), (\"print\", print_status), (\"open\", open_status), (\"global\", global_kind)):\n",
    "            update_bench_bins(bench_bins_pre, cls, \"start\", sk, pre_start_bench, status)\n",
    "            update_bench_bins(bench_bins_pre, cls, \"peak\",  sk, pre_peak_bench, status)\n",
    "\n",
    "        # norm dt per class (for norm bench bins + norm timebands)\n",
    "        def cls_norm_dt(cls):\n",
    "            if cls == \"blue\":\n",
    "                return blue_hard_dt if blue_status == \"hard\" else (blue_soft_dt if blue_status == \"soft\" else None)\n",
    "            if cls == \"ark\":\n",
    "                return ark_hard_dt if ark_status == \"hard\" else (ark_soft_dt if ark_status == \"soft\" else None)\n",
    "            if cls == \"print\":\n",
    "                return print_first_dt if print_status != \"none\" else None\n",
    "            if cls == \"open\":\n",
    "                return open_hard_dt if open_status == \"hard\" else (open_soft_dt if open_status == \"soft\" else None)\n",
    "            if cls == \"global\":\n",
    "                if global_label.startswith(\"BLUE_\"):\n",
    "                    return cls_norm_dt(\"blue\")\n",
    "                if global_label.startswith(\"ARK_\"):\n",
    "                    return cls_norm_dt(\"ark\")\n",
    "                if global_label.startswith(\"PRINT_\"):\n",
    "                    return cls_norm_dt(\"print\")\n",
    "                if global_label.startswith(\"OPEN_\"):\n",
    "                    return cls_norm_dt(\"open\")\n",
    "                return None\n",
    "            return None\n",
    "\n",
    "        def cls_outcome(cls):\n",
    "            if cls == \"blue\": return blue_status\n",
    "            if cls == \"ark\": return ark_status\n",
    "            if cls == \"print\": return print_status\n",
    "            if cls == \"open\": return open_status\n",
    "            if cls == \"global\": return global_kind\n",
    "            return \"none\"\n",
    "\n",
    "        def cls_peak_signed(cls):\n",
    "            if cls == \"blue\": return blue_peak_signed\n",
    "            return pre_peak_signed\n",
    "\n",
    "        def cls_end_fields(cls, status):\n",
    "            if cls == \"blue\":\n",
    "                if status == \"hard\":\n",
    "                    return blue_hard_val, blue_hard_stock, blue_hard_bench\n",
    "                if status == \"soft\":\n",
    "                    return blue_soft_val, blue_soft_stock, blue_soft_bench\n",
    "                return np.nan, np.nan, np.nan\n",
    "            if cls == \"ark\":\n",
    "                if status == \"hard\":\n",
    "                    return ark_hard_val, ark_hard_stock, ark_hard_bench\n",
    "                if status == \"soft\":\n",
    "                    return ark_soft_val, ark_soft_stock, ark_soft_bench\n",
    "                return np.nan, np.nan, np.nan\n",
    "            if cls == \"print\":\n",
    "                if status != \"none\":\n",
    "                    return print_first_val, print_first_stock, print_first_bench\n",
    "                return np.nan, np.nan, np.nan\n",
    "            if cls == \"open\":\n",
    "                if status == \"hard\":\n",
    "                    return open_hard_val, open_hard_stock, open_hard_bench\n",
    "                if status == \"soft\":\n",
    "                    return open_soft_val, open_soft_stock, open_soft_bench\n",
    "                return np.nan, np.nan, np.nan\n",
    "            if cls == \"global\":\n",
    "                if global_label.startswith(\"BLUE_\"):\n",
    "                    return cls_end_fields(\"blue\", blue_status)\n",
    "                if global_label.startswith(\"ARK_\"):\n",
    "                    return cls_end_fields(\"ark\", ark_status)\n",
    "                if global_label.startswith(\"PRINT_\"):\n",
    "                    return cls_end_fields(\"print\", print_status)\n",
    "                if global_label.startswith(\"OPEN_\"):\n",
    "                    return cls_end_fields(\"open\", open_status)\n",
    "                return np.nan, np.nan, np.nan\n",
    "            return np.nan, np.nan, np.nan\n",
    "\n",
    "        # norm bins + bench norm + ✅ last3 pushes (hard/soft only)\n",
    "        for cls in (\"blue\", \"ark\", \"print\", \"open\", \"global\"):\n",
    "            ndt = cls_norm_dt(cls)\n",
    "            status = cls_outcome(cls)\n",
    "            if isinstance(ndt, datetime):\n",
    "                b = floor_to_band(ndt, norm_band_minutes)\n",
    "                if b:\n",
    "                    # OLD norm counters kept (any/hard/soft only)\n",
    "                    if status != \"none\":\n",
    "                        norm_bands_pre_any[b] += 1\n",
    "                    if status == \"hard\":\n",
    "                        norm_bands_pre_hard[b] += 1\n",
    "                    if status == \"soft\":\n",
    "                        norm_bands_pre_soft[b] += 1\n",
    "\n",
    "                    # NEW per-class-sign norm bins\n",
    "                    update_timeband_by_class_sign(timebands_pre_by_class_sign, cls, \"norm\", sk, b, status)\n",
    "\n",
    "                    # bench norm bin value:\n",
    "                    if cls == \"blue\":\n",
    "                        end_bench_val = blue_hard_bench if status == \"hard\" else (blue_soft_bench if status == \"soft\" else np.nan)\n",
    "                        update_bench_bins(bench_bins_pre, cls, \"norm\", sk, end_bench_val, status)\n",
    "                    else:\n",
    "                        update_bench_bins(bench_bins_pre, cls, \"norm\", sk, pre_peak_bench, status)\n",
    "\n",
    "                # last3 only for normalized statuses\n",
    "                if status in (\"hard\", \"soft\"):\n",
    "                    end_dev, end_stock, end_bench = cls_end_fields(cls, status)\n",
    "                    push_last3_example(\n",
    "                        cls, sk, status,\n",
    "                        pre_start_dt, ndt,\n",
    "                        pre_start_dev, end_dev, cls_peak_signed(cls),\n",
    "                        pre_start_stock, end_stock,\n",
    "                        pre_start_bench, end_bench,\n",
    "                        start_time=pre_start_dt.strftime(\"%H:%M\") if isinstance(pre_start_dt, datetime) else None,\n",
    "                        end_time=ndt.strftime(\"%H:%M\") if isinstance(ndt, datetime) else None,\n",
    "                    )\n",
    "\n",
    "        # global mean peak for normalized — use BLUE peak if global label is BLUE\n",
    "        if global_kind != \"none\":\n",
    "            if global_label.startswith(\"BLUE_\") and is_finite_num(blue_peak_abs):\n",
    "                global_norm_peak_sum[sk] += float(blue_peak_abs)\n",
    "                global_norm_peak_cnt[sk] += 1\n",
    "            elif is_finite_num(pre_peak_abs):\n",
    "                global_norm_peak_sum[sk] += float(pre_peak_abs)\n",
    "                global_norm_peak_cnt[sk] += 1\n",
    "\n",
    "        # DAILY RECENT (kept): based on PRE peak (09:29-frozen)\n",
    "        if isinstance(pre_start_dt, datetime):\n",
    "            day_str = pre_start_dt.date().isoformat()\n",
    "            _ensure_recent_day(day_str)\n",
    "            _update_recent_daily_peak(day_str, pre_peak_dt, pre_peak_abs, pre_peak_signed, int(pre_start_sign))\n",
    "            if isinstance(print_first_dt, datetime) and is_finite_num(print_first_val):\n",
    "                _update_recent_daily_print(\n",
    "                    day_str,\n",
    "                    print_first_dt,\n",
    "                    float(print_first_val),\n",
    "                    float(pre_peak_abs),\n",
    "                    float(pre_peak_signed),\n",
    "                    int(pre_start_sign),\n",
    "                )\n",
    "\n",
    "        # rebuild last5 deques from recent_days (kept)\n",
    "        last5_print_days_pos.clear()\n",
    "        last5_print_days_neg.clear()\n",
    "        last5_peak_days_pos.clear()\n",
    "        last5_peak_days_neg.clear()\n",
    "        for d in list(recent_days):\n",
    "            snap = recent_by_day.get(d)\n",
    "            if not snap:\n",
    "                continue\n",
    "            pk = snap.get(\"peak\")\n",
    "            pr = snap.get(\"print\")\n",
    "            if pk and is_finite_num(pk.get(\"sigma_abs\")):\n",
    "                if int(pk.get(\"first_sign\", 1)) > 0:\n",
    "                    last5_peak_days_pos.append(float(pk[\"sigma_abs\"]))\n",
    "                else:\n",
    "                    last5_peak_days_neg.append(float(pk[\"sigma_abs\"]))\n",
    "            if pr and is_finite_num(pr.get(\"dev\")):\n",
    "                if int(pr.get(\"first_sign\", 1)) > 0:\n",
    "                    last5_print_days_pos.append(float(pr[\"dev\"]))\n",
    "                else:\n",
    "                    last5_print_days_neg.append(float(pr[\"dev\"]))\n",
    "            if (\n",
    "                len(last5_print_days_pos) >= 5\n",
    "                and len(last5_print_days_neg) >= 5\n",
    "                and len(last5_peak_days_pos) >= 5\n",
    "                and len(last5_peak_days_neg) >= 5\n",
    "            ):\n",
    "                break\n",
    "\n",
    "        if include_events_pre:\n",
    "            pre_events_buf.append({\n",
    "                \"pre_id\": int(pre_id),\n",
    "                \"reason_finalized\": reason,\n",
    "                \"start\": {\"dt\": _dt_iso(pre_start_dt), \"dev\": _json_safe(pre_start_dev), \"sign\": int(pre_start_sign),\n",
    "                          \"stock_pct\": _json_safe(pre_start_stock), \"bench_pct\": _json_safe(pre_start_bench)},\n",
    "                \"pre_peak_frozen\": {\"dt\": _dt_iso(pre_peak_dt), \"abs\": _json_safe(pre_peak_abs), \"signed\": _json_safe(pre_peak_signed),\n",
    "                                    \"bin\": sigma_bin(pre_peak_abs),\n",
    "                                    \"stock_pct\": _json_safe(pre_peak_stock), \"bench_pct\": _json_safe(pre_peak_bench)},\n",
    "                \"blue_peak_frozen\": {\"dt\": _dt_iso(blue_peak_dt), \"abs\": _json_safe(blue_peak_abs), \"signed\": _json_safe(blue_peak_signed),\n",
    "                                     \"bin\": sigma_bin(blue_peak_abs),\n",
    "                                     \"stock_pct\": _json_safe(blue_peak_stock), \"bench_pct\": _json_safe(blue_peak_bench)},\n",
    "                \"blue\": {\"status\": blue_status},\n",
    "                \"ark\": {\"status\": ark_status},\n",
    "                \"print\": {\"status\": print_status},\n",
    "                \"open\": {\"status\": open_status},\n",
    "                \"global\": {\"label\": global_label, \"kind\": global_kind},\n",
    "            })\n",
    "\n",
    "        pre_id += 1\n",
    "        reset_pre_event()\n",
    "\n",
    "    # ---------------- INTRA event state ----------------\n",
    "    intra_active = False\n",
    "    intra_id = 0\n",
    "\n",
    "    intra_start_dt = None\n",
    "    intra_start_dev = np.nan\n",
    "    intra_start_sign = 0\n",
    "    intra_start_stock = np.nan\n",
    "    intra_start_bench = np.nan\n",
    "\n",
    "    intra_peak_abs = 0.0\n",
    "    intra_peak_signed = 0.0\n",
    "    intra_peak_dt = None\n",
    "    intra_peak_stock = np.nan\n",
    "    intra_peak_bench = np.nan\n",
    "\n",
    "    intra_hard_dt = None\n",
    "    intra_hard_val = np.nan\n",
    "    intra_hard_stock = np.nan\n",
    "    intra_hard_bench = np.nan\n",
    "\n",
    "    intra_soft_found = False\n",
    "    intra_soft_dt = None\n",
    "    intra_soft_val = np.nan\n",
    "    intra_soft_stock = np.nan\n",
    "    intra_soft_bench = np.nan\n",
    "\n",
    "    def reset_intra_event():\n",
    "        nonlocal intra_active, intra_start_dt, intra_start_dev, intra_start_sign, intra_start_stock, intra_start_bench\n",
    "        nonlocal intra_peak_abs, intra_peak_signed, intra_peak_dt, intra_peak_stock, intra_peak_bench\n",
    "        nonlocal intra_hard_dt, intra_hard_val, intra_hard_stock, intra_hard_bench\n",
    "        nonlocal intra_soft_found, intra_soft_dt, intra_soft_val, intra_soft_stock, intra_soft_bench\n",
    "\n",
    "        intra_active = False\n",
    "        intra_start_dt = None\n",
    "        intra_start_dev = np.nan\n",
    "        intra_start_sign = 0\n",
    "        intra_start_stock = np.nan\n",
    "        intra_start_bench = np.nan\n",
    "\n",
    "        intra_peak_abs = 0.0\n",
    "        intra_peak_signed = 0.0\n",
    "        intra_peak_dt = None\n",
    "        intra_peak_stock = np.nan\n",
    "        intra_peak_bench = np.nan\n",
    "\n",
    "        intra_hard_dt = None\n",
    "        intra_hard_val = np.nan\n",
    "        intra_hard_stock = np.nan\n",
    "        intra_hard_bench = np.nan\n",
    "\n",
    "        intra_soft_found = False\n",
    "        intra_soft_dt = None\n",
    "        intra_soft_val = np.nan\n",
    "        intra_soft_stock = np.nan\n",
    "        intra_soft_bench = np.nan\n",
    "\n",
    "    def start_intra_event(dt_now, dev_now, stock_pct, bench_pct):\n",
    "        nonlocal intra_active, intra_start_dt, intra_start_dev, intra_start_sign, intra_start_stock, intra_start_bench\n",
    "        nonlocal intra_peak_abs, intra_peak_signed, intra_peak_dt, intra_peak_stock, intra_peak_bench\n",
    "\n",
    "        intra_active = True\n",
    "        intra_start_dt = dt_now\n",
    "        intra_start_dev = float(dev_now)\n",
    "        intra_start_sign = 1 if float(dev_now) >= 0 else -1\n",
    "        intra_start_stock = stock_pct\n",
    "        intra_start_bench = bench_pct\n",
    "\n",
    "        intra_peak_abs = abs(float(dev_now))\n",
    "        intra_peak_signed = float(dev_now)\n",
    "        intra_peak_dt = dt_now\n",
    "        intra_peak_stock = stock_pct\n",
    "        intra_peak_bench = bench_pct\n",
    "\n",
    "    def intra_sign_key():\n",
    "        return \"pos\" if intra_start_sign > 0 else \"neg\"\n",
    "\n",
    "    def intra_process_tick(dt_now, dev_now, stock_pct, bench_pct):\n",
    "        nonlocal intra_peak_abs, intra_peak_signed, intra_peak_dt, intra_peak_stock, intra_peak_bench\n",
    "        nonlocal intra_hard_dt, intra_hard_val, intra_hard_stock, intra_hard_bench\n",
    "        nonlocal intra_soft_found, intra_soft_dt, intra_soft_val, intra_soft_stock, intra_soft_bench\n",
    "\n",
    "        cur_abs = abs(float(dev_now))\n",
    "\n",
    "        if cur_abs > float(intra_peak_abs):\n",
    "            intra_peak_abs = float(cur_abs)\n",
    "            intra_peak_signed = float(dev_now)\n",
    "            intra_peak_dt = dt_now\n",
    "            intra_peak_stock = stock_pct\n",
    "            intra_peak_bench = bench_pct\n",
    "            if intra_hard_dt is None:\n",
    "                intra_soft_found = False\n",
    "                intra_soft_dt = None\n",
    "                intra_soft_val = np.nan\n",
    "                intra_soft_stock = np.nan\n",
    "                intra_soft_bench = np.nan\n",
    "\n",
    "        t = (dt_now.hour, dt_now.minute)\n",
    "        if not in_range(t, INTRA_FROM, INTRA_TO):\n",
    "            return\n",
    "\n",
    "        if intra_hard_dt is None and cur_abs <= norm_thr:\n",
    "            intra_hard_dt = dt_now\n",
    "            intra_hard_val = float(dev_now)\n",
    "            intra_hard_stock = stock_pct\n",
    "            intra_hard_bench = bench_pct\n",
    "\n",
    "        if intra_hard_dt is None and isinstance(intra_peak_dt, datetime) and intra_peak_abs > 0:\n",
    "            if dt_now >= intra_peak_dt and cur_abs <= (float(intra_peak_abs) / float(soft_ratio)):\n",
    "                if (not intra_soft_found) or (dt_now < intra_soft_dt):\n",
    "                    intra_soft_found = True\n",
    "                    intra_soft_dt = dt_now\n",
    "                    intra_soft_val = float(dev_now)\n",
    "                    intra_soft_stock = stock_pct\n",
    "                    intra_soft_bench = bench_pct\n",
    "\n",
    "    def finalize_intra_event(reason=\"window_end\"):\n",
    "        nonlocal intra_active, intra_id\n",
    "        if not intra_active:\n",
    "            return\n",
    "\n",
    "        if intra_hard_dt is not None:\n",
    "            status = \"hard\"\n",
    "            end_dt = intra_hard_dt\n",
    "            add_hard_delay(\"intra\", intra_start_dt, intra_hard_dt)\n",
    "        elif intra_soft_found and intra_soft_dt is not None:\n",
    "            status = \"soft\"\n",
    "            end_dt = intra_soft_dt\n",
    "        else:\n",
    "            status = \"none\"\n",
    "            end_dt = None\n",
    "\n",
    "        sk = intra_sign_key()\n",
    "\n",
    "        sb = floor_to_band(intra_start_dt, start_band_minutes)\n",
    "        if sb:\n",
    "            start_bands_intra_total[sb] += 1\n",
    "            if status != \"none\":\n",
    "                start_bands_intra_any[sb] += 1\n",
    "            if status == \"hard\":\n",
    "                start_bands_intra_hard[sb] += 1\n",
    "            if status == \"soft\":\n",
    "                start_bands_intra_soft[sb] += 1\n",
    "\n",
    "            update_timeband_by_class_sign(timebands_intra_by_class_sign, \"intra\", \"start\", sk, sb, status)\n",
    "\n",
    "        counts_intra[\"intra\"][status] += 1\n",
    "\n",
    "        update_sigma_bins(sigma_bins_intra, \"intra\", sk, intra_peak_abs, status)\n",
    "        update_bench_bins(bench_bins_intra, \"intra\", \"start\", sk, intra_start_bench, status)\n",
    "        update_bench_bins(bench_bins_intra, \"intra\", \"peak\",  sk, intra_peak_bench, status)\n",
    "\n",
    "        if status != \"none\" and isinstance(end_dt, datetime):\n",
    "            b = floor_to_band(end_dt, norm_band_minutes)\n",
    "            if b:\n",
    "                norm_bands_intra_any[b] += 1\n",
    "                if status == \"hard\":\n",
    "                    norm_bands_intra_hard[b] += 1\n",
    "                if status == \"soft\":\n",
    "                    norm_bands_intra_soft[b] += 1\n",
    "\n",
    "                update_timeband_by_class_sign(timebands_intra_by_class_sign, \"intra\", \"norm\", sk, b, status)\n",
    "                update_bench_bins(bench_bins_intra, \"intra\", \"norm\", sk, (intra_hard_bench if status == \"hard\" else intra_soft_bench), status)\n",
    "\n",
    "            push_last3_example(\n",
    "                \"intra\", sk, status,\n",
    "                intra_start_dt, end_dt,\n",
    "                intra_start_dev, (intra_hard_val if status == \"hard\" else intra_soft_val),\n",
    "                intra_peak_signed,\n",
    "                intra_start_stock, (intra_hard_stock if status == \"hard\" else intra_soft_stock),\n",
    "                intra_start_bench, (intra_hard_bench if status == \"hard\" else intra_soft_bench),\n",
    "                start_time=intra_start_dt.strftime(\"%H:%M\") if isinstance(intra_start_dt, datetime) else None,\n",
    "                end_time=end_dt.strftime(\"%H:%M\") if isinstance(end_dt, datetime) else None,\n",
    "            )\n",
    "\n",
    "        if include_events_intra:\n",
    "            intra_events_buf.append({\n",
    "                \"intra_id\": int(intra_id),\n",
    "                \"reason_finalized\": reason,\n",
    "                \"start\": {\"dt\": _dt_iso(intra_start_dt), \"dev\": _json_safe(intra_start_dev), \"sign\": int(intra_start_sign)},\n",
    "                \"peak\":  {\"dt\": _dt_iso(intra_peak_dt), \"abs\": _json_safe(intra_peak_abs), \"signed\": _json_safe(intra_peak_signed)},\n",
    "                \"status\": status,\n",
    "            })\n",
    "\n",
    "        intra_id += 1\n",
    "        reset_intra_event()\n",
    "\n",
    "    # ---------------- POST event state ----------------\n",
    "    post_active = False\n",
    "    post_id = 0\n",
    "\n",
    "    post_start_dt = None\n",
    "    post_start_dev = np.nan\n",
    "    post_start_sign = 0\n",
    "    post_start_stock = np.nan\n",
    "    post_start_bench = np.nan\n",
    "\n",
    "    post_peak_abs = 0.0\n",
    "    post_peak_signed = 0.0\n",
    "    post_peak_dt = None\n",
    "    post_peak_stock = np.nan\n",
    "    post_peak_bench = np.nan\n",
    "\n",
    "    post_hard_dt = None\n",
    "    post_hard_val = np.nan\n",
    "    post_hard_stock = np.nan\n",
    "    post_hard_bench = np.nan\n",
    "\n",
    "    post_soft_found = False\n",
    "    post_soft_dt = None\n",
    "    post_soft_val = np.nan\n",
    "    post_soft_stock = np.nan\n",
    "    post_soft_bench = np.nan\n",
    "\n",
    "    def reset_post_event():\n",
    "        nonlocal post_active, post_start_dt, post_start_dev, post_start_sign, post_start_stock, post_start_bench\n",
    "        nonlocal post_peak_abs, post_peak_signed, post_peak_dt, post_peak_stock, post_peak_bench\n",
    "        nonlocal post_hard_dt, post_hard_val, post_hard_stock, post_hard_bench\n",
    "        nonlocal post_soft_found, post_soft_dt, post_soft_val, post_soft_stock, post_soft_bench\n",
    "\n",
    "        post_active = False\n",
    "        post_start_dt = None\n",
    "        post_start_dev = np.nan\n",
    "        post_start_sign = 0\n",
    "        post_start_stock = np.nan\n",
    "        post_start_bench = np.nan\n",
    "\n",
    "        post_peak_abs = 0.0\n",
    "        post_peak_signed = 0.0\n",
    "        post_peak_dt = None\n",
    "        post_peak_stock = np.nan\n",
    "        post_peak_bench = np.nan\n",
    "\n",
    "        post_hard_dt = None\n",
    "        post_hard_val = np.nan\n",
    "        post_hard_stock = np.nan\n",
    "        post_hard_bench = np.nan\n",
    "\n",
    "        post_soft_found = False\n",
    "        post_soft_dt = None\n",
    "        post_soft_val = np.nan\n",
    "        post_soft_stock = np.nan\n",
    "        post_soft_bench = np.nan\n",
    "\n",
    "    def start_post_event(dt_now, dev_now, stock_pct, bench_pct):\n",
    "        nonlocal post_active, post_start_dt, post_start_dev, post_start_sign, post_start_stock, post_start_bench\n",
    "        nonlocal post_peak_abs, post_peak_signed, post_peak_dt, post_peak_stock, post_peak_bench\n",
    "\n",
    "        post_active = True\n",
    "        post_start_dt = dt_now\n",
    "        post_start_dev = float(dev_now)\n",
    "        post_start_sign = 1 if float(dev_now) >= 0 else -1\n",
    "        post_start_stock = stock_pct\n",
    "        post_start_bench = bench_pct\n",
    "\n",
    "        post_peak_abs = abs(float(dev_now))\n",
    "        post_peak_signed = float(dev_now)\n",
    "        post_peak_dt = dt_now\n",
    "        post_peak_stock = stock_pct\n",
    "        post_peak_bench = bench_pct\n",
    "\n",
    "    def post_sign_key():\n",
    "        return \"pos\" if post_start_sign > 0 else \"neg\"\n",
    "\n",
    "    def post_process_tick(dt_now, dev_now, stock_pct, bench_pct):\n",
    "        nonlocal post_peak_abs, post_peak_signed, post_peak_dt, post_peak_stock, post_peak_bench\n",
    "        nonlocal post_hard_dt, post_hard_val, post_hard_stock, post_hard_bench\n",
    "        nonlocal post_soft_found, post_soft_dt, post_soft_val, post_soft_stock, post_soft_bench\n",
    "\n",
    "        cur_abs = abs(float(dev_now))\n",
    "\n",
    "        if cur_abs > float(post_peak_abs):\n",
    "            post_peak_abs = float(cur_abs)\n",
    "            post_peak_signed = float(dev_now)\n",
    "            post_peak_dt = dt_now\n",
    "            post_peak_stock = stock_pct\n",
    "            post_peak_bench = bench_pct\n",
    "            if post_hard_dt is None:\n",
    "                post_soft_found = False\n",
    "                post_soft_dt = None\n",
    "                post_soft_val = np.nan\n",
    "                post_soft_stock = np.nan\n",
    "                post_soft_bench = np.nan\n",
    "\n",
    "        t = (dt_now.hour, dt_now.minute)\n",
    "        if not in_range(t, POST_FROM, POST_TO):\n",
    "            return\n",
    "\n",
    "        if post_hard_dt is None and cur_abs <= norm_thr:\n",
    "            post_hard_dt = dt_now\n",
    "            post_hard_val = float(dev_now)\n",
    "            post_hard_stock = stock_pct\n",
    "            post_hard_bench = bench_pct\n",
    "\n",
    "        if post_hard_dt is None and isinstance(post_peak_dt, datetime) and post_peak_abs > 0:\n",
    "            if dt_now >= post_peak_dt and cur_abs <= (float(post_peak_abs) / float(soft_ratio)):\n",
    "                if (not post_soft_found) or (dt_now < post_soft_dt):\n",
    "                    post_soft_found = True\n",
    "                    post_soft_dt = dt_now\n",
    "                    post_soft_val = float(dev_now)\n",
    "                    post_soft_stock = stock_pct\n",
    "                    post_soft_bench = bench_pct\n",
    "\n",
    "    def finalize_post_event(reason=\"window_end\"):\n",
    "        nonlocal post_active, post_id\n",
    "        if not post_active:\n",
    "            return\n",
    "\n",
    "        if post_hard_dt is not None:\n",
    "            status = \"hard\"\n",
    "            end_dt = post_hard_dt\n",
    "            add_hard_delay(\"post\", post_start_dt, post_hard_dt)\n",
    "        elif post_soft_found and post_soft_dt is not None:\n",
    "            status = \"soft\"\n",
    "            end_dt = post_soft_dt\n",
    "        else:\n",
    "            status = \"none\"\n",
    "            end_dt = None\n",
    "\n",
    "        sk = post_sign_key()\n",
    "\n",
    "        sb = floor_to_band(post_start_dt, start_band_minutes)\n",
    "        if sb:\n",
    "            start_bands_post_total[sb] += 1\n",
    "            if status != \"none\":\n",
    "                start_bands_post_any[sb] += 1\n",
    "            if status == \"hard\":\n",
    "                start_bands_post_hard[sb] += 1\n",
    "            if status == \"soft\":\n",
    "                start_bands_post_soft[sb] += 1\n",
    "\n",
    "            update_timeband_by_class_sign(timebands_post_by_class_sign, \"post\", \"start\", sk, sb, status)\n",
    "\n",
    "        counts_post[\"post\"][status] += 1\n",
    "\n",
    "        update_sigma_bins(sigma_bins_post, \"post\", sk, post_peak_abs, status)\n",
    "        update_bench_bins(bench_bins_post, \"post\", \"start\", sk, post_start_bench, status)\n",
    "        update_bench_bins(bench_bins_post, \"post\", \"peak\",  sk, post_peak_bench, status)\n",
    "\n",
    "        if status != \"none\" and isinstance(end_dt, datetime):\n",
    "            b = floor_to_band(end_dt, norm_band_minutes)\n",
    "            if b:\n",
    "                norm_bands_post_any[b] += 1\n",
    "                if status == \"hard\":\n",
    "                    norm_bands_post_hard[b] += 1\n",
    "                if status == \"soft\":\n",
    "                    norm_bands_post_soft[b] += 1\n",
    "\n",
    "                update_timeband_by_class_sign(timebands_post_by_class_sign, \"post\", \"norm\", sk, b, status)\n",
    "                update_bench_bins(bench_bins_post, \"post\", \"norm\", sk, (post_hard_bench if status == \"hard\" else post_soft_bench), status)\n",
    "\n",
    "            push_last3_example(\n",
    "                \"post\", sk, status,\n",
    "                post_start_dt, end_dt,\n",
    "                post_start_dev, (post_hard_val if status == \"hard\" else post_soft_val),\n",
    "                post_peak_signed,\n",
    "                post_start_stock, (post_hard_stock if status == \"hard\" else post_soft_stock),\n",
    "                post_start_bench, (post_hard_bench if status == \"hard\" else post_soft_bench),\n",
    "                start_time=post_start_dt.strftime(\"%H:%M\") if isinstance(post_start_dt, datetime) else None,\n",
    "                end_time=end_dt.strftime(\"%H:%M\") if isinstance(end_dt, datetime) else None,\n",
    "            )\n",
    "\n",
    "        if include_events_post:\n",
    "            post_events_buf.append({\n",
    "                \"post_id\": int(post_id),\n",
    "                \"reason_finalized\": reason,\n",
    "                \"start\": {\"dt\": _dt_iso(post_start_dt), \"dev\": _json_safe(post_start_dev), \"sign\": int(post_start_sign)},\n",
    "                \"peak\":  {\"dt\": _dt_iso(post_peak_dt), \"abs\": _json_safe(post_peak_abs), \"signed\": _json_safe(post_peak_signed)},\n",
    "                \"status\": status,\n",
    "            })\n",
    "\n",
    "        post_id += 1\n",
    "        reset_post_event()\n",
    "\n",
    "    # ---------------- day boundary helpers ----------------\n",
    "    def on_new_day():\n",
    "        if pre_active:\n",
    "            finalize_pre_event(reason=\"day_boundary\")\n",
    "        if intra_active:\n",
    "            finalize_intra_event(reason=\"day_boundary\")\n",
    "        if post_active:\n",
    "            finalize_post_event(reason=\"day_boundary\")\n",
    "\n",
    "    # ---------------- dictify helpers ----------------\n",
    "    def dictify_sigma_bins(m):\n",
    "        return {\n",
    "            \"pos\": {b: dict(c) for b, c in m[\"pos\"].items()},\n",
    "            \"neg\": {b: dict(c) for b, c in m[\"neg\"].items()},\n",
    "        }\n",
    "\n",
    "    def dictify_bench_bins(m):\n",
    "        out = {}\n",
    "        for which in (\"start\", \"peak\", \"norm\"):\n",
    "            out[which] = {\n",
    "                \"pos\": {b: dict(c) for b, c in m[which][\"pos\"].items()},\n",
    "                \"neg\": {b: dict(c) for b, c in m[which][\"neg\"].items()},\n",
    "            }\n",
    "        return out\n",
    "\n",
    "    def dictify_timebands_by_class_sign(m):\n",
    "        out = {}\n",
    "        for cls, blk in m.items():\n",
    "            out[cls] = {}\n",
    "            for which in (\"start\", \"norm\"):\n",
    "                out[cls][which] = {\n",
    "                    \"pos\": {band: dict(c) for band, c in blk[which][\"pos\"].items()},\n",
    "                    \"neg\": {band: dict(c) for band, c in blk[which][\"neg\"].items()},\n",
    "                }\n",
    "        return out\n",
    "\n",
    "    def dictify_last3(last3_map):\n",
    "        out = {}\n",
    "        for cls, by_sign in last3_map.items():\n",
    "            out[cls] = {\"pos\": list(by_sign[\"pos\"]), \"neg\": list(by_sign[\"neg\"])}\n",
    "        return out\n",
    "\n",
    "    # ---------------- flush ticker (write files) ----------------\n",
    "    def flush_current_ticker():\n",
    "        nonlocal cur_ticker, cur_day\n",
    "        nonlocal bench_name_seen, corr_static, beta_static, sigma_static\n",
    "\n",
    "        if cur_ticker is None:\n",
    "            return\n",
    "\n",
    "        if pre_active:\n",
    "            finalize_pre_event(reason=\"ticker_end\")\n",
    "        if intra_active:\n",
    "            finalize_intra_event(reason=\"ticker_end\")\n",
    "        if post_active:\n",
    "            finalize_post_event(reason=\"ticker_end\")\n",
    "\n",
    "        blue_r = class_rates(counts_pre[\"blue\"])\n",
    "        ark_r = class_rates(counts_pre[\"ark\"])\n",
    "        pr_r  = class_rates(counts_pre[\"print\"])\n",
    "        op_r  = class_rates(counts_pre[\"open\"])\n",
    "        gl_r  = class_rates(counts_pre[\"global\"])\n",
    "        intra_r = class_rates(counts_intra[\"intra\"])\n",
    "        post_r  = class_rates(counts_post[\"post\"])\n",
    "\n",
    "        events_pre_total = int(gl_r[\"total\"])  # pre event count aligns with global counter\n",
    "        events_intra_total = int(intra_r[\"total\"])\n",
    "        events_post_total  = int(post_r[\"total\"])\n",
    "        events_total = events_pre_total + events_intra_total + events_post_total\n",
    "\n",
    "        # ✅ global filter for ALL outputs\n",
    "        if events_total < int(min_events_per_ticker):\n",
    "            reset_ticker_state()\n",
    "            return\n",
    "\n",
    "        # last10\n",
    "        last10_print_days = []\n",
    "        last10_peak_days = []\n",
    "        for d in list(recent_days):\n",
    "            snap = recent_by_day.get(d)\n",
    "            if not snap:\n",
    "                continue\n",
    "            if snap.get(\"print\") is not None:\n",
    "                last10_print_days.append(snap[\"print\"])\n",
    "            if snap.get(\"peak\") is not None:\n",
    "                last10_peak_days.append(snap[\"peak\"])\n",
    "\n",
    "        pos_vals = list(last5_print_days_pos)\n",
    "        neg_vals = list(last5_print_days_neg)\n",
    "\n",
    "        # open series last10\n",
    "        open_series_last10 = []\n",
    "        for d in list(recent_days):\n",
    "            series_map = open_series_by_day.get(d)\n",
    "            if not series_map:\n",
    "                continue\n",
    "            pts = sorted(series_map.items(), key=lambda kv: kv[0])\n",
    "            open_series_last10.append({\n",
    "                \"date\": d,\n",
    "                \"points\": [[dt_iso, _json_safe(val)] for dt_iso, val in pts],\n",
    "            })\n",
    "\n",
    "        payload = {\n",
    "            \"ticker\": cur_ticker,\n",
    "            \"bench\": bench_name_seen,\n",
    "            \"static\": {\"corr\": _json_safe(corr_static), \"beta\": _json_safe(beta_static), \"sigma\": _json_safe(sigma_static)},\n",
    "            \"params\": {\n",
    "                \"dev_thr\": float(dev_thr), \"norm_thr\": float(norm_thr), \"soft_ratio\": float(soft_ratio),\n",
    "                \"windows\": {\n",
    "                    \"blue\": \"00:01-03:59 (trigger allowed; peak frozen to 03:59; hard/soft within BLUE)\",\n",
    "                    \"fixation_window\": \"00:05-09:29 (ARK peak frozen; ARK hard/soft within)\",\n",
    "                    \"ignored_gaps\": [\"03:58-04:05\", \"07:58-08:05\"],\n",
    "                    \"frozen_peak_until\": \"09:29\",\n",
    "                    \"print_first\": \"09:30-09:35 (first tick only)\",\n",
    "                    \"open_scan\": \"09:31-09:40 (scan + open dev series)\",\n",
    "                    \"intra\": \"10:00-12:00 (trigger+normalize within)\",\n",
    "                    \"post\": \"16:01-19:59 (trigger+normalize within)\",\n",
    "                    \"global_priority\": GLOBAL_PRIORITY,\n",
    "                },\n",
    "                \"bins\": {\n",
    "                    \"sigma\": {\"min\": sigma_bin_min, \"max\": sigma_bin_max, \"step\": sigma_bin_step},\n",
    "                    \"bench\": {\"min\": bench_bin_min, \"max\": bench_bin_max, \"step\": bench_bin_step},\n",
    "                },\n",
    "                \"time_bands\": {\"start_band_minutes\": start_band_minutes, \"norm_band_minutes\": norm_band_minutes},\n",
    "                \"best_rules\": best_rules,\n",
    "                \"min_events_per_ticker\": int(min_events_per_ticker),\n",
    "                \"open_series_downsample_seconds\": int(open_series_downsample_seconds),\n",
    "            },\n",
    "      \"stats\": {\n",
    "                \"events_total\": int(events_total),\n",
    "                \"pre\": {\n",
    "                    \"events_total\": int(events_pre_total),\n",
    "                    \"blue\": blue_r,\n",
    "                    \"ark\": ark_r,\n",
    "                    \"print\": pr_r,\n",
    "                    \"open\": op_r,\n",
    "                    \"global\": {\n",
    "                        **gl_r,\n",
    "                        \"labels\": dict(global_labels_counter),\n",
    "                        \"best_label\": global_labels_counter.most_common(1)[0][0] if global_labels_counter else None,\n",
    "                    },\n",
    "                    \"hard_delay_avg_sec\": {\n",
    "                        \"blue\": _json_safe(avg_hard_delay(\"blue\")),\n",
    "                        \"ark\": _json_safe(avg_hard_delay(\"ark\")),\n",
    "                        \"print\": _json_safe(avg_hard_delay(\"print\")),\n",
    "                        \"open\": _json_safe(avg_hard_delay(\"open\")),\n",
    "                        \"global\": _json_safe(avg_hard_delay(\"global\")),\n",
    "                    },\n",
    "                    \"global_mean_peak_abs_when_normalized\": {\n",
    "                        \"pos\": _json_safe((global_norm_peak_sum[\"pos\"] / global_norm_peak_cnt[\"pos\"]) if global_norm_peak_cnt[\"pos\"] else None),\n",
    "                        \"neg\": _json_safe((global_norm_peak_sum[\"neg\"] / global_norm_peak_cnt[\"neg\"]) if global_norm_peak_cnt[\"neg\"] else None),\n",
    "                    },\n",
    "                },\n",
    "                \"intra\": {\n",
    "                    \"events_total\": int(events_intra_total),\n",
    "                    \"intra\": intra_r,\n",
    "                    \"hard_delay_avg_sec\": {\"intra\": _json_safe(avg_hard_delay(\"intra\"))},\n",
    "                },\n",
    "                \"post\": {\n",
    "                    \"events_total\": int(events_post_total),\n",
    "                    \"post\": post_r,\n",
    "                    \"hard_delay_avg_sec\": {\"post\": _json_safe(avg_hard_delay(\"post\"))},\n",
    "                },\n",
    "            },\n",
    "            \"time_bands\": {\n",
    "                \"pre\": {\n",
    "                    \"start_total\": dict(start_bands_pre_total),\n",
    "                    \"start_any\": dict(start_bands_pre_any),\n",
    "                    \"start_hard\": dict(start_bands_pre_hard),\n",
    "                    \"start_soft\": dict(start_bands_pre_soft),\n",
    "                    \"norm_any\": dict(norm_bands_pre_any),\n",
    "                    \"norm_hard\": dict(norm_bands_pre_hard),\n",
    "                    \"norm_soft\": dict(norm_bands_pre_soft),\n",
    "                },\n",
    "                \"intra\": {\n",
    "                    \"start_total\": dict(start_bands_intra_total),\n",
    "                    \"start_any\": dict(start_bands_intra_any),\n",
    "                    \"start_hard\": dict(start_bands_intra_hard),\n",
    "                    \"start_soft\": dict(start_bands_intra_soft),\n",
    "                    \"norm_any\": dict(norm_bands_intra_any),\n",
    "                    \"norm_hard\": dict(norm_bands_intra_hard),\n",
    "                    \"norm_soft\": dict(norm_bands_intra_soft),\n",
    "                },\n",
    "                \"post\": {\n",
    "                    \"start_total\": dict(start_bands_post_total),\n",
    "                    \"start_any\": dict(start_bands_post_any),\n",
    "                    \"start_hard\": dict(start_bands_post_hard),\n",
    "                    \"start_soft\": dict(start_bands_post_soft),\n",
    "                    \"norm_any\": dict(norm_bands_post_any),\n",
    "                    \"norm_hard\": dict(norm_bands_post_hard),\n",
    "                    \"norm_soft\": dict(norm_bands_post_soft),\n",
    "                },\n",
    "                \"pre_by_class_sign\": dictify_timebands_by_class_sign(timebands_pre_by_class_sign),\n",
    "                \"intra_by_class_sign\": dictify_timebands_by_class_sign(timebands_intra_by_class_sign),\n",
    "                \"post_by_class_sign\": dictify_timebands_by_class_sign(timebands_post_by_class_sign),\n",
    "            },\n",
    "            \"recent\": {\n",
    "                \"last10_days\": list(recent_days),\n",
    "                \"last10_print\": last10_print_days,\n",
    "                \"last10_pre_peak_sigma\": last10_peak_days,\n",
    "                \"last10_open_dev_series\": open_series_last10,\n",
    "                \"last5_print\": {\n",
    "                    \"pos\": {\n",
    "                        \"values\": pos_vals,\n",
    "                        \"mean\": _json_safe(float(np.mean(pos_vals)) if pos_vals else None),\n",
    "                        \"median\": _json_safe(float(np.median(pos_vals)) if pos_vals else None),\n",
    "                    },\n",
    "                    \"neg\": {\n",
    "                        \"values\": neg_vals,\n",
    "                        \"mean\": _json_safe(float(np.mean(neg_vals)) if neg_vals else None),\n",
    "                        \"median\": _json_safe(float(np.median(neg_vals)) if neg_vals else None),\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "\n",
    "            \"examples_last3_normalized\": dictify_last3(last3_examples),\n",
    "\n",
    "            \"bins\": {\n",
    "                \"sigma\": {\n",
    "                    \"pre\": {\n",
    "                        \"blue\": dictify_sigma_bins(sigma_bins_pre[\"blue\"]),\n",
    "                        \"ark\": dictify_sigma_bins(sigma_bins_pre[\"ark\"]),\n",
    "                        \"print\": dictify_sigma_bins(sigma_bins_pre[\"print\"]),\n",
    "                        \"open\": dictify_sigma_bins(sigma_bins_pre[\"open\"]),\n",
    "                        \"global\": dictify_sigma_bins(sigma_bins_pre[\"global\"]),\n",
    "                    },\n",
    "                    \"intra\": {\"intra\": dictify_sigma_bins(sigma_bins_intra[\"intra\"])},\n",
    "                    \"post\": {\"post\": dictify_sigma_bins(sigma_bins_post[\"post\"])},\n",
    "                },\n",
    "                \"bench\": {\n",
    "                    \"pre\": {\n",
    "                        \"blue\": dictify_bench_bins(bench_bins_pre[\"blue\"]),\n",
    "                        \"ark\": dictify_bench_bins(bench_bins_pre[\"ark\"]),\n",
    "                        \"print\": dictify_bench_bins(bench_bins_pre[\"print\"]),\n",
    "                        \"open\": dictify_bench_bins(bench_bins_pre[\"open\"]),\n",
    "                        \"global\": dictify_bench_bins(bench_bins_pre[\"global\"]),\n",
    "                    },\n",
    "                    \"intra\": {\"intra\": dictify_bench_bins(bench_bins_intra[\"intra\"])},\n",
    "                    \"post\": {\"post\": dictify_bench_bins(bench_bins_post[\"post\"])},\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if include_events_pre:\n",
    "            payload[\"events_pre\"] = list(pre_events_buf)\n",
    "        if include_events_intra:\n",
    "            payload[\"events_intra\"] = list(intra_events_buf)\n",
    "        if include_events_post:\n",
    "            payload[\"events_post\"] = list(post_events_buf)\n",
    "\n",
    "        onefile_f.write(json.dumps(payload, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        # SUMMARY row\n",
    "        row = {\n",
    "            \"ticker\": cur_ticker,\n",
    "            \"bench\": bench_name_seen,\n",
    "            \"events_total\": int(events_total),\n",
    "            \"events_pre_total\": int(events_pre_total),\n",
    "            \"events_intra_total\": int(events_intra_total),\n",
    "            \"events_post_total\": int(events_post_total),\n",
    "\n",
    "            \"blue_any_rate\": _json_safe(blue_r[\"rate_any\"]),\n",
    "            \"blue_hard_rate\": _json_safe(blue_r[\"rate_hard\"]),\n",
    "            \"blue_soft_rate\": _json_safe(blue_r[\"rate_soft\"]),\n",
    "\n",
    "            \"ark_any_rate\": _json_safe(ark_r[\"rate_any\"]),\n",
    "            \"ark_hard_rate\": _json_safe(ark_r[\"rate_hard\"]),\n",
    "            \"ark_soft_rate\": _json_safe(ark_r[\"rate_soft\"]),\n",
    "\n",
    "            \"print_any_rate\": _json_safe(pr_r[\"rate_any\"]),\n",
    "            \"print_hard_rate\": _json_safe(pr_r[\"rate_hard\"]),\n",
    "            \"print_soft_rate\": _json_safe(pr_r[\"rate_soft\"]),\n",
    "\n",
    "            \"open_any_rate\": _json_safe(op_r[\"rate_any\"]),\n",
    "            \"open_hard_rate\": _json_safe(op_r[\"rate_hard\"]),\n",
    "            \"open_soft_rate\": _json_safe(op_r[\"rate_soft\"]),\n",
    "\n",
    "            \"global_any_rate\": _json_safe(gl_r[\"rate_any\"]),\n",
    "            \"global_hard_rate\": _json_safe(gl_r[\"rate_hard\"]),\n",
    "            \"global_soft_rate\": _json_safe(gl_r[\"rate_soft\"]),\n",
    "\n",
    "            \"intra_any_rate\": _json_safe(intra_r[\"rate_any\"]),\n",
    "            \"intra_hard_rate\": _json_safe(intra_r[\"rate_hard\"]),\n",
    "            \"intra_soft_rate\": _json_safe(intra_r[\"rate_soft\"]),\n",
    "\n",
    "            \"post_any_rate\": _json_safe(post_r[\"rate_any\"]),\n",
    "            \"post_hard_rate\": _json_safe(post_r[\"rate_hard\"]),\n",
    "            \"post_soft_rate\": _json_safe(post_r[\"rate_soft\"]),\n",
    "\n",
    "            \"corr\": _json_safe(corr_static),\n",
    "            \"beta\": _json_safe(beta_static),\n",
    "            \"sigma\": _json_safe(sigma_static),\n",
    "        }\n",
    "        pd.DataFrame([row], columns=summary_cols).to_csv(output_summary_csv, mode=\"a\", header=False, index=False)\n",
    "\n",
    "        # BEST PARAMS: keep + ADD best_windows_any for ALL classes\n",
    "        def median_or_none(arr):\n",
    "            arr = list(arr)\n",
    "            return _json_safe(float(np.median(arr)) if arr else None)\n",
    "\n",
    "        best_windows_any = {\n",
    "            \"sigma_peak_bins\": {\n",
    "                \"blue\":  {\"pos\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"blue\"][\"pos\"], step=sigma_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"blue\"][\"neg\"], step=sigma_bin_step)},\n",
    "                \"ark\":   {\"pos\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"ark\"][\"pos\"], step=sigma_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"ark\"][\"neg\"], step=sigma_bin_step)},\n",
    "                \"print\": {\"pos\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"print\"][\"pos\"], step=sigma_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"print\"][\"neg\"], step=sigma_bin_step)},\n",
    "                \"open\":  {\"pos\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"open\"][\"pos\"], step=sigma_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"open\"][\"neg\"], step=sigma_bin_step)},\n",
    "                \"global\":{\"pos\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"global\"][\"pos\"], step=sigma_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(sigma_bins_pre[\"global\"][\"neg\"], step=sigma_bin_step)},\n",
    "                \"intra\": {\"pos\": stitch_numeric_bin_intervals_from_any(sigma_bins_intra[\"intra\"][\"pos\"], step=sigma_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(sigma_bins_intra[\"intra\"][\"neg\"], step=sigma_bin_step)},\n",
    "                \"post\":  {\"pos\": stitch_numeric_bin_intervals_from_any(sigma_bins_post[\"post\"][\"pos\"], step=sigma_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(sigma_bins_post[\"post\"][\"neg\"], step=sigma_bin_step)},\n",
    "            },\n",
    "            \"bench_peak_bins\": {\n",
    "                \"blue\":  {\"pos\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"blue\"][\"peak\"][\"pos\"], step=bench_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"blue\"][\"peak\"][\"neg\"], step=bench_bin_step)},\n",
    "                \"ark\":   {\"pos\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"ark\"][\"peak\"][\"pos\"], step=bench_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"ark\"][\"peak\"][\"neg\"], step=bench_bin_step)},\n",
    "                \"print\": {\"pos\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"print\"][\"peak\"][\"pos\"], step=bench_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"print\"][\"peak\"][\"neg\"], step=bench_bin_step)},\n",
    "                \"open\":  {\"pos\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"open\"][\"peak\"][\"pos\"], step=bench_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"open\"][\"peak\"][\"neg\"], step=bench_bin_step)},\n",
    "                \"global\":{\"pos\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"global\"][\"peak\"][\"pos\"], step=bench_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(bench_bins_pre[\"global\"][\"peak\"][\"neg\"], step=bench_bin_step)},\n",
    "                \"intra\": {\"pos\": stitch_numeric_bin_intervals_from_any(bench_bins_intra[\"intra\"][\"peak\"][\"pos\"], step=bench_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(bench_bins_intra[\"intra\"][\"peak\"][\"neg\"], step=bench_bin_step)},\n",
    "                \"post\":  {\"pos\": stitch_numeric_bin_intervals_from_any(bench_bins_post[\"post\"][\"peak\"][\"pos\"], step=bench_bin_step),\n",
    "                          \"neg\": stitch_numeric_bin_intervals_from_any(bench_bins_post[\"post\"][\"peak\"][\"neg\"], step=bench_bin_step)},\n",
    "            },\n",
    "            \"time_start_bands\": {\n",
    "                \"blue\": {\n",
    "                    \"pos\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"blue\"][\"start\"][\"pos\"]),\n",
    "                    \"neg\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"blue\"][\"start\"][\"neg\"]),\n",
    "                },\n",
    "                \"ark\": {\n",
    "                    \"pos\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"ark\"][\"start\"][\"pos\"]),\n",
    "                    \"neg\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"ark\"][\"start\"][\"neg\"]),\n",
    "                },\n",
    "                \"print\": {\n",
    "                    \"pos\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"print\"][\"start\"][\"pos\"]),\n",
    "                    \"neg\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"print\"][\"start\"][\"neg\"]),\n",
    "                },\n",
    "                \"open\": {\n",
    "                    \"pos\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"open\"][\"start\"][\"pos\"]),\n",
    "                    \"neg\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"open\"][\"start\"][\"neg\"]),\n",
    "                },\n",
    "                \"global\": {\n",
    "                    \"pos\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"global\"][\"start\"][\"pos\"]),\n",
    "                    \"neg\": stitch_timeband_intervals_from_any(timebands_pre_by_class_sign[\"global\"][\"start\"][\"neg\"]),\n",
    "                },\n",
    "                \"intra\": {\n",
    "                    \"pos\": stitch_timeband_intervals_from_any(timebands_intra_by_class_sign[\"intra\"][\"start\"][\"pos\"]),\n",
    "                    \"neg\": stitch_timeband_intervals_from_any(timebands_intra_by_class_sign[\"intra\"][\"start\"][\"neg\"]),\n",
    "                },\n",
    "                \"post\": {\n",
    "                    \"pos\": stitch_timeband_intervals_from_any(timebands_post_by_class_sign[\"post\"][\"start\"][\"pos\"]),\n",
    "                    \"neg\": stitch_timeband_intervals_from_any(timebands_post_by_class_sign[\"post\"][\"start\"][\"neg\"]),\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "\n",
    "        best = {\n",
    "            \"ticker\": cur_ticker,\n",
    "            \"bench\": bench_name_seen,\n",
    "            \"static\": {\"corr\": _json_safe(corr_static), \"beta\": _json_safe(beta_static), \"sigma\": _json_safe(sigma_static)},\n",
    "\n",
    "            \"dev_print_last5_median\": {\n",
    "                \"pos\": median_or_none(last5_print_days_pos),\n",
    "                \"neg\": median_or_none(last5_print_days_neg),\n",
    "            },\n",
    "\n",
    "            \"totals\": {\n",
    "                \"events_total\": int(events_total),\n",
    "                \"pre_total\": int(events_pre_total),\n",
    "                \"intra_total\": int(events_intra_total),\n",
    "                \"post_total\": int(events_post_total),\n",
    "            },\n",
    "\n",
    "            \"ratings\": {\n",
    "                \"blue\": _json_safe(blue_r[\"rate_any\"]),\n",
    "                \"ark\": _json_safe(ark_r[\"rate_any\"]),\n",
    "                \"print\": _json_safe(pr_r[\"rate_any\"]),\n",
    "                \"open\": _json_safe(op_r[\"rate_any\"]),\n",
    "                \"intra\": _json_safe(intra_r[\"rate_any\"]),\n",
    "                \"post\": _json_safe(post_r[\"rate_any\"]),\n",
    "                \"global\": _json_safe(gl_r[\"rate_any\"]),\n",
    "            },\n",
    "\n",
    "            \"hard_soft_share\": {\n",
    "                \"blue\":  {\"hard\": int(blue_r[\"hard\"]), \"soft\": int(blue_r[\"soft\"]), \"hard_share\": _json_safe(blue_r[\"hard_share_in_norm\"])},\n",
    "                \"ark\":   {\"hard\": int(ark_r[\"hard\"]),  \"soft\": int(ark_r[\"soft\"]),  \"hard_share\": _json_safe(ark_r[\"hard_share_in_norm\"])},\n",
    "                \"print\": {\"hard\": int(pr_r[\"hard\"]),   \"soft\": int(pr_r[\"soft\"]),   \"hard_share\": _json_safe(pr_r[\"hard_share_in_norm\"])},\n",
    "                \"open\":  {\"hard\": int(op_r[\"hard\"]),   \"soft\": int(op_r[\"soft\"]),   \"hard_share\": _json_safe(op_r[\"hard_share_in_norm\"])},\n",
    "                \"intra\": {\"hard\": int(intra_r[\"hard\"]), \"soft\": int(intra_r[\"soft\"]), \"hard_share\": _json_safe(intra_r[\"hard_share_in_norm\"])},\n",
    "                \"post\":  {\"hard\": int(post_r[\"hard\"]),  \"soft\": int(post_r[\"soft\"]),  \"hard_share\": _json_safe(post_r[\"hard_share_in_norm\"])},\n",
    "                \"global\":{\"hard\": int(gl_r[\"hard\"]),   \"soft\": int(gl_r[\"soft\"]),   \"hard_share\": _json_safe(gl_r[\"hard_share_in_norm\"])},\n",
    "            },\n",
    "\n",
    "            \"avg_hard_delay_sec\": {\n",
    "                \"blue\": _json_safe(avg_hard_delay(\"blue\")),\n",
    "                \"ark\": _json_safe(avg_hard_delay(\"ark\")),\n",
    "                \"print\": _json_safe(avg_hard_delay(\"print\")),\n",
    "                \"open\": _json_safe(avg_hard_delay(\"open\")),\n",
    "                \"intra\": _json_safe(avg_hard_delay(\"intra\")),\n",
    "                \"post\": _json_safe(avg_hard_delay(\"post\")),\n",
    "                \"global\": _json_safe(avg_hard_delay(\"global\")),\n",
    "            },\n",
    "\n",
    "            \"best_windows_any\": {\n",
    "                \"rule\": {\"min_rate\": 0.60, \"min_total\": 4, \"rate\": \"(hard+soft)/total\"},\n",
    "                \"stitched\": best_windows_any,\n",
    "            },\n",
    "\n",
    "            \"params\": {\"dev_thr\": float(dev_thr), \"norm_thr\": float(norm_thr), \"soft_ratio\": float(soft_ratio)},\n",
    "        }\n",
    "\n",
    "        best_params_f.write(json.dumps(best, ensure_ascii=False) + \"\\n\")\n",
    "        reset_ticker_state()\n",
    "        \n",
    "    # ---------------- processing chunks ----------------\n",
    "    def process_chunk(chunk: \"pd.DataFrame\", ci: int):\n",
    "        nonlocal cur_ticker, cur_day\n",
    "        nonlocal bench_name_seen, static_triplet_set, corr_static, beta_static, sigma_static\n",
    "        nonlocal pre_active, intra_active, post_active\n",
    "\n",
    "        req = {\"ticker\", \"date\", \"dt\", \"dev_sig\"}\n",
    "        if not req.issubset(chunk.columns):\n",
    "            raise KeyError(f\"Input must contain columns: {sorted(req)}\")\n",
    "\n",
    "        # If not sorted — make it sorted once (vectorized), no per-row parse_dt\n",
    "        if not assume_sorted:\n",
    "            chunk[\"dt\"] = pd.to_datetime(chunk[\"dt\"], errors=\"coerce\", utc=True)\n",
    "            chunk.sort_values([\"ticker\", \"date\", \"dt\"], inplace=True)\n",
    "\n",
    "        def col(name):\n",
    "            return chunk[name] if name in chunk.columns else pd.Series(np.nan, index=chunk.index)\n",
    "\n",
    "        s_ticker = col(\"ticker\")\n",
    "        s_date   = col(\"date\")\n",
    "\n",
    "        # ✅ Vectorized datetime + numeric parse\n",
    "        s_dt_ts  = pd.to_datetime(col(\"dt\"), errors=\"coerce\", utc=True)  # tz-aware Timestamp (UTC)\n",
    "        s_dev    = pd.to_numeric(col(\"dev_sig\"), errors=\"coerce\")\n",
    "\n",
    "        s_bench_name = col(\"bench\")\n",
    "        s_corr  = col(\"corr\")\n",
    "        s_beta  = col(\"beta\")\n",
    "        s_sigma = col(\"sigma\")\n",
    "\n",
    "        s_bench_num = (\n",
    "            pd.to_numeric(col(BENCH_NUM_FIELD), errors=\"coerce\")\n",
    "            if BENCH_NUM_FIELD in chunk.columns\n",
    "            else pd.Series(np.nan, index=chunk.index)\n",
    "        )\n",
    "        s_stock_pct = (\n",
    "            pd.to_numeric(col(STOCK_NUM_FIELD), errors=\"coerce\")\n",
    "            if STOCK_NUM_FIELD in chunk.columns\n",
    "            else pd.Series(np.nan, index=chunk.index)\n",
    "        )\n",
    "\n",
    "        # ✅ Build a fast mask upfront (drop bad dt/dev and ignored windows) BEFORE loop\n",
    "        dt_ok  = s_dt_ts.notna()\n",
    "        dev_ok = np.isfinite(s_dev.to_numpy(dtype=\"float64\", copy=False))\n",
    "        mask = (dt_ok.to_numpy(copy=False) & dev_ok)\n",
    "\n",
    "        if mask.any():\n",
    "            # ignored windows mask using hour/min (vectorized)\n",
    "            dt2 = s_dt_ts[mask]\n",
    "            h = dt2.dt.hour.to_numpy(dtype=\"int16\", copy=False)\n",
    "            m = dt2.dt.minute.to_numpy(dtype=\"int16\", copy=False)\n",
    "\n",
    "            # vectorized ignored windows:\n",
    "            # IGNORE_WINDOWS = [((3, 58), (4, 5)), ((7, 58), (8, 5))]\n",
    "            # condition: a <= (h,m) <= b for any window\n",
    "            def _in_win(h, m, a, b):\n",
    "                ah, am = a\n",
    "                bh, bm = b\n",
    "                return ((h > ah) | ((h == ah) & (m >= am))) & ((h < bh) | ((h == bh) & (m <= bm)))\n",
    "\n",
    "            ig = np.zeros_like(h, dtype=bool)\n",
    "            for a, b in IGNORE_WINDOWS:\n",
    "                ig |= _in_win(h, m, a, b)\n",
    "\n",
    "            # apply back to global mask\n",
    "            idx_mask = np.flatnonzero(mask)\n",
    "            mask[idx_mask] = ~ig\n",
    "\n",
    "        # nothing useful in chunk\n",
    "        if not mask.any():\n",
    "            return\n",
    "\n",
    "\n",
    "        # ✅ Build compact arrays (keep original order)\n",
    "        # Convert to python datetime ONLY for the filtered rows (cheap vs per-row parse_dt)\n",
    "        dt_py = s_dt_ts[mask].dt.to_pydatetime()  # ndarray of datetime (tz-aware)\n",
    "        tk_arr = s_ticker[mask].to_numpy(copy=False)\n",
    "        ds_arr = s_date[mask].to_numpy(copy=False)\n",
    "        dev_arr = s_dev[mask].to_numpy(dtype=\"float64\", copy=False)\n",
    "        bench_arr = s_bench_num[mask].to_numpy(dtype=\"float64\", copy=False)\n",
    "        stock_arr = s_stock_pct[mask].to_numpy(dtype=\"float64\", copy=False)\n",
    "\n",
    "        # ✅ per-row sources for bench/static (aligned with filtered rows)\n",
    "        bench_name_arr = (s_bench_name[mask].to_numpy(copy=False) if \"bench\" in chunk.columns else None)\n",
    "        corr_arr  = (s_corr[mask].to_numpy(copy=False) if \"corr\" in chunk.columns else None)\n",
    "        beta_arr  = (s_beta[mask].to_numpy(copy=False) if \"beta\" in chunk.columns else None)\n",
    "        sigma_arr = (s_sigma[mask].to_numpy(copy=False) if \"sigma\" in chunk.columns else None)\n",
    "\n",
    "        # Precompute hour/min for fast tuple t\n",
    "        dt2 = s_dt_ts[mask]\n",
    "        h_arr = dt2.dt.hour.to_numpy(dtype=\"int16\", copy=False)\n",
    "        m_arr = dt2.dt.minute.to_numpy(dtype=\"int16\", copy=False)\n",
    "\n",
    "        n = len(dev_arr)\n",
    "        for i in range(n):\n",
    "            tk = tk_arr[i]\n",
    "            ds = ds_arr[i]\n",
    "            dt_now = dt_py[i]         # datetime with tzinfo\n",
    "            dev_now = dev_arr[i]      # float\n",
    "            bench_num = bench_arr[i]  # float (may be nan)\n",
    "            stock_pct = stock_arr[i]  # float (may be nan)\n",
    "\n",
    "            # cheap time tuple\n",
    "            t = (int(h_arr[i]), int(m_arr[i]))\n",
    "\n",
    "            # ticker boundary\n",
    "            if cur_ticker is not None and tk != cur_ticker:\n",
    "                flush_current_ticker()\n",
    "                cur_ticker, cur_day = tk, ds\n",
    "                on_new_day()\n",
    "\n",
    "            if cur_ticker is None:\n",
    "                cur_ticker, cur_day = tk, ds\n",
    "                on_new_day()\n",
    "\n",
    "            # ✅ set bench/static ONLY from the first valid row of THIS ticker\n",
    "            if bench_name_seen is None and bench_name_arr is not None:\n",
    "                bn = bench_name_arr[i]\n",
    "                if pd.notna(bn) and str(bn).strip():\n",
    "                    bench_name_seen = str(bn)\n",
    "\n",
    "            if (not static_triplet_set) and (corr_arr is not None) and (beta_arr is not None) and (sigma_arr is not None):\n",
    "                c = corr_arr[i]\n",
    "                b = beta_arr[i]\n",
    "                s = sigma_arr[i]\n",
    "                if pd.notna(c) and pd.notna(b) and pd.notna(s):\n",
    "                    corr_static, beta_static, sigma_static = c, b, s\n",
    "                    static_triplet_set = True\n",
    "\n",
    "            # day boundary\n",
    "            if ds != cur_day:\n",
    "                cur_day = ds\n",
    "                on_new_day()\n",
    "\n",
    "            # finalize PRE after OPEN window\n",
    "            if pre_active and (t > OPEN_TO):\n",
    "                finalize_pre_event(reason=\"passed_open_window\")\n",
    "\n",
    "            # start PRE in BLUE or ARK window\n",
    "            if (not pre_active) and (in_range(t, BLUE_FROM, BLUE_TO) or in_range(t, ARK_FROM, ARK_TO)):\n",
    "                if abs(float(dev_now)) >= dev_thr:\n",
    "                    start_pre_event(dt_now, dev_now, stock_pct, bench_num)\n",
    "\n",
    "            if pre_active:\n",
    "                pre_process_tick(dt_now, dev_now, stock_pct, bench_num)\n",
    "\n",
    "            # finalize INTRA after window\n",
    "            if intra_active and (t > INTRA_TO):\n",
    "                finalize_intra_event(reason=\"passed_intra_window\")\n",
    "\n",
    "            # start INTRA inside 10:00-12:00\n",
    "            if (not intra_active) and in_range(t, INTRA_FROM, INTRA_TO):\n",
    "                if abs(float(dev_now)) >= dev_thr:\n",
    "                    start_intra_event(dt_now, dev_now, stock_pct, bench_num)\n",
    "\n",
    "            if intra_active and in_range(t, INTRA_FROM, INTRA_TO):\n",
    "                intra_process_tick(dt_now, dev_now, stock_pct, bench_num)\n",
    "\n",
    "            # finalize POST after window\n",
    "            if post_active and (t > POST_TO):\n",
    "                finalize_post_event(reason=\"passed_post_window\")\n",
    "\n",
    "            # start POST inside 16:01-19:59\n",
    "            if (not post_active) and in_range(t, POST_FROM, POST_TO):\n",
    "                if abs(float(dev_now)) >= dev_thr:\n",
    "                    start_post_event(dt_now, dev_now, stock_pct, bench_num)\n",
    "\n",
    "            if post_active and in_range(t, POST_FROM, POST_TO):\n",
    "                post_process_tick(dt_now, dev_now, stock_pct, bench_num)\n",
    "\n",
    "\n",
    "    # ---------------- main read loop ----------------\n",
    "    t0 = time.time()\n",
    "    total_rows = 0\n",
    "    last_rows = 0\n",
    "    last_ts = t0\n",
    "\n",
    "    is_parquet = str(input_path).lower().endswith((\".parquet\", \".pq\", \".parq\"))\n",
    "    print(\n",
    "        f\"▶️ START v12 exporter+BLUE+POST file={input_path} parquet={is_parquet} \"\n",
    "        f\"dev_thr={dev_thr} norm_thr={norm_thr} soft_ratio={soft_ratio} min_events={min_events_per_ticker}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        if is_parquet and parquet_use_pyarrow:\n",
    "            import pyarrow.parquet as pq\n",
    "            pf = pq.ParquetFile(input_path)\n",
    "\n",
    "            wanted = [\"ticker\", \"date\", \"dt\", \"dev_sig\", \"bench\", \"corr\", \"beta\", \"sigma\", STOCK_NUM_FIELD, BENCH_NUM_FIELD]\n",
    "            cols = [c for c in wanted if c in pf.schema.names]\n",
    "\n",
    "            for ci in range(pf.num_row_groups):\n",
    "                chunk = pf.read_row_group(ci, columns=cols).to_pandas()\n",
    "                process_chunk(chunk, ci + 1)\n",
    "                total_rows += len(chunk)\n",
    "\n",
    "                if (ci + 1) % log_every_n_chunks == 0:\n",
    "                    now = time.time()\n",
    "                    rps = (total_rows - last_rows) / max(now - last_ts, 1e-6)\n",
    "                    print(f\"[rg {ci+1:>4}/{pf.num_row_groups}] rows={total_rows:,} speed={rps:,.0f}/s elapsed={now-t0:,.1f}s\")\n",
    "                    last_rows, last_ts = total_rows, now\n",
    "\n",
    "                # cheaper cleanup (avoid gc.collect each chunk)\n",
    "                del chunk\n",
    "                if (ci + 1) % max(10, log_every_n_chunks * 2) == 0:\n",
    "                    gc.collect()\n",
    "\n",
    "        elif not is_parquet:\n",
    "            reader = pd.read_csv(input_path, compression=\"infer\", low_memory=False, chunksize=csv_chunksize)\n",
    "            for ci, chunk in enumerate(reader, 1):\n",
    "                process_chunk(chunk, ci)\n",
    "                total_rows += len(chunk)\n",
    "\n",
    "                if ci % log_every_n_chunks == 0:\n",
    "                    now = time.time()\n",
    "                    rps =qar = (total_rows - last_rows) / max(now - last_ts, 1e-6)\n",
    "                    print(f\"[chunk {ci:>5}] rows={total_rows:,} speed={rps:,.0f}/s elapsed={now-t0:,.1f}s\")\n",
    "                    last_rows, last_ts = total_rows, now\n",
    "\n",
    "                del chunk\n",
    "                if ci % max(10, log_every_n_chunks * 2) == 0:\n",
    "                    gc.collect()\n",
    "\n",
    "        else:\n",
    "            df = pd.read_parquet(input_path)\n",
    "            step = 1_000_000\n",
    "            for ci, start in enumerate(range(0, len(df), step), 1):\n",
    "                chunk = df.iloc[start:start + step]\n",
    "                process_chunk(chunk, ci)\n",
    "                total_rows += len(chunk)\n",
    "\n",
    "                if ci % log_every_n_chunks == 0:\n",
    "                    now = time.time()\n",
    "                    rps = (total_rows - last_rows) / max(now - last_ts, 1e-6)\n",
    "                    print(f\"[chunk {ci:>5}] rows={total_rows:,} speed={rps:,.0f}/s elapsed={now-t0:,.1f}s\")\n",
    "                    last_rows, last_ts = total_rows, now\n",
    "\n",
    "                del chunk\n",
    "                if ci % max(10, log_every_n_chunks * 2) == 0:\n",
    "                    gc.collect()\n",
    "\n",
    "        flush_current_ticker()\n",
    "        print(f\"🏁 DONE rows={total_rows:,} -> onefile={output_onefile_jsonl} summary={output_summary_csv} best_params={output_best_params_jsonl}\")\n",
    "\n",
    "    finally:\n",
    "        onefile_f.close()\n",
    "        best_params_f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eea8ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# devsig_stream_stats_v12_exporter(\n",
    "#     input_path=\"ARBITRAGE/final_filtered.parquet\",\n",
    "#     output_onefile_jsonl=\"ARBITRAGE/onefile.jsonl\",\n",
    "#     output_summary_csv=\"ARBITRAGE/summary.csv\",\n",
    "#     output_best_params_jsonl=\"ARBITRAGE/best_params.jsonl\",\n",
    "\n",
    "#     dev_thr=0.30,\n",
    "#     norm_thr=0.10,\n",
    "#     soft_ratio=3.0,\n",
    "\n",
    "#     include_events_pre=False,\n",
    "#     include_events_intra=False,\n",
    "#     max_events_per_ticker=500,\n",
    "\n",
    "#     min_events_per_ticker=10,\n",
    "\n",
    "#     start_band_minutes=30,\n",
    "#     norm_band_minutes=30,\n",
    "\n",
    "#     sigma_bin_min=0.2,\n",
    "#     sigma_bin_max=2.7,\n",
    "#     sigma_bin_step=0.1,\n",
    "\n",
    "#     bench_bin_min=-3.0,\n",
    "#     bench_bin_max=3.0,\n",
    "#     bench_bin_step=0.1,\n",
    "\n",
    "#     open_series_downsample_seconds=60,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "419a1c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using FINAL parquet (no sorting): C:\\datum-api-examples-main\\OriON\\CRACEN\\final.parquet\n",
      "▶️ START v12 exporter+BLUE+POST file=C:\\datum-api-examples-main\\OriON\\CRACEN\\final.parquet parquet=True dev_thr=0.2 norm_thr=0.1 soft_ratio=3.0 min_events=10\n",
      "[rg    5/2746] rows=77,566 speed=360,785/s elapsed=0.2s\n",
      "[rg   10/2746] rows=143,178 speed=440,289/s elapsed=0.4s\n",
      "[rg   15/2746] rows=272,002 speed=446,799/s elapsed=0.7s\n",
      "[rg   20/2746] rows=328,722 speed=363,057/s elapsed=0.8s\n",
      "[rg   25/2746] rows=418,517 speed=410,499/s elapsed=1.0s\n",
      "[rg   30/2746] rows=525,780 speed=430,618/s elapsed=1.3s\n",
      "[rg   35/2746] rows=581,345 speed=489,503/s elapsed=1.4s\n",
      "[rg   40/2746] rows=669,418 speed=462,854/s elapsed=1.6s\n",
      "[rg   45/2746] rows=759,716 speed=457,993/s elapsed=1.8s\n",
      "[rg   50/2746] rows=844,828 speed=425,665/s elapsed=2.0s\n",
      "[rg   55/2746] rows=938,074 speed=474,558/s elapsed=2.2s\n",
      "[rg   60/2746] rows=1,055,806 speed=462,531/s elapsed=2.4s\n",
      "[rg   65/2746] rows=1,118,892 speed=368,522/s elapsed=2.6s\n",
      "[rg   70/2746] rows=1,203,393 speed=397,136/s elapsed=2.8s\n",
      "[rg   75/2746] rows=1,270,297 speed=402,431/s elapsed=3.0s\n",
      "[rg   80/2746] rows=1,342,700 speed=398,851/s elapsed=3.2s\n",
      "[rg   85/2746] rows=1,398,807 speed=422,469/s elapsed=3.3s\n",
      "[rg   90/2746] rows=1,474,270 speed=421,499/s elapsed=3.5s\n",
      "[rg   95/2746] rows=1,552,034 speed=417,408/s elapsed=3.7s\n",
      "[rg  100/2746] rows=1,616,970 speed=544,853/s elapsed=3.8s\n",
      "[rg  105/2746] rows=1,715,643 speed=443,925/s elapsed=4.0s\n",
      "[rg  110/2746] rows=1,750,233 speed=446,781/s elapsed=4.1s\n",
      "[rg  115/2746] rows=1,797,677 speed=345,329/s elapsed=4.2s\n",
      "[rg  120/2746] rows=1,866,492 speed=469,190/s elapsed=4.4s\n",
      "[rg  125/2746] rows=1,949,329 speed=417,861/s elapsed=4.6s\n",
      "[rg  130/2746] rows=2,030,715 speed=415,368/s elapsed=4.8s\n",
      "[rg  135/2746] rows=2,080,351 speed=381,663/s elapsed=4.9s\n",
      "[rg  140/2746] rows=2,153,099 speed=462,879/s elapsed=5.0s\n",
      "[rg  145/2746] rows=2,219,624 speed=397,199/s elapsed=5.2s\n",
      "[rg  150/2746] rows=2,283,673 speed=380,340/s elapsed=5.4s\n",
      "[rg  155/2746] rows=2,342,826 speed=295,928/s elapsed=5.6s\n",
      "[rg  160/2746] rows=2,411,984 speed=411,101/s elapsed=5.7s\n",
      "[rg  165/2746] rows=2,486,367 speed=505,416/s elapsed=5.9s\n",
      "[rg  170/2746] rows=2,547,057 speed=404,938/s elapsed=6.0s\n",
      "[rg  175/2746] rows=2,626,022 speed=428,533/s elapsed=6.2s\n",
      "[rg  180/2746] rows=2,664,105 speed=382,172/s elapsed=6.3s\n",
      "[rg  185/2746] rows=2,710,168 speed=343,938/s elapsed=6.5s\n",
      "[rg  190/2746] rows=2,776,808 speed=379,332/s elapsed=6.6s\n",
      "[rg  195/2746] rows=2,863,230 speed=397,974/s elapsed=6.9s\n",
      "[rg  200/2746] rows=2,944,524 speed=406,704/s elapsed=7.1s\n",
      "[rg  205/2746] rows=3,006,024 speed=381,030/s elapsed=7.2s\n",
      "[rg  210/2746] rows=3,105,212 speed=477,770/s elapsed=7.4s\n",
      "[rg  215/2746] rows=3,159,727 speed=437,136/s elapsed=7.5s\n",
      "[rg  220/2746] rows=3,257,894 speed=530,227/s elapsed=7.7s\n",
      "[rg  225/2746] rows=3,309,902 speed=396,203/s elapsed=7.9s\n",
      "[rg  230/2746] rows=3,390,733 speed=493,823/s elapsed=8.0s\n",
      "[rg  235/2746] rows=3,469,344 speed=429,025/s elapsed=8.2s\n",
      "[rg  240/2746] rows=3,569,332 speed=474,214/s elapsed=8.4s\n",
      "[rg  245/2746] rows=3,644,942 speed=356,114/s elapsed=8.6s\n",
      "[rg  250/2746] rows=3,735,062 speed=401,115/s elapsed=8.9s\n",
      "[rg  255/2746] rows=3,809,016 speed=434,332/s elapsed=9.0s\n",
      "[rg  260/2746] rows=3,876,878 speed=392,419/s elapsed=9.2s\n",
      "[rg  265/2746] rows=3,928,234 speed=350,572/s elapsed=9.3s\n",
      "[rg  270/2746] rows=3,991,042 speed=487,461/s elapsed=9.5s\n",
      "[rg  275/2746] rows=4,024,707 speed=296,283/s elapsed=9.6s\n",
      "[rg  280/2746] rows=4,187,818 speed=554,583/s elapsed=9.9s\n",
      "[rg  285/2746] rows=4,296,614 speed=410,901/s elapsed=10.2s\n",
      "[rg  290/2746] rows=4,393,869 speed=472,830/s elapsed=10.4s\n",
      "[rg  295/2746] rows=4,496,862 speed=470,224/s elapsed=10.6s\n",
      "[rg  300/2746] rows=4,572,789 speed=416,363/s elapsed=10.8s\n",
      "[rg  305/2746] rows=4,649,164 speed=439,819/s elapsed=10.9s\n",
      "[rg  310/2746] rows=4,720,723 speed=414,257/s elapsed=11.1s\n",
      "[rg  315/2746] rows=4,779,372 speed=406,728/s elapsed=11.2s\n",
      "[rg  320/2746] rows=4,844,243 speed=388,845/s elapsed=11.4s\n",
      "[rg  325/2746] rows=4,962,996 speed=508,593/s elapsed=11.6s\n",
      "[rg  330/2746] rows=5,046,840 speed=447,454/s elapsed=11.8s\n",
      "[rg  335/2746] rows=5,092,391 speed=350,605/s elapsed=12.0s\n",
      "[rg  340/2746] rows=5,185,458 speed=465,841/s elapsed=12.2s\n",
      "[rg  345/2746] rows=5,246,243 speed=364,412/s elapsed=12.3s\n",
      "[rg  350/2746] rows=5,289,565 speed=358,751/s elapsed=12.5s\n",
      "[rg  355/2746] rows=5,342,317 speed=360,684/s elapsed=12.6s\n",
      "[rg  360/2746] rows=5,402,244 speed=401,963/s elapsed=12.7s\n",
      "[rg  365/2746] rows=5,441,188 speed=355,656/s elapsed=12.9s\n",
      "[rg  370/2746] rows=5,508,313 speed=537,208/s elapsed=13.0s\n",
      "[rg  375/2746] rows=5,595,817 speed=403,631/s elapsed=13.2s\n",
      "[rg  380/2746] rows=5,725,206 speed=516,581/s elapsed=13.4s\n",
      "[rg  385/2746] rows=5,788,481 speed=379,838/s elapsed=13.6s\n",
      "[rg  390/2746] rows=5,905,479 speed=467,621/s elapsed=13.9s\n",
      "[rg  395/2746] rows=5,957,637 speed=332,946/s elapsed=14.0s\n",
      "[rg  400/2746] rows=6,016,712 speed=411,441/s elapsed=14.2s\n",
      "[rg  405/2746] rows=6,099,135 speed=403,387/s elapsed=14.4s\n",
      "[rg  410/2746] rows=6,189,823 speed=425,835/s elapsed=14.6s\n",
      "[rg  415/2746] rows=6,277,291 speed=435,444/s elapsed=14.8s\n",
      "[rg  420/2746] rows=6,363,562 speed=433,214/s elapsed=15.0s\n",
      "[rg  425/2746] rows=6,444,547 speed=455,840/s elapsed=15.2s\n",
      "[rg  430/2746] rows=6,536,315 speed=484,669/s elapsed=15.4s\n",
      "[rg  435/2746] rows=6,637,587 speed=410,079/s elapsed=15.6s\n",
      "[rg  440/2746] rows=6,699,821 speed=366,815/s elapsed=15.8s\n",
      "[rg  445/2746] rows=6,757,355 speed=391,729/s elapsed=15.9s\n",
      "[rg  450/2746] rows=6,843,493 speed=419,364/s elapsed=16.1s\n",
      "[rg  455/2746] rows=6,932,933 speed=421,013/s elapsed=16.3s\n",
      "[rg  460/2746] rows=7,049,733 speed=494,264/s elapsed=16.6s\n",
      "[rg  465/2746] rows=7,100,735 speed=381,279/s elapsed=16.7s\n",
      "[rg  470/2746] rows=7,190,271 speed=441,237/s elapsed=16.9s\n",
      "[rg  475/2746] rows=7,267,948 speed=422,673/s elapsed=17.1s\n",
      "[rg  480/2746] rows=7,356,233 speed=403,968/s elapsed=17.3s\n",
      "[rg  485/2746] rows=7,454,893 speed=465,331/s elapsed=17.5s\n",
      "[rg  490/2746] rows=7,593,676 speed=520,482/s elapsed=17.8s\n",
      "[rg  495/2746] rows=7,683,191 speed=447,159/s elapsed=18.0s\n",
      "[rg  500/2746] rows=7,745,466 speed=410,173/s elapsed=18.1s\n",
      "[rg  505/2746] rows=7,788,686 speed=665,301/s elapsed=18.2s\n",
      "[rg  510/2746] rows=7,839,274 speed=391,438/s elapsed=18.3s\n",
      "[rg  515/2746] rows=7,894,269 speed=392,205/s elapsed=18.5s\n",
      "[rg  520/2746] rows=7,975,531 speed=488,174/s elapsed=18.6s\n",
      "[rg  525/2746] rows=8,040,301 speed=413,048/s elapsed=18.8s\n",
      "[rg  530/2746] rows=8,103,055 speed=396,541/s elapsed=19.0s\n",
      "[rg  535/2746] rows=8,167,614 speed=387,743/s elapsed=19.1s\n",
      "[rg  540/2746] rows=8,231,774 speed=464,505/s elapsed=19.3s\n",
      "[rg  545/2746] rows=8,303,914 speed=413,701/s elapsed=19.4s\n",
      "[rg  550/2746] rows=8,396,384 speed=492,123/s elapsed=19.6s\n",
      "[rg  555/2746] rows=8,524,561 speed=438,199/s elapsed=19.9s\n",
      "[rg  560/2746] rows=8,592,726 speed=431,915/s elapsed=20.1s\n",
      "[rg  565/2746] rows=8,653,881 speed=366,520/s elapsed=20.2s\n",
      "[rg  570/2746] rows=8,734,648 speed=440,189/s elapsed=20.4s\n",
      "[rg  575/2746] rows=8,788,912 speed=405,010/s elapsed=20.6s\n",
      "[rg  580/2746] rows=8,840,191 speed=441,367/s elapsed=20.7s\n",
      "[rg  585/2746] rows=8,891,632 speed=341,500/s elapsed=20.8s\n",
      "[rg  590/2746] rows=8,979,861 speed=529,590/s elapsed=21.0s\n",
      "[rg  595/2746] rows=9,060,788 speed=406,682/s elapsed=21.2s\n",
      "[rg  600/2746] rows=9,158,867 speed=486,672/s elapsed=21.4s\n",
      "[rg  605/2746] rows=9,229,215 speed=421,882/s elapsed=21.6s\n",
      "[rg  610/2746] rows=9,363,308 speed=621,152/s elapsed=21.8s\n",
      "[rg  615/2746] rows=9,431,726 speed=445,229/s elapsed=21.9s\n",
      "[rg  620/2746] rows=9,514,309 speed=420,177/s elapsed=22.1s\n",
      "[rg  625/2746] rows=9,592,357 speed=453,128/s elapsed=22.3s\n",
      "[rg  630/2746] rows=9,617,312 speed=329,300/s elapsed=22.4s\n",
      "[rg  635/2746] rows=9,676,355 speed=433,357/s elapsed=22.5s\n",
      "[rg  640/2746] rows=9,801,239 speed=501,227/s elapsed=22.8s\n",
      "[rg  645/2746] rows=9,851,308 speed=361,749/s elapsed=22.9s\n",
      "[rg  650/2746] rows=9,919,139 speed=452,460/s elapsed=23.0s\n",
      "[rg  655/2746] rows=9,970,845 speed=398,558/s elapsed=23.2s\n",
      "[rg  660/2746] rows=10,052,710 speed=545,068/s elapsed=23.3s\n",
      "[rg  665/2746] rows=10,117,824 speed=389,422/s elapsed=23.5s\n",
      "[rg  670/2746] rows=10,166,781 speed=391,737/s elapsed=23.6s\n",
      "[rg  675/2746] rows=10,213,021 speed=360,278/s elapsed=23.7s\n",
      "[rg  680/2746] rows=10,271,351 speed=448,833/s elapsed=23.9s\n",
      "[rg  685/2746] rows=10,317,251 speed=308,988/s elapsed=24.0s\n",
      "[rg  690/2746] rows=10,360,276 speed=423,209/s elapsed=24.1s\n",
      "[rg  695/2746] rows=10,409,723 speed=360,304/s elapsed=24.3s\n",
      "[rg  700/2746] rows=10,525,856 speed=502,723/s elapsed=24.5s\n",
      "[rg  705/2746] rows=10,593,424 speed=510,310/s elapsed=24.6s\n",
      "[rg  710/2746] rows=10,655,579 speed=446,520/s elapsed=24.8s\n",
      "[rg  715/2746] rows=10,708,969 speed=365,046/s elapsed=24.9s\n",
      "[rg  720/2746] rows=10,773,215 speed=477,164/s elapsed=25.0s\n",
      "[rg  725/2746] rows=10,839,857 speed=398,211/s elapsed=25.2s\n",
      "[rg  730/2746] rows=10,892,997 speed=470,931/s elapsed=25.3s\n",
      "[rg  735/2746] rows=10,918,102 speed=241,217/s elapsed=25.4s\n",
      "[rg  740/2746] rows=10,956,208 speed=381,130/s elapsed=25.5s\n",
      "[rg  745/2746] rows=11,041,981 speed=428,735/s elapsed=25.7s\n",
      "[rg  750/2746] rows=11,079,117 speed=385,897/s elapsed=25.8s\n",
      "[rg  755/2746] rows=11,211,025 speed=564,940/s elapsed=26.1s\n",
      "[rg  760/2746] rows=11,292,108 speed=399,113/s elapsed=26.3s\n",
      "[rg  765/2746] rows=11,362,036 speed=436,459/s elapsed=26.4s\n",
      "[rg  770/2746] rows=11,493,635 speed=517,514/s elapsed=26.7s\n",
      "[rg  775/2746] rows=11,629,581 speed=579,250/s elapsed=26.9s\n",
      "[rg  780/2746] rows=11,731,389 speed=616,322/s elapsed=27.1s\n",
      "[rg  785/2746] rows=11,789,398 speed=347,704/s elapsed=27.2s\n",
      "[rg  790/2746] rows=11,869,490 speed=423,786/s elapsed=27.4s\n",
      "[rg  795/2746] rows=11,944,024 speed=462,283/s elapsed=27.6s\n",
      "[rg  800/2746] rows=12,020,900 speed=499,098/s elapsed=27.7s\n",
      "[rg  805/2746] rows=12,100,134 speed=472,488/s elapsed=27.9s\n",
      "[rg  810/2746] rows=12,158,753 speed=359,108/s elapsed=28.1s\n",
      "[rg  815/2746] rows=12,228,178 speed=465,389/s elapsed=28.2s\n",
      "[rg  820/2746] rows=12,301,606 speed=450,662/s elapsed=28.4s\n",
      "[rg  825/2746] rows=12,381,739 speed=393,234/s elapsed=28.6s\n",
      "[rg  830/2746] rows=12,442,279 speed=452,806/s elapsed=28.7s\n",
      "[rg  835/2746] rows=12,519,395 speed=381,145/s elapsed=28.9s\n",
      "[rg  840/2746] rows=12,657,375 speed=551,423/s elapsed=29.2s\n",
      "[rg  845/2746] rows=12,805,582 speed=548,732/s elapsed=29.5s\n",
      "[rg  850/2746] rows=12,905,971 speed=475,355/s elapsed=29.7s\n",
      "[rg  855/2746] rows=12,979,101 speed=389,214/s elapsed=29.9s\n",
      "[rg  860/2746] rows=13,022,294 speed=400,355/s elapsed=30.0s\n",
      "[rg  865/2746] rows=13,087,970 speed=424,910/s elapsed=30.1s\n",
      "[rg  870/2746] rows=13,132,206 speed=386,423/s elapsed=30.2s\n",
      "[rg  875/2746] rows=13,203,144 speed=445,627/s elapsed=30.4s\n",
      "[rg  880/2746] rows=13,236,415 speed=369,576/s elapsed=30.5s\n",
      "[rg  885/2746] rows=13,290,274 speed=394,086/s elapsed=30.6s\n",
      "[rg  890/2746] rows=13,406,117 speed=462,921/s elapsed=30.9s\n",
      "[rg  895/2746] rows=13,462,403 speed=420,363/s elapsed=31.0s\n",
      "[rg  900/2746] rows=13,515,169 speed=461,373/s elapsed=31.1s\n",
      "[rg  905/2746] rows=13,589,018 speed=485,551/s elapsed=31.3s\n",
      "[rg  910/2746] rows=13,621,905 speed=380,534/s elapsed=31.4s\n",
      "[rg  915/2746] rows=13,701,049 speed=483,251/s elapsed=31.5s\n",
      "[rg  920/2746] rows=13,752,007 speed=509,136/s elapsed=31.6s\n",
      "[rg  925/2746] rows=13,812,910 speed=441,650/s elapsed=31.8s\n",
      "[rg  930/2746] rows=13,885,121 speed=494,613/s elapsed=31.9s\n",
      "[rg  935/2746] rows=13,927,695 speed=417,295/s elapsed=32.0s\n",
      "[rg  940/2746] rows=14,005,212 speed=427,633/s elapsed=32.2s\n",
      "[rg  945/2746] rows=14,078,411 speed=399,081/s elapsed=32.4s\n",
      "[rg  950/2746] rows=14,179,762 speed=427,603/s elapsed=32.6s\n",
      "[rg  955/2746] rows=14,248,681 speed=382,986/s elapsed=32.8s\n",
      "[rg  960/2746] rows=14,307,200 speed=424,131/s elapsed=32.9s\n",
      "[rg  965/2746] rows=14,395,603 speed=451,880/s elapsed=33.1s\n",
      "[rg  970/2746] rows=14,480,605 speed=423,670/s elapsed=33.3s\n",
      "[rg  975/2746] rows=14,549,466 speed=402,929/s elapsed=33.5s\n",
      "[rg  980/2746] rows=14,633,023 speed=441,886/s elapsed=33.7s\n",
      "[rg  985/2746] rows=14,757,618 speed=498,255/s elapsed=33.9s\n",
      "[rg  990/2746] rows=14,808,410 speed=399,212/s elapsed=34.1s\n",
      "[rg  995/2746] rows=14,892,605 speed=439,650/s elapsed=34.2s\n",
      "[rg 1000/2746] rows=14,940,149 speed=382,802/s elapsed=34.4s\n",
      "[rg 1005/2746] rows=15,016,494 speed=422,041/s elapsed=34.6s\n",
      "[rg 1010/2746] rows=15,146,035 speed=531,687/s elapsed=34.8s\n",
      "[rg 1015/2746] rows=15,218,046 speed=394,216/s elapsed=35.0s\n",
      "[rg 1020/2746] rows=15,276,305 speed=456,406/s elapsed=35.1s\n",
      "[rg 1025/2746] rows=15,311,404 speed=309,926/s elapsed=35.2s\n",
      "[rg 1030/2746] rows=15,389,632 speed=520,387/s elapsed=35.4s\n",
      "[rg 1035/2746] rows=15,471,469 speed=437,083/s elapsed=35.6s\n",
      "[rg 1040/2746] rows=15,554,118 speed=438,631/s elapsed=35.7s\n",
      "[rg 1045/2746] rows=15,654,344 speed=476,843/s elapsed=36.0s\n",
      "[rg 1050/2746] rows=15,722,261 speed=516,379/s elapsed=36.1s\n",
      "[rg 1055/2746] rows=15,770,925 speed=365,557/s elapsed=36.2s\n",
      "[rg 1060/2746] rows=15,838,672 speed=494,442/s elapsed=36.4s\n",
      "[rg 1065/2746] rows=15,892,705 speed=405,813/s elapsed=36.5s\n",
      "[rg 1070/2746] rows=15,979,281 speed=512,294/s elapsed=36.7s\n",
      "[rg 1075/2746] rows=16,025,441 speed=470,748/s elapsed=36.8s\n",
      "[rg 1080/2746] rows=16,109,782 speed=457,872/s elapsed=36.9s\n",
      "[rg 1085/2746] rows=16,183,013 speed=452,007/s elapsed=37.1s\n",
      "[rg 1090/2746] rows=16,251,665 speed=460,300/s elapsed=37.3s\n",
      "[rg 1095/2746] rows=16,309,978 speed=386,173/s elapsed=37.4s\n",
      "[rg 1100/2746] rows=16,408,784 speed=505,114/s elapsed=37.6s\n",
      "[rg 1105/2746] rows=16,468,147 speed=464,067/s elapsed=37.7s\n",
      "[rg 1110/2746] rows=16,540,115 speed=498,822/s elapsed=37.9s\n",
      "[rg 1115/2746] rows=16,614,754 speed=372,887/s elapsed=38.1s\n",
      "[rg 1120/2746] rows=16,689,326 speed=433,056/s elapsed=38.2s\n",
      "[rg 1125/2746] rows=16,740,316 speed=456,672/s elapsed=38.4s\n",
      "[rg 1130/2746] rows=16,826,514 speed=427,722/s elapsed=38.6s\n",
      "[rg 1135/2746] rows=16,914,044 speed=429,486/s elapsed=38.8s\n",
      "[rg 1140/2746] rows=16,968,982 speed=428,560/s elapsed=38.9s\n",
      "[rg 1145/2746] rows=17,001,865 speed=281,775/s elapsed=39.0s\n",
      "[rg 1150/2746] rows=17,096,806 speed=487,210/s elapsed=39.2s\n",
      "[rg 1155/2746] rows=17,194,581 speed=546,932/s elapsed=39.4s\n",
      "[rg 1160/2746] rows=17,270,246 speed=459,986/s elapsed=39.5s\n",
      "[rg 1165/2746] rows=17,374,083 speed=461,532/s elapsed=39.8s\n",
      "[rg 1170/2746] rows=17,460,481 speed=457,236/s elapsed=40.0s\n",
      "[rg 1175/2746] rows=17,529,157 speed=414,052/s elapsed=40.1s\n",
      "[rg 1180/2746] rows=17,576,896 speed=308,151/s elapsed=40.3s\n",
      "[rg 1185/2746] rows=17,638,853 speed=427,438/s elapsed=40.4s\n",
      "[rg 1190/2746] rows=17,700,703 speed=456,088/s elapsed=40.6s\n",
      "[rg 1195/2746] rows=17,736,411 speed=364,681/s elapsed=40.7s\n",
      "[rg 1200/2746] rows=17,826,258 speed=524,434/s elapsed=40.8s\n",
      "[rg 1205/2746] rows=17,920,130 speed=450,624/s elapsed=41.0s\n",
      "[rg 1210/2746] rows=18,003,998 speed=426,658/s elapsed=41.2s\n",
      "[rg 1215/2746] rows=18,093,034 speed=510,410/s elapsed=41.4s\n",
      "[rg 1220/2746] rows=18,116,144 speed=275,853/s elapsed=41.5s\n",
      "[rg 1225/2746] rows=18,173,511 speed=385,208/s elapsed=41.6s\n",
      "[rg 1230/2746] rows=18,233,615 speed=479,718/s elapsed=41.8s\n",
      "[rg 1235/2746] rows=18,298,659 speed=419,072/s elapsed=41.9s\n",
      "[rg 1240/2746] rows=18,360,245 speed=508,754/s elapsed=42.0s\n",
      "[rg 1245/2746] rows=18,396,126 speed=358,871/s elapsed=42.1s\n",
      "[rg 1250/2746] rows=18,456,653 speed=454,816/s elapsed=42.3s\n",
      "[rg 1255/2746] rows=18,518,742 speed=362,215/s elapsed=42.4s\n",
      "[rg 1260/2746] rows=18,577,223 speed=438,543/s elapsed=42.6s\n",
      "[rg 1265/2746] rows=18,661,529 speed=470,936/s elapsed=42.8s\n",
      "[rg 1270/2746] rows=18,731,482 speed=465,909/s elapsed=42.9s\n",
      "[rg 1275/2746] rows=18,841,525 speed=592,045/s elapsed=43.1s\n",
      "[rg 1280/2746] rows=18,933,118 speed=422,038/s elapsed=43.3s\n",
      "[rg 1285/2746] rows=19,006,274 speed=444,453/s elapsed=43.5s\n",
      "[rg 1290/2746] rows=19,091,427 speed=640,034/s elapsed=43.6s\n",
      "[rg 1295/2746] rows=19,174,962 speed=407,957/s elapsed=43.8s\n",
      "[rg 1300/2746] rows=19,230,619 speed=430,452/s elapsed=43.9s\n",
      "[rg 1305/2746] rows=19,304,925 speed=445,754/s elapsed=44.1s\n",
      "[rg 1310/2746] rows=19,394,186 speed=535,008/s elapsed=44.3s\n",
      "[rg 1315/2746] rows=19,450,662 speed=412,737/s elapsed=44.4s\n",
      "[rg 1320/2746] rows=19,493,493 speed=373,845/s elapsed=44.5s\n",
      "[rg 1325/2746] rows=19,544,625 speed=377,045/s elapsed=44.7s\n",
      "[rg 1330/2746] rows=19,578,336 speed=408,393/s elapsed=44.7s\n",
      "[rg 1335/2746] rows=19,666,313 speed=535,606/s elapsed=44.9s\n",
      "[rg 1340/2746] rows=19,724,358 speed=435,736/s elapsed=45.0s\n",
      "[rg 1345/2746] rows=19,840,697 speed=488,761/s elapsed=45.3s\n",
      "[rg 1350/2746] rows=19,919,198 speed=606,361/s elapsed=45.4s\n",
      "[rg 1355/2746] rows=20,051,777 speed=527,990/s elapsed=45.7s\n",
      "[rg 1360/2746] rows=20,140,148 speed=484,904/s elapsed=45.8s\n",
      "[rg 1365/2746] rows=20,218,061 speed=425,335/s elapsed=46.0s\n",
      "[rg 1370/2746] rows=20,308,729 speed=452,419/s elapsed=46.2s\n",
      "[rg 1375/2746] rows=20,366,319 speed=382,917/s elapsed=46.4s\n",
      "[rg 1380/2746] rows=20,459,042 speed=428,528/s elapsed=46.6s\n",
      "[rg 1385/2746] rows=20,535,780 speed=450,960/s elapsed=46.8s\n",
      "[rg 1390/2746] rows=20,610,377 speed=507,383/s elapsed=46.9s\n",
      "[rg 1395/2746] rows=20,693,113 speed=427,201/s elapsed=47.1s\n",
      "[rg 1400/2746] rows=20,744,375 speed=380,232/s elapsed=47.2s\n",
      "[rg 1405/2746] rows=20,795,841 speed=413,466/s elapsed=47.4s\n",
      "[rg 1410/2746] rows=20,952,711 speed=554,965/s elapsed=47.6s\n",
      "[rg 1415/2746] rows=21,061,722 speed=481,833/s elapsed=47.9s\n",
      "[rg 1420/2746] rows=21,140,837 speed=410,064/s elapsed=48.1s\n",
      "[rg 1425/2746] rows=21,216,494 speed=380,051/s elapsed=48.3s\n",
      "[rg 1430/2746] rows=21,313,404 speed=470,709/s elapsed=48.5s\n",
      "[rg 1435/2746] rows=21,406,449 speed=446,607/s elapsed=48.7s\n",
      "[rg 1440/2746] rows=21,480,240 speed=369,200/s elapsed=48.9s\n",
      "[rg 1445/2746] rows=21,560,725 speed=393,170/s elapsed=49.1s\n",
      "[rg 1450/2746] rows=21,617,527 speed=379,157/s elapsed=49.2s\n",
      "[rg 1455/2746] rows=21,735,619 speed=447,808/s elapsed=49.5s\n",
      "[rg 1460/2746] rows=21,861,901 speed=469,310/s elapsed=49.8s\n",
      "[rg 1465/2746] rows=21,943,698 speed=453,101/s elapsed=49.9s\n",
      "[rg 1470/2746] rows=22,023,700 speed=381,019/s elapsed=50.2s\n",
      "[rg 1475/2746] rows=22,100,036 speed=440,126/s elapsed=50.3s\n",
      "[rg 1480/2746] rows=22,152,506 speed=339,176/s elapsed=50.5s\n",
      "[rg 1485/2746] rows=22,233,226 speed=422,018/s elapsed=50.7s\n",
      "[rg 1490/2746] rows=22,311,471 speed=455,880/s elapsed=50.8s\n",
      "[rg 1495/2746] rows=22,367,676 speed=421,439/s elapsed=51.0s\n",
      "[rg 1500/2746] rows=22,436,803 speed=424,421/s elapsed=51.1s\n",
      "[rg 1505/2746] rows=22,503,651 speed=391,726/s elapsed=51.3s\n",
      "[rg 1510/2746] rows=22,557,261 speed=357,202/s elapsed=51.5s\n",
      "[rg 1515/2746] rows=22,631,875 speed=525,258/s elapsed=51.6s\n",
      "[rg 1520/2746] rows=22,703,279 speed=417,458/s elapsed=51.8s\n",
      "[rg 1525/2746] rows=22,753,269 speed=318,729/s elapsed=51.9s\n",
      "[rg 1530/2746] rows=22,833,748 speed=525,557/s elapsed=52.1s\n",
      "[rg 1535/2746] rows=22,892,186 speed=354,055/s elapsed=52.3s\n",
      "[rg 1540/2746] rows=22,958,038 speed=569,757/s elapsed=52.4s\n",
      "[rg 1545/2746] rows=23,059,357 speed=458,165/s elapsed=52.6s\n",
      "[rg 1550/2746] rows=23,126,337 speed=532,410/s elapsed=52.7s\n",
      "[rg 1555/2746] rows=23,194,768 speed=424,676/s elapsed=52.9s\n",
      "[rg 1560/2746] rows=23,299,474 speed=462,096/s elapsed=53.1s\n",
      "[rg 1565/2746] rows=23,349,439 speed=342,091/s elapsed=53.2s\n",
      "[rg 1570/2746] rows=23,438,533 speed=523,530/s elapsed=53.4s\n",
      "[rg 1575/2746] rows=23,507,083 speed=389,681/s elapsed=53.6s\n",
      "[rg 1580/2746] rows=23,585,104 speed=447,926/s elapsed=53.8s\n",
      "[rg 1585/2746] rows=23,645,637 speed=404,706/s elapsed=53.9s\n",
      "[rg 1590/2746] rows=23,715,746 speed=425,872/s elapsed=54.1s\n",
      "[rg 1595/2746] rows=23,777,384 speed=375,337/s elapsed=54.2s\n",
      "[rg 1600/2746] rows=23,859,893 speed=440,160/s elapsed=54.4s\n",
      "[rg 1605/2746] rows=23,925,580 speed=387,892/s elapsed=54.6s\n",
      "[rg 1610/2746] rows=24,014,579 speed=453,790/s elapsed=54.8s\n",
      "[rg 1615/2746] rows=24,098,570 speed=449,562/s elapsed=55.0s\n",
      "[rg 1620/2746] rows=24,194,280 speed=589,245/s elapsed=55.1s\n",
      "[rg 1625/2746] rows=24,263,571 speed=447,723/s elapsed=55.3s\n",
      "[rg 1630/2746] rows=24,353,017 speed=538,428/s elapsed=55.5s\n",
      "[rg 1635/2746] rows=24,419,711 speed=385,551/s elapsed=55.6s\n",
      "[rg 1640/2746] rows=24,492,752 speed=519,313/s elapsed=55.8s\n",
      "[rg 1645/2746] rows=24,552,599 speed=388,350/s elapsed=55.9s\n",
      "[rg 1650/2746] rows=24,618,157 speed=506,043/s elapsed=56.1s\n",
      "[rg 1655/2746] rows=24,700,322 speed=439,900/s elapsed=56.3s\n",
      "[rg 1660/2746] rows=24,751,690 speed=513,134/s elapsed=56.4s\n",
      "[rg 1665/2746] rows=24,808,263 speed=380,654/s elapsed=56.5s\n",
      "[rg 1670/2746] rows=24,895,125 speed=514,560/s elapsed=56.7s\n",
      "[rg 1675/2746] rows=24,949,425 speed=418,312/s elapsed=56.8s\n",
      "[rg 1680/2746] rows=25,023,093 speed=491,244/s elapsed=57.0s\n",
      "[rg 1685/2746] rows=25,078,019 speed=356,916/s elapsed=57.1s\n",
      "[rg 1690/2746] rows=25,130,275 speed=398,634/s elapsed=57.2s\n",
      "[rg 1695/2746] rows=25,194,345 speed=430,258/s elapsed=57.4s\n",
      "[rg 1700/2746] rows=25,296,730 speed=455,697/s elapsed=57.6s\n",
      "[rg 1705/2746] rows=25,406,161 speed=452,039/s elapsed=57.9s\n",
      "[rg 1710/2746] rows=25,442,009 speed=356,673/s elapsed=58.0s\n",
      "[rg 1715/2746] rows=25,505,160 speed=420,975/s elapsed=58.1s\n",
      "[rg 1720/2746] rows=25,617,079 speed=474,376/s elapsed=58.3s\n",
      "[rg 1725/2746] rows=25,685,557 speed=464,804/s elapsed=58.5s\n",
      "[rg 1730/2746] rows=25,759,064 speed=484,737/s elapsed=58.6s\n",
      "[rg 1735/2746] rows=25,813,907 speed=363,139/s elapsed=58.8s\n",
      "[rg 1740/2746] rows=25,878,331 speed=436,060/s elapsed=58.9s\n",
      "[rg 1745/2746] rows=25,908,726 speed=302,541/s elapsed=59.0s\n",
      "[rg 1750/2746] rows=25,997,005 speed=481,957/s elapsed=59.2s\n",
      "[rg 1755/2746] rows=26,034,046 speed=317,445/s elapsed=59.3s\n",
      "[rg 1760/2746] rows=26,104,966 speed=472,124/s elapsed=59.5s\n",
      "[rg 1765/2746] rows=26,191,651 speed=464,236/s elapsed=59.7s\n",
      "[rg 1770/2746] rows=26,342,414 speed=571,096/s elapsed=59.9s\n",
      "[rg 1775/2746] rows=26,402,298 speed=398,667/s elapsed=60.1s\n",
      "[rg 1780/2746] rows=26,471,609 speed=419,162/s elapsed=60.3s\n",
      "[rg 1785/2746] rows=26,537,575 speed=477,548/s elapsed=60.4s\n",
      "[rg 1790/2746] rows=26,600,781 speed=466,821/s elapsed=60.5s\n",
      "[rg 1795/2746] rows=26,677,855 speed=450,801/s elapsed=60.7s\n",
      "[rg 1800/2746] rows=26,735,631 speed=616,701/s elapsed=60.8s\n",
      "[rg 1805/2746] rows=26,808,935 speed=446,853/s elapsed=61.0s\n",
      "[rg 1810/2746] rows=26,880,608 speed=420,765/s elapsed=61.1s\n",
      "[rg 1815/2746] rows=26,941,016 speed=383,451/s elapsed=61.3s\n",
      "[rg 1820/2746] rows=26,982,225 speed=438,985/s elapsed=61.4s\n",
      "[rg 1825/2746] rows=27,029,977 speed=365,791/s elapsed=61.5s\n",
      "[rg 1830/2746] rows=27,086,453 speed=484,942/s elapsed=61.6s\n",
      "[rg 1835/2746] rows=27,150,226 speed=420,743/s elapsed=61.8s\n",
      "[rg 1840/2746] rows=27,202,459 speed=408,988/s elapsed=61.9s\n",
      "[rg 1845/2746] rows=27,286,507 speed=489,658/s elapsed=62.1s\n",
      "[rg 1850/2746] rows=27,317,852 speed=386,479/s elapsed=62.2s\n",
      "[rg 1855/2746] rows=27,403,126 speed=512,929/s elapsed=62.3s\n",
      "[rg 1860/2746] rows=27,458,983 speed=371,884/s elapsed=62.5s\n",
      "[rg 1865/2746] rows=27,517,191 speed=384,213/s elapsed=62.6s\n",
      "[rg 1870/2746] rows=27,601,369 speed=453,388/s elapsed=62.8s\n",
      "[rg 1875/2746] rows=27,666,020 speed=385,027/s elapsed=63.0s\n",
      "[rg 1880/2746] rows=27,701,716 speed=443,751/s elapsed=63.1s\n",
      "[rg 1885/2746] rows=27,764,936 speed=425,712/s elapsed=63.2s\n",
      "[rg 1890/2746] rows=27,809,309 speed=444,037/s elapsed=63.3s\n",
      "[rg 1895/2746] rows=27,884,981 speed=428,137/s elapsed=63.5s\n",
      "[rg 1900/2746] rows=27,966,661 speed=462,088/s elapsed=63.7s\n",
      "[rg 1905/2746] rows=28,035,104 speed=463,985/s elapsed=63.8s\n",
      "[rg 1910/2746] rows=28,113,662 speed=429,585/s elapsed=64.0s\n",
      "[rg 1915/2746] rows=28,165,071 speed=369,275/s elapsed=64.1s\n",
      "[rg 1920/2746] rows=28,215,601 speed=524,394/s elapsed=64.2s\n",
      "[rg 1925/2746] rows=28,299,613 speed=422,940/s elapsed=64.4s\n",
      "[rg 1930/2746] rows=28,373,315 speed=554,622/s elapsed=64.6s\n",
      "[rg 1935/2746] rows=28,453,724 speed=438,096/s elapsed=64.7s\n",
      "[rg 1940/2746] rows=28,516,937 speed=421,227/s elapsed=64.9s\n",
      "[rg 1945/2746] rows=28,564,458 speed=340,777/s elapsed=65.0s\n",
      "[rg 1950/2746] rows=28,634,617 speed=713,762/s elapsed=65.1s\n",
      "[rg 1955/2746] rows=28,750,956 speed=465,953/s elapsed=65.4s\n",
      "[rg 1960/2746] rows=28,818,248 speed=459,354/s elapsed=65.5s\n",
      "[rg 1965/2746] rows=28,897,517 speed=432,030/s elapsed=65.7s\n",
      "[rg 1970/2746] rows=28,938,827 speed=495,175/s elapsed=65.8s\n",
      "[rg 1975/2746] rows=28,991,302 speed=430,179/s elapsed=65.9s\n",
      "[rg 1980/2746] rows=29,034,499 speed=381,673/s elapsed=66.0s\n",
      "[rg 1985/2746] rows=29,111,672 speed=466,080/s elapsed=66.2s\n",
      "[rg 1990/2746] rows=29,179,447 speed=482,719/s elapsed=66.3s\n",
      "[rg 1995/2746] rows=29,369,697 speed=582,520/s elapsed=66.7s\n",
      "[rg 2000/2746] rows=29,529,515 speed=598,686/s elapsed=66.9s\n",
      "[rg 2005/2746] rows=29,590,396 speed=394,655/s elapsed=67.1s\n",
      "[rg 2010/2746] rows=29,648,903 speed=453,841/s elapsed=67.2s\n",
      "[rg 2015/2746] rows=29,710,646 speed=360,670/s elapsed=67.4s\n",
      "[rg 2020/2746] rows=29,754,041 speed=432,868/s elapsed=67.5s\n",
      "[rg 2025/2746] rows=29,811,938 speed=385,946/s elapsed=67.6s\n",
      "[rg 2030/2746] rows=29,888,731 speed=392,570/s elapsed=67.8s\n",
      "[rg 2035/2746] rows=29,940,764 speed=392,999/s elapsed=68.0s\n",
      "[rg 2040/2746] rows=30,015,349 speed=523,818/s elapsed=68.1s\n",
      "[rg 2045/2746] rows=30,093,745 speed=550,226/s elapsed=68.2s\n",
      "[rg 2050/2746] rows=30,185,896 speed=433,630/s elapsed=68.5s\n",
      "[rg 2055/2746] rows=30,249,625 speed=413,094/s elapsed=68.6s\n",
      "[rg 2060/2746] rows=30,329,330 speed=459,759/s elapsed=68.8s\n",
      "[rg 2065/2746] rows=30,434,350 speed=494,225/s elapsed=69.0s\n",
      "[rg 2070/2746] rows=30,529,976 speed=482,476/s elapsed=69.2s\n",
      "[rg 2075/2746] rows=30,618,774 speed=443,680/s elapsed=69.4s\n",
      "[rg 2080/2746] rows=30,709,810 speed=484,345/s elapsed=69.6s\n",
      "[rg 2085/2746] rows=30,783,109 speed=393,446/s elapsed=69.8s\n",
      "[rg 2090/2746] rows=30,831,975 speed=427,834/s elapsed=69.9s\n",
      "[rg 2095/2746] rows=30,914,441 speed=462,056/s elapsed=70.1s\n",
      "[rg 2100/2746] rows=30,984,807 speed=527,536/s elapsed=70.2s\n",
      "[rg 2105/2746] rows=31,017,837 speed=282,760/s elapsed=70.3s\n",
      "[rg 2110/2746] rows=31,096,678 speed=459,125/s elapsed=70.5s\n",
      "[rg 2115/2746] rows=31,204,001 speed=467,832/s elapsed=70.7s\n",
      "[rg 2120/2746] rows=31,289,082 speed=442,537/s elapsed=70.9s\n",
      "[rg 2125/2746] rows=31,325,750 speed=355,798/s elapsed=71.0s\n",
      "[rg 2130/2746] rows=31,386,894 speed=502,439/s elapsed=71.1s\n",
      "[rg 2135/2746] rows=31,455,907 speed=447,161/s elapsed=71.3s\n",
      "[rg 2140/2746] rows=31,527,476 speed=497,899/s elapsed=71.4s\n",
      "[rg 2145/2746] rows=31,612,933 speed=481,796/s elapsed=71.6s\n",
      "[rg 2150/2746] rows=31,649,628 speed=351,506/s elapsed=71.7s\n",
      "[rg 2155/2746] rows=31,727,741 speed=448,277/s elapsed=71.9s\n",
      "[rg 2160/2746] rows=31,820,024 speed=444,925/s elapsed=72.1s\n",
      "[rg 2165/2746] rows=31,896,991 speed=437,127/s elapsed=72.3s\n",
      "[rg 2170/2746] rows=31,990,948 speed=479,363/s elapsed=72.5s\n",
      "[rg 2175/2746] rows=32,019,099 speed=337,040/s elapsed=72.5s\n",
      "[rg 2180/2746] rows=32,102,450 speed=499,936/s elapsed=72.7s\n",
      "[rg 2185/2746] rows=32,171,010 speed=448,913/s elapsed=72.9s\n",
      "[rg 2190/2746] rows=32,260,244 speed=494,485/s elapsed=73.0s\n",
      "[rg 2195/2746] rows=32,344,973 speed=421,817/s elapsed=73.2s\n",
      "[rg 2200/2746] rows=32,447,081 speed=546,513/s elapsed=73.4s\n",
      "[rg 2205/2746] rows=32,494,838 speed=366,833/s elapsed=73.6s\n",
      "[rg 2210/2746] rows=32,546,036 speed=440,154/s elapsed=73.7s\n",
      "[rg 2215/2746] rows=32,611,023 speed=404,304/s elapsed=73.8s\n",
      "[rg 2220/2746] rows=32,685,954 speed=482,056/s elapsed=74.0s\n",
      "[rg 2225/2746] rows=32,755,550 speed=448,716/s elapsed=74.2s\n",
      "[rg 2230/2746] rows=32,827,754 speed=443,001/s elapsed=74.3s\n",
      "[rg 2235/2746] rows=32,918,242 speed=410,008/s elapsed=74.5s\n",
      "[rg 2240/2746] rows=32,977,243 speed=456,130/s elapsed=74.7s\n",
      "[rg 2245/2746] rows=33,038,318 speed=399,703/s elapsed=74.8s\n",
      "[rg 2250/2746] rows=33,139,330 speed=511,945/s elapsed=75.0s\n",
      "[rg 2255/2746] rows=33,230,395 speed=496,183/s elapsed=75.2s\n",
      "[rg 2260/2746] rows=33,303,172 speed=410,737/s elapsed=75.4s\n",
      "[rg 2265/2746] rows=33,353,053 speed=405,318/s elapsed=75.5s\n",
      "[rg 2270/2746] rows=33,403,576 speed=505,034/s elapsed=75.6s\n",
      "[rg 2275/2746] rows=33,491,558 speed=468,315/s elapsed=75.8s\n",
      "[rg 2280/2746] rows=33,559,341 speed=441,772/s elapsed=75.9s\n",
      "[rg 2285/2746] rows=33,654,237 speed=453,152/s elapsed=76.2s\n",
      "[rg 2290/2746] rows=33,733,211 speed=419,989/s elapsed=76.3s\n",
      "[rg 2295/2746] rows=33,839,485 speed=464,555/s elapsed=76.6s\n",
      "[rg 2300/2746] rows=33,895,493 speed=408,619/s elapsed=76.7s\n",
      "[rg 2305/2746] rows=33,957,879 speed=377,869/s elapsed=76.9s\n",
      "[rg 2310/2746] rows=34,024,942 speed=441,207/s elapsed=77.0s\n",
      "[rg 2315/2746] rows=34,112,391 speed=441,717/s elapsed=77.2s\n",
      "[rg 2320/2746] rows=34,189,335 speed=440,960/s elapsed=77.4s\n",
      "[rg 2325/2746] rows=34,264,450 speed=431,166/s elapsed=77.6s\n",
      "[rg 2330/2746] rows=34,348,164 speed=456,501/s elapsed=77.8s\n",
      "[rg 2335/2746] rows=34,426,497 speed=429,242/s elapsed=77.9s\n",
      "[rg 2340/2746] rows=34,442,908 speed=270,851/s elapsed=78.0s\n",
      "[rg 2345/2746] rows=34,524,001 speed=459,981/s elapsed=78.2s\n",
      "[rg 2350/2746] rows=34,589,564 speed=512,065/s elapsed=78.3s\n",
      "[rg 2355/2746] rows=34,679,202 speed=434,726/s elapsed=78.5s\n",
      "[rg 2360/2746] rows=34,727,284 speed=347,457/s elapsed=78.6s\n",
      "[rg 2365/2746] rows=34,826,254 speed=508,854/s elapsed=78.8s\n",
      "[rg 2370/2746] rows=34,856,948 speed=424,876/s elapsed=78.9s\n",
      "[rg 2375/2746] rows=34,916,553 speed=363,681/s elapsed=79.1s\n",
      "[rg 2380/2746] rows=34,959,099 speed=420,222/s elapsed=79.2s\n",
      "[rg 2385/2746] rows=35,010,293 speed=367,864/s elapsed=79.3s\n",
      "[rg 2390/2746] rows=35,148,331 speed=486,154/s elapsed=79.6s\n",
      "[rg 2395/2746] rows=35,255,577 speed=422,786/s elapsed=79.9s\n",
      "[rg 2400/2746] rows=35,321,820 speed=419,886/s elapsed=80.0s\n",
      "[rg 2405/2746] rows=35,398,318 speed=407,117/s elapsed=80.2s\n",
      "[rg 2410/2746] rows=35,490,625 speed=413,141/s elapsed=80.4s\n",
      "[rg 2415/2746] rows=35,581,561 speed=387,329/s elapsed=80.7s\n",
      "[rg 2420/2746] rows=35,716,791 speed=510,475/s elapsed=80.9s\n",
      "[rg 2425/2746] rows=35,783,995 speed=379,968/s elapsed=81.1s\n",
      "[rg 2430/2746] rows=35,827,888 speed=403,781/s elapsed=81.2s\n",
      "[rg 2435/2746] rows=35,873,070 speed=475,337/s elapsed=81.3s\n",
      "[rg 2440/2746] rows=35,948,106 speed=424,016/s elapsed=81.5s\n",
      "[rg 2445/2746] rows=36,011,095 speed=406,058/s elapsed=81.6s\n",
      "[rg 2450/2746] rows=36,153,694 speed=581,961/s elapsed=81.9s\n",
      "[rg 2455/2746] rows=36,188,678 speed=305,146/s elapsed=82.0s\n",
      "[rg 2460/2746] rows=36,254,053 speed=448,665/s elapsed=82.1s\n",
      "[rg 2465/2746] rows=36,318,147 speed=363,277/s elapsed=82.3s\n",
      "[rg 2470/2746] rows=36,388,034 speed=439,321/s elapsed=82.5s\n",
      "[rg 2475/2746] rows=36,519,739 speed=462,561/s elapsed=82.8s\n",
      "[rg 2480/2746] rows=36,584,893 speed=394,005/s elapsed=82.9s\n",
      "[rg 2485/2746] rows=36,598,305 speed=192,271/s elapsed=83.0s\n",
      "[rg 2490/2746] rows=36,645,381 speed=468,916/s elapsed=83.1s\n",
      "[rg 2495/2746] rows=36,715,861 speed=386,414/s elapsed=83.3s\n",
      "[rg 2500/2746] rows=36,790,420 speed=422,782/s elapsed=83.5s\n",
      "[rg 2505/2746] rows=36,855,011 speed=425,524/s elapsed=83.6s\n",
      "[rg 2510/2746] rows=37,018,673 speed=547,356/s elapsed=83.9s\n",
      "[rg 2515/2746] rows=37,078,880 speed=347,297/s elapsed=84.1s\n",
      "[rg 2520/2746] rows=37,138,887 speed=467,499/s elapsed=84.2s\n",
      "[rg 2525/2746] rows=37,194,440 speed=350,990/s elapsed=84.4s\n",
      "[rg 2530/2746] rows=37,276,910 speed=467,755/s elapsed=84.5s\n",
      "[rg 2535/2746] rows=37,370,170 speed=466,149/s elapsed=84.7s\n",
      "[rg 2540/2746] rows=37,476,862 speed=503,699/s elapsed=85.0s\n",
      "[rg 2545/2746] rows=37,557,055 speed=445,456/s elapsed=85.1s\n",
      "[rg 2550/2746] rows=37,585,612 speed=303,222/s elapsed=85.2s\n",
      "[rg 2555/2746] rows=37,669,770 speed=471,673/s elapsed=85.4s\n",
      "[rg 2560/2746] rows=37,724,414 speed=361,735/s elapsed=85.6s\n",
      "[rg 2565/2746] rows=37,811,964 speed=420,224/s elapsed=85.8s\n",
      "[rg 2570/2746] rows=37,899,855 speed=431,664/s elapsed=86.0s\n",
      "[rg 2575/2746] rows=37,985,776 speed=449,022/s elapsed=86.2s\n",
      "[rg 2580/2746] rows=38,060,078 speed=403,129/s elapsed=86.3s\n",
      "[rg 2585/2746] rows=38,121,169 speed=432,946/s elapsed=86.5s\n",
      "[rg 2590/2746] rows=38,187,632 speed=489,683/s elapsed=86.6s\n",
      "[rg 2595/2746] rows=38,258,442 speed=465,014/s elapsed=86.8s\n",
      "[rg 2600/2746] rows=38,326,204 speed=407,787/s elapsed=86.9s\n",
      "[rg 2605/2746] rows=38,378,702 speed=353,304/s elapsed=87.1s\n",
      "[rg 2610/2746] rows=38,422,866 speed=397,635/s elapsed=87.2s\n",
      "[rg 2615/2746] rows=38,476,688 speed=373,435/s elapsed=87.3s\n",
      "[rg 2620/2746] rows=38,565,282 speed=493,452/s elapsed=87.5s\n",
      "[rg 2625/2746] rows=38,656,441 speed=584,474/s elapsed=87.7s\n",
      "[rg 2630/2746] rows=38,725,647 speed=395,255/s elapsed=87.9s\n",
      "[rg 2635/2746] rows=38,770,561 speed=355,876/s elapsed=88.0s\n",
      "[rg 2640/2746] rows=38,821,575 speed=460,973/s elapsed=88.1s\n",
      "[rg 2645/2746] rows=38,923,065 speed=485,705/s elapsed=88.3s\n",
      "[rg 2650/2746] rows=38,990,759 speed=408,378/s elapsed=88.5s\n",
      "[rg 2655/2746] rows=39,034,066 speed=338,599/s elapsed=88.6s\n",
      "[rg 2660/2746] rows=39,073,806 speed=574,713/s elapsed=88.7s\n",
      "[rg 2665/2746] rows=39,126,307 speed=405,883/s elapsed=88.8s\n",
      "[rg 2670/2746] rows=39,196,276 speed=481,045/s elapsed=88.9s\n",
      "[rg 2675/2746] rows=39,329,507 speed=434,299/s elapsed=89.2s\n",
      "[rg 2680/2746] rows=39,416,558 speed=433,376/s elapsed=89.4s\n",
      "[rg 2685/2746] rows=39,453,174 speed=318,526/s elapsed=89.6s\n",
      "[rg 2690/2746] rows=39,535,667 speed=540,312/s elapsed=89.7s\n",
      "[rg 2695/2746] rows=39,624,011 speed=468,671/s elapsed=89.9s\n",
      "[rg 2700/2746] rows=39,719,243 speed=451,033/s elapsed=90.1s\n",
      "[rg 2705/2746] rows=39,771,581 speed=439,299/s elapsed=90.2s\n",
      "[rg 2710/2746] rows=39,847,655 speed=491,344/s elapsed=90.4s\n",
      "[rg 2715/2746] rows=39,915,226 speed=411,531/s elapsed=90.6s\n",
      "[rg 2720/2746] rows=40,004,236 speed=557,967/s elapsed=90.7s\n",
      "[rg 2725/2746] rows=40,077,431 speed=401,478/s elapsed=90.9s\n",
      "[rg 2730/2746] rows=40,129,020 speed=460,902/s elapsed=91.0s\n",
      "[rg 2735/2746] rows=40,212,565 speed=420,974/s elapsed=91.2s\n",
      "[rg 2740/2746] rows=40,307,561 speed=474,780/s elapsed=91.4s\n",
      "[rg 2745/2746] rows=40,397,365 speed=491,532/s elapsed=91.6s\n",
      "🏁 DONE rows=40,409,432 -> onefile=C:\\datum-api-examples-main\\OriON\\signals\\arbitrage\\onefile.jsonl.gz summary=C:\\datum-api-examples-main\\OriON\\signals\\arbitrage\\summary.csv best_params=C:\\datum-api-examples-main\\OriON\\signals\\arbitrage\\best_params.jsonl.gz\n",
      "Arbitrage completed (no pre-sorting).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _resolve_orion_paths(strategy_code: str):\n",
    "    final_env = os.environ.get(\"FINAL_PARQUET_PATH\")\n",
    "    sig_env   = os.environ.get(\"SIGNALS_DIR\")\n",
    "    orion_env = os.environ.get(\"ORION_HOME\")\n",
    "\n",
    "    final_path = Path(final_env).expanduser().resolve() if final_env else None\n",
    "    signals_base = Path(sig_env).expanduser().resolve() if sig_env else None\n",
    "\n",
    "    if (final_path is None or signals_base is None) and orion_env:\n",
    "        orion_home = Path(orion_env).expanduser().resolve()\n",
    "        if final_path is None:\n",
    "            final_path = (orion_home / \"CRACEN\" / \"final.parquet\").resolve()\n",
    "        if signals_base is None:\n",
    "            signals_base = (orion_home / \"signals\").resolve()\n",
    "\n",
    "    if final_path is None or signals_base is None:\n",
    "        here = Path.cwd().resolve()\n",
    "        orion_home = None\n",
    "        for parent in [here] + list(here.parents):\n",
    "            if parent.name.lower() == \"orion\":\n",
    "                orion_home = parent\n",
    "                break\n",
    "            cand = parent / \"OriON\"\n",
    "            if cand.exists() and cand.is_dir():\n",
    "                orion_home = cand.resolve()\n",
    "                break\n",
    "\n",
    "        if orion_home is None:\n",
    "            raise RuntimeError(\"Cannot locate OriON. Set ORION_HOME (recommended).\")\n",
    "\n",
    "        if final_path is None:\n",
    "            final_path = (orion_home / \"CRACEN\" / \"final.parquet\").resolve()\n",
    "        if signals_base is None:\n",
    "            signals_base = (orion_home / \"signals\").resolve()\n",
    "\n",
    "    out_dir = (signals_base / strategy_code.lower()).resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not final_path.exists():\n",
    "        raise FileNotFoundError(f\"FINAL parquet not found: {final_path}\")\n",
    "\n",
    "    return final_path, out_dir\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# MAIN (NO SORTING)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "FINAL_PATH, OUT_DIR = _resolve_orion_paths(\"arbitrage\")\n",
    "\n",
    "print(\"Using FINAL parquet (no sorting):\", FINAL_PATH)\n",
    "\n",
    "devsig_stream_stats_v12_exporter(\n",
    "    input_path=str(FINAL_PATH),  # <-- напряму\n",
    "\n",
    "    output_onefile_jsonl=str(OUT_DIR / \"onefile.jsonl.gz\"),\n",
    "    output_best_params_jsonl=str(OUT_DIR / \"best_params.jsonl.gz\"),\n",
    "    output_summary_csv=str(OUT_DIR / \"summary.csv\"),\n",
    "\n",
    "    dev_thr=0.20,\n",
    "    norm_thr=0.10,\n",
    "    soft_ratio=3.0,\n",
    "\n",
    "    include_events_pre=False,\n",
    "    include_events_intra=False,\n",
    "    max_events_per_ticker=500,\n",
    "    min_events_per_ticker=10,\n",
    "\n",
    "    start_band_minutes=30,\n",
    "    norm_band_minutes=30,\n",
    "\n",
    "    sigma_bin_min=0.2,\n",
    "    sigma_bin_max=2.7,\n",
    "    sigma_bin_step=0.1,\n",
    "\n",
    "    bench_bin_min=-3.0,\n",
    "    bench_bin_max=3.0,\n",
    "    bench_bin_step=0.1,\n",
    "\n",
    "    open_series_downsample_seconds=60,\n",
    ")\n",
    "\n",
    "print(\"Arbitrage completed (no pre-sorting).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
